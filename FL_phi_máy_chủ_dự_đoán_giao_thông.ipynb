{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMmqAteHekb4/qX7lEaLDMm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thangthao22/python-training/blob/main/FL_phi_m%C3%A1y_ch%E1%BB%A7_d%E1%BB%B1_%C4%91o%C3%A1n_giao_th%C3%B4ng.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Phase 1: chuẩn bị**"
      ],
      "metadata": {
        "id": "TynGjfb_vg4m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 1: Import Libraries và Setup"
      ],
      "metadata": {
        "id": "XRMu0cXmEbxw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from datetime import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import logging\n",
        "import time\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Kiểm tra GPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Tạo thư mục cần thiết\n",
        "for dir_name in ['logs', 'checkpoints', 'results']:\n",
        "    os.makedirs(f'/content/{dir_name}', exist_ok=True)\n",
        "\n",
        "print(\"Current time:\", datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
        "print(\"Current user:\", os.getenv('USER'))  # Trong Colab thường là None"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "evYw-jOevhAj",
        "outputId": "736ba10b-1759-4a2a-8a70-0a8841271069"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n",
            "Current time: 2025-05-02 10:05:56\n",
            "Current user: None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 2: Logger Setup\n",
        "\n"
      ],
      "metadata": {
        "id": "L6UaKCHAtdaE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def setup_logger(log_dir):\n",
        "    \"\"\"\n",
        "    Khởi tạo logger cho việc tracking quá trình training\n",
        "    \"\"\"\n",
        "    logger = logging.getLogger('AGCRN')\n",
        "    logger.setLevel(logging.INFO)\n",
        "\n",
        "    # File handler\n",
        "    log_filename = os.path.join(log_dir, f'training_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.log')\n",
        "    fh = logging.FileHandler(log_filename)\n",
        "    fh.setLevel(logging.INFO)\n",
        "\n",
        "    # Console handler\n",
        "    ch = logging.StreamHandler()\n",
        "    ch.setLevel(logging.INFO)\n",
        "\n",
        "    # Formatter\n",
        "    formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
        "    fh.setFormatter(formatter)\n",
        "    ch.setFormatter(formatter)\n",
        "\n",
        "    logger.addHandler(fh)\n",
        "    logger.addHandler(ch)\n",
        "\n",
        "    return logger\n",
        "\n",
        "logger = setup_logger('/content/logs')\n",
        "logger.info(\"Starting AGCRN training process...\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oaIFpu1Itdge",
        "outputId": "b3bedc04-c3e8-443b-93cb-976ebdda23ad"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-05-02 10:06:01,748 - INFO - Starting AGCRN training process...\n",
            "INFO:AGCRN:Starting AGCRN training process...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 3: Data Loading và Processing"
      ],
      "metadata": {
        "id": "GCxiXqh5tdl6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DataLoader:\n",
        "    def __init__(self, data_path):\n",
        "        self.data_path = data_path\n",
        "\n",
        "    def load_metr_la(self):\n",
        "        \"\"\"\n",
        "        Load dữ liệu METR-LA từ file csv\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # Load traffic data\n",
        "            df = pd.read_csv(os.path.join(self.data_path, 'metr-la.csv'), index_col=0)\n",
        "            df.index = pd.to_datetime(df.index)\n",
        "\n",
        "            # Load sensor locations\n",
        "            sensor_df = pd.read_csv(os.path.join(self.data_path, 'sensor_locations.csv'))\n",
        "\n",
        "            logger.info(f\"Data loaded successfully!\")\n",
        "            logger.info(f\"Traffic data shape: {df.shape}\")\n",
        "            logger.info(f\"Number of sensors: {len(sensor_df)}\")\n",
        "            logger.info(f\"Time range: from {df.index[0]} to {df.index[-1]}\")\n",
        "\n",
        "            return df, sensor_df\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error loading data: {e}\")\n",
        "            raise\n",
        "\n",
        "    def preprocess_data(self, df):\n",
        "        \"\"\"\n",
        "        Tiền xử lý dữ liệu\n",
        "        \"\"\"\n",
        "        # Convert to numpy array\n",
        "        data = df.values\n",
        "\n",
        "        # Add channel dimension\n",
        "        data = np.expand_dims(data, axis=-1)\n",
        "\n",
        "        # Normalize data\n",
        "        mean = np.mean(data)\n",
        "        std = np.std(data)\n",
        "        data_normalized = (data - mean) / std\n",
        "\n",
        "        # Create scaler dictionary for later use\n",
        "        scaler = {\n",
        "            'mean': mean,\n",
        "            'std': std\n",
        "        }\n",
        "\n",
        "        logger.info(f\"Data preprocessed:\")\n",
        "        logger.info(f\"Mean: {mean:.4f}\")\n",
        "        logger.info(f\"Std: {std:.4f}\")\n",
        "\n",
        "        return data_normalized, scaler\n",
        "\n",
        "    def train_test_split(self, data, val_ratio=0.1, test_ratio=0.2):\n",
        "        \"\"\"\n",
        "        Chia dữ liệu thành train, validation và test\n",
        "        \"\"\"\n",
        "        num_samples = data.shape[0]\n",
        "        num_test = int(num_samples * test_ratio)\n",
        "        num_val = int(num_samples * val_ratio)\n",
        "        num_train = num_samples - num_test - num_val\n",
        "\n",
        "        train_data = data[:num_train]\n",
        "        val_data = data[num_train:num_train+num_val]\n",
        "        test_data = data[num_train+num_val:]\n",
        "\n",
        "        logger.info(\"Data split completed:\")\n",
        "        logger.info(f\"Training set: {train_data.shape}\")\n",
        "        logger.info(f\"Validation set: {val_data.shape}\")\n",
        "        logger.info(f\"Test set: {test_data.shape}\")\n",
        "\n",
        "        return train_data, val_data, test_data\n",
        "\n",
        "# Khởi tạo DataLoader và load dữ liệu\n",
        "data_loader = DataLoader('/content/data')\n",
        "traffic_df, sensor_df = data_loader.load_metr_la()\n",
        "data_normalized, scaler = data_loader.preprocess_data(traffic_df)\n",
        "train_data, val_data, test_data = data_loader.train_test_split(data_normalized)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aVudkNbttdtj",
        "outputId": "629273cf-5009-4dfc-8bda-470f0280c23e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-05-02 10:06:06,134 - INFO - Data loaded successfully!\n",
            "INFO:AGCRN:Data loaded successfully!\n",
            "2025-05-02 10:06:06,137 - INFO - Traffic data shape: (34272, 207)\n",
            "INFO:AGCRN:Traffic data shape: (34272, 207)\n",
            "2025-05-02 10:06:06,139 - INFO - Number of sensors: 207\n",
            "INFO:AGCRN:Number of sensors: 207\n",
            "2025-05-02 10:06:06,142 - INFO - Time range: from 2012-03-01 00:00:00 to 2012-06-27 23:55:00\n",
            "INFO:AGCRN:Time range: from 2012-03-01 00:00:00 to 2012-06-27 23:55:00\n",
            "2025-05-02 10:06:06,236 - INFO - Data preprocessed:\n",
            "INFO:AGCRN:Data preprocessed:\n",
            "2025-05-02 10:06:06,239 - INFO - Mean: 53.7190\n",
            "INFO:AGCRN:Mean: 53.7190\n",
            "2025-05-02 10:06:06,242 - INFO - Std: 20.2614\n",
            "INFO:AGCRN:Std: 20.2614\n",
            "2025-05-02 10:06:06,245 - INFO - Data split completed:\n",
            "INFO:AGCRN:Data split completed:\n",
            "2025-05-02 10:06:06,247 - INFO - Training set: (23991, 207, 1)\n",
            "INFO:AGCRN:Training set: (23991, 207, 1)\n",
            "2025-05-02 10:06:06,250 - INFO - Validation set: (3427, 207, 1)\n",
            "INFO:AGCRN:Validation set: (3427, 207, 1)\n",
            "2025-05-02 10:06:06,252 - INFO - Test set: (6854, 207, 1)\n",
            "INFO:AGCRN:Test set: (6854, 207, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 4: Dataset và Batch Generator"
      ],
      "metadata": {
        "id": "dZI8vO8_tdy6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TrafficDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, data, seq_len, horizon, num_nodes):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            data: numpy array shape (time_steps, num_nodes, features)\n",
        "            seq_len: input sequence length\n",
        "            horizon: prediction horizon\n",
        "            num_nodes: number of nodes/sensors\n",
        "        \"\"\"\n",
        "        self.data = torch.FloatTensor(data)\n",
        "        self.seq_len = seq_len\n",
        "        self.horizon = horizon\n",
        "        self.num_nodes = num_nodes\n",
        "        self.samples = self._generate_samples()\n",
        "\n",
        "    def _generate_samples(self):\n",
        "        \"\"\"\n",
        "        Generate samples for training/testing\n",
        "        \"\"\"\n",
        "        num_samples = len(self.data) - self.seq_len - self.horizon + 1\n",
        "        samples = []\n",
        "        for i in range(num_samples):\n",
        "            x = self.data[i:i+self.seq_len]\n",
        "            y = self.data[i+self.seq_len:i+self.seq_len+self.horizon]\n",
        "            samples.append((x, y))\n",
        "        return samples\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.samples[idx]\n",
        "\n",
        "def create_data_loaders(train_data, val_data, test_data, batch_size, seq_len, horizon, num_nodes):\n",
        "    \"\"\"\n",
        "    Create DataLoader objects for train, validation and test sets\n",
        "    \"\"\"\n",
        "    train_dataset = TrafficDataset(train_data, seq_len, horizon, num_nodes)\n",
        "    val_dataset = TrafficDataset(val_data, seq_len, horizon, num_nodes)\n",
        "    test_dataset = TrafficDataset(test_data, seq_len, horizon, num_nodes)\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        num_workers=0,  # Colab recommendation\n",
        "        pin_memory=True if torch.cuda.is_available() else False\n",
        "    )\n",
        "\n",
        "    val_loader = torch.utils.data.DataLoader(\n",
        "        val_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=0,\n",
        "        pin_memory=True if torch.cuda.is_available() else False\n",
        "    )\n",
        "\n",
        "    test_loader = torch.utils.data.DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=0,\n",
        "        pin_memory=True if torch.cuda.is_available() else False\n",
        "    )\n",
        "\n",
        "    logger.info(\"DataLoaders created:\")\n",
        "    logger.info(f\"Training batches: {len(train_loader)}\")\n",
        "    logger.info(f\"Validation batches: {len(val_loader)}\")\n",
        "    logger.info(f\"Test batches: {len(test_loader)}\")\n",
        "\n",
        "    return train_loader, val_loader, test_loader\n",
        "\n",
        "# Create dataloaders\n",
        "config = {\n",
        "    'batch_size': 64,\n",
        "    'seq_len': 12,\n",
        "    'horizon': 12,\n",
        "    'num_nodes': traffic_df.shape[1]\n",
        "}\n",
        "\n",
        "train_loader, val_loader, test_loader = create_data_loaders(\n",
        "    train_data, val_data, test_data,\n",
        "    config['batch_size'], config['seq_len'],\n",
        "    config['horizon'], config['num_nodes']\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VALWJYCztd7z",
        "outputId": "88ed22fd-05e3-44f0-f0ed-95bc66936398"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-05-02 10:06:17,211 - INFO - DataLoaders created:\n",
            "INFO:AGCRN:DataLoaders created:\n",
            "2025-05-02 10:06:17,213 - INFO - Training batches: 375\n",
            "INFO:AGCRN:Training batches: 375\n",
            "2025-05-02 10:06:17,215 - INFO - Validation batches: 54\n",
            "INFO:AGCRN:Validation batches: 54\n",
            "2025-05-02 10:06:17,216 - INFO - Test batches: 107\n",
            "INFO:AGCRN:Test batches: 107\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 5: Visualization Functions"
      ],
      "metadata": {
        "id": "W2MPl5lDteDj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Visualizer:\n",
        "    def __init__(self, save_dir='/content/results'):\n",
        "        self.save_dir = save_dir\n",
        "        os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "    def plot_training_progress(self, train_losses, val_losses):\n",
        "        \"\"\"\n",
        "        Plot training và validation losses\n",
        "        \"\"\"\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        plt.plot(train_losses, label='Training Loss', marker='o')\n",
        "        plt.plot(val_losses, label='Validation Loss', marker='s')\n",
        "        plt.title('Training Progress')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "\n",
        "        # Save plot\n",
        "        plt.savefig(os.path.join(self.save_dir, 'training_progress.png'))\n",
        "        plt.close()\n",
        "\n",
        "    def plot_prediction_comparison(self, predictions, targets, sensor_id=0, num_steps=100):\n",
        "        \"\"\"\n",
        "        Plot so sánh giữa giá trị dự đoán và thực tế\n",
        "        \"\"\"\n",
        "        plt.figure(figsize=(15, 6))\n",
        "\n",
        "        # Plot actual values\n",
        "        plt.plot(targets[:num_steps, sensor_id, 0],\n",
        "                 label='Actual', marker='o', markersize=2)\n",
        "\n",
        "        # Plot predictions\n",
        "        plt.plot(predictions[:num_steps, sensor_id, 0],\n",
        "                 label='Predicted', marker='s', markersize=2)\n",
        "\n",
        "        plt.title(f'Traffic Flow Predictions vs Actual (Sensor {sensor_id})')\n",
        "        plt.xlabel('Time Steps')\n",
        "        plt.ylabel('Traffic Flow')\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "\n",
        "        # Save plot\n",
        "        plt.savefig(os.path.join(self.save_dir, f'prediction_comparison_sensor_{sensor_id}.png'))\n",
        "        plt.close()\n",
        "\n",
        "    def plot_spatial_heatmap(self, correlation_matrix, sensor_ids):\n",
        "        \"\"\"\n",
        "        Plot heatmap của spatial correlations\n",
        "        \"\"\"\n",
        "        plt.figure(figsize=(12, 10))\n",
        "        sns.heatmap(correlation_matrix,\n",
        "                    xticklabels=sensor_ids,\n",
        "                    yticklabels=sensor_ids,\n",
        "                    cmap='RdYlBu_r')\n",
        "        plt.title('Spatial Correlations between Sensors')\n",
        "\n",
        "        # Save plot\n",
        "        plt.savefig(os.path.join(self.save_dir, 'spatial_correlations.png'))\n",
        "        plt.close()\n",
        "\n",
        "# Initialize visualizer\n",
        "visualizer = Visualizer()\n",
        "\n",
        "# Example usage:\n",
        "# visualizer.plot_training_progress(train_losses, val_losses)\n",
        "# visualizer.plot_prediction_comparison(predictions, targets, sensor_id=0)\n",
        "# visualizer.plot_spatial_heatmap(correlation_matrix, sensor_ids)"
      ],
      "metadata": {
        "id": "eyrBrJPVteJm"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 6: Metrics"
      ],
      "metadata": {
        "id": "c_9j7mk5tePl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Metrics:\n",
        "    @staticmethod\n",
        "    def mae(pred, true):\n",
        "        \"\"\"Mean Absolute Error\"\"\"\n",
        "        return np.mean(np.abs(pred - true))\n",
        "\n",
        "    @staticmethod\n",
        "    def rmse(pred, true):\n",
        "        \"\"\"Root Mean Square Error\"\"\"\n",
        "        return np.sqrt(np.mean((pred - true) ** 2))\n",
        "\n",
        "    @staticmethod\n",
        "    def mape(pred, true):\n",
        "        \"\"\"Mean Absolute Percentage Error\"\"\"\n",
        "        mask = true != 0\n",
        "        return np.mean(np.abs((true[mask] - pred[mask]) / true[mask])) * 100\n",
        "\n",
        "    @staticmethod\n",
        "    def evaluate(pred, true):\n",
        "        \"\"\"Calculate all metrics\"\"\"\n",
        "        mae = Metrics.mae(pred, true)\n",
        "        rmse = Metrics.rmse(pred, true)\n",
        "        mape = Metrics.mape(pred, true)\n",
        "\n",
        "        return {\n",
        "            'MAE': mae,\n",
        "            'RMSE': rmse,\n",
        "            'MAPE': mape\n",
        "        }\n",
        "\n",
        "# Example usage:\n",
        "# metrics = Metrics.evaluate(predictions, targets)\n",
        "# logger.info(\"Test Results:\")\n",
        "# for metric_name, value in metrics.items():\n",
        "#     logger.info(f\"{metric_name}: {value:.4f}\")"
      ],
      "metadata": {
        "id": "tWt0HXnkteWX"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 7: AGCRN Model Components"
      ],
      "metadata": {
        "id": "dC9TkSHCtecM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AVWGCN(nn.Module):\n",
        "    def __init__(self, dim_in, dim_out, cheb_k, embed_dim):\n",
        "        super(AVWGCN, self).__init__()\n",
        "        self.cheb_k = cheb_k\n",
        "        self.weights_pool = nn.Parameter(torch.FloatTensor(embed_dim, cheb_k, dim_in, dim_out))\n",
        "        self.bias_pool = nn.Parameter(torch.FloatTensor(embed_dim, dim_out))\n",
        "        nn.init.xavier_uniform_(self.weights_pool)\n",
        "        nn.init.uniform_(self.bias_pool)\n",
        "        logger.info(f\"AVWGCN initialized with dim_in={dim_in}, dim_out={dim_out}, cheb_k={cheb_k}\")\n",
        "\n",
        "    def forward(self, x, node_embeddings):\n",
        "        node_num = node_embeddings.shape[0]\n",
        "        supports = F.softmax(F.relu(torch.mm(node_embeddings, node_embeddings.transpose(0, 1))), dim=1)\n",
        "        support_set = [torch.eye(node_num).to(supports.device), supports]\n",
        "\n",
        "        for k in range(2, self.cheb_k):\n",
        "            support_set.append(torch.matmul(2 * supports, support_set[-1]) - support_set[-2])\n",
        "        supports = torch.stack(support_set, dim=0)\n",
        "\n",
        "        weights = torch.einsum('nd,dkio->nkio', node_embeddings, self.weights_pool)\n",
        "        bias = torch.matmul(node_embeddings, self.bias_pool)\n",
        "        x_g = torch.einsum(\"knm,bmc->bknc\", supports, x)\n",
        "        x_g = x_g.permute(0, 2, 1, 3)\n",
        "        x_gconv = torch.einsum('bnki,nkio->bno', x_g, weights) + bias\n",
        "        return x_gconv\n",
        "\n",
        "class AGCRNCell(nn.Module):\n",
        "    def __init__(self, node_num, dim_in, dim_out, cheb_k, embed_dim):\n",
        "        super(AGCRNCell, self).__init__()\n",
        "        self.node_num = node_num\n",
        "        self.hidden_dim = dim_out\n",
        "        self.gate = AVWGCN(dim_in+self.hidden_dim, 2*dim_out, cheb_k, embed_dim)\n",
        "        self.update = AVWGCN(dim_in+self.hidden_dim, dim_out, cheb_k, embed_dim)\n",
        "        logger.info(f\"AGCRNCell initialized with node_num={node_num}, dim_in={dim_in}, dim_out={dim_out}\")\n",
        "\n",
        "    def forward(self, x, state, node_embeddings):\n",
        "        state = state.to(x.device)\n",
        "        input_and_state = torch.cat((x, state), dim=-1)\n",
        "        z_r = torch.sigmoid(self.gate(input_and_state, node_embeddings))\n",
        "        z, r = torch.split(z_r, self.hidden_dim, dim=-1)\n",
        "        candidate = torch.cat((x, z*state), dim=-1)\n",
        "        hc = torch.tanh(self.update(candidate, node_embeddings))\n",
        "        h = r*state + (1-r)*hc\n",
        "        return h\n",
        "\n",
        "    def init_hidden_state(self, batch_size):\n",
        "        return torch.zeros(batch_size, self.node_num, self.hidden_dim)"
      ],
      "metadata": {
        "id": "AsiqmGfzteiI"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 8: Main AGCRN Model"
      ],
      "metadata": {
        "id": "TvJajTTCtenM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AGCRN(nn.Module):\n",
        "    def __init__(self, num_nodes, input_dim, hidden_dim, output_dim, horizon, num_layers, cheb_k, embed_dim):\n",
        "        super(AGCRN, self).__init__()\n",
        "        self.num_nodes = num_nodes\n",
        "        self.input_dim = input_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.output_dim = output_dim\n",
        "        self.horizon = horizon\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.node_embeddings = nn.Parameter(torch.randn(self.num_nodes, embed_dim), requires_grad=True)\n",
        "\n",
        "        self.encoder = nn.ModuleList()\n",
        "        self.encoder.append(AGCRNCell(num_nodes, input_dim, hidden_dim, cheb_k, embed_dim))\n",
        "        for _ in range(1, num_layers):\n",
        "            self.encoder.append(AGCRNCell(num_nodes, hidden_dim, hidden_dim, cheb_k, embed_dim))\n",
        "\n",
        "        self.end_conv = nn.Conv2d(1, horizon * output_dim, kernel_size=(1, hidden_dim), bias=True)\n",
        "        logger.info(f\"AGCRN initialized with {num_layers} layers\")\n",
        "\n",
        "    def forward(self, source, target=None):\n",
        "        init_state = self.init_hidden(source.shape[0])\n",
        "        output, _ = self.encoder_forward(source, init_state)\n",
        "        output = output[:, -1:, :, :]\n",
        "        output = self.end_conv(output)\n",
        "        output = output.squeeze(-1).reshape(-1, self.horizon, self.output_dim, self.num_nodes)\n",
        "        output = output.permute(0, 1, 3, 2)\n",
        "        return output\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "        init_states = []\n",
        "        for i in range(self.num_layers):\n",
        "            init_states.append(self.encoder[i].init_hidden_state(batch_size))\n",
        "        return torch.stack(init_states, dim=0)\n",
        "\n",
        "    def encoder_forward(self, input_data, init_state):\n",
        "        seq_length = input_data.shape[1]\n",
        "        current_inputs = input_data\n",
        "        output_hidden = []\n",
        "\n",
        "        for i in range(self.num_layers):\n",
        "            state = init_state[i]\n",
        "            inner_states = []\n",
        "            for t in range(seq_length):\n",
        "                state = self.encoder[i](current_inputs[:, t, :, :], state, self.node_embeddings)\n",
        "                inner_states.append(state)\n",
        "            output_hidden.append(state)\n",
        "            current_inputs = torch.stack(inner_states, dim=1)\n",
        "\n",
        "        return current_inputs, output_hidden"
      ],
      "metadata": {
        "id": "VXia6E7ytes3"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 9: Model Configuration và Training Setup"
      ],
      "metadata": {
        "id": "bmDw5l32teyM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ModelConfig:\n",
        "    def __init__(self):\n",
        "        # Model Parameters\n",
        "        self.num_nodes = 207  # METR-LA dataset\n",
        "        self.input_dim = 1\n",
        "        self.output_dim = 1\n",
        "        self.hidden_dim = 64\n",
        "        self.embed_dim = 10\n",
        "        self.num_layers = 2\n",
        "        self.cheb_k = 2\n",
        "        self.horizon = 12\n",
        "        self.seq_len = 12\n",
        "\n",
        "        # Training Parameters\n",
        "        self.batch_size = 64\n",
        "        self.epochs = 100\n",
        "        self.learning_rate = 0.001\n",
        "        self.weight_decay = 0.0001\n",
        "        self.early_stop_patience = 10\n",
        "        self.grad_norm = True\n",
        "        self.max_grad_norm = 5\n",
        "        self.use_gpu = torch.cuda.is_available()\n",
        "\n",
        "        # Logging\n",
        "        self.log_step = 20\n",
        "\n",
        "        logger.info(\"Model configuration initialized\")\n",
        "        self.log_config()\n",
        "\n",
        "    def log_config(self):\n",
        "        logger.info(\"\\nModel Configuration:\")\n",
        "        for attr, value in vars(self).items():\n",
        "            logger.info(f\"{attr}: {value}\")\n",
        "\n",
        "config = ModelConfig()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uU2FOrBbte3m",
        "outputId": "a2ec874d-941a-456c-93c1-dcde78b04fd7"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-05-02 10:06:30,744 - INFO - Model configuration initialized\n",
            "INFO:AGCRN:Model configuration initialized\n",
            "2025-05-02 10:06:30,746 - INFO - \n",
            "Model Configuration:\n",
            "INFO:AGCRN:\n",
            "Model Configuration:\n",
            "2025-05-02 10:06:30,748 - INFO - num_nodes: 207\n",
            "INFO:AGCRN:num_nodes: 207\n",
            "2025-05-02 10:06:30,750 - INFO - input_dim: 1\n",
            "INFO:AGCRN:input_dim: 1\n",
            "2025-05-02 10:06:30,754 - INFO - output_dim: 1\n",
            "INFO:AGCRN:output_dim: 1\n",
            "2025-05-02 10:06:30,756 - INFO - hidden_dim: 64\n",
            "INFO:AGCRN:hidden_dim: 64\n",
            "2025-05-02 10:06:30,758 - INFO - embed_dim: 10\n",
            "INFO:AGCRN:embed_dim: 10\n",
            "2025-05-02 10:06:30,759 - INFO - num_layers: 2\n",
            "INFO:AGCRN:num_layers: 2\n",
            "2025-05-02 10:06:30,762 - INFO - cheb_k: 2\n",
            "INFO:AGCRN:cheb_k: 2\n",
            "2025-05-02 10:06:30,763 - INFO - horizon: 12\n",
            "INFO:AGCRN:horizon: 12\n",
            "2025-05-02 10:06:30,764 - INFO - seq_len: 12\n",
            "INFO:AGCRN:seq_len: 12\n",
            "2025-05-02 10:06:30,765 - INFO - batch_size: 64\n",
            "INFO:AGCRN:batch_size: 64\n",
            "2025-05-02 10:06:30,766 - INFO - epochs: 100\n",
            "INFO:AGCRN:epochs: 100\n",
            "2025-05-02 10:06:30,767 - INFO - learning_rate: 0.001\n",
            "INFO:AGCRN:learning_rate: 0.001\n",
            "2025-05-02 10:06:30,769 - INFO - weight_decay: 0.0001\n",
            "INFO:AGCRN:weight_decay: 0.0001\n",
            "2025-05-02 10:06:30,770 - INFO - early_stop_patience: 10\n",
            "INFO:AGCRN:early_stop_patience: 10\n",
            "2025-05-02 10:06:30,771 - INFO - grad_norm: True\n",
            "INFO:AGCRN:grad_norm: True\n",
            "2025-05-02 10:06:30,772 - INFO - max_grad_norm: 5\n",
            "INFO:AGCRN:max_grad_norm: 5\n",
            "2025-05-02 10:06:30,773 - INFO - use_gpu: False\n",
            "INFO:AGCRN:use_gpu: False\n",
            "2025-05-02 10:06:30,774 - INFO - log_step: 20\n",
            "INFO:AGCRN:log_step: 20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 10: Training Functions"
      ],
      "metadata": {
        "id": "8op7fEJDte9G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Trainer:\n",
        "    def __init__(self, model, train_loader, val_loader, test_loader, config, device):\n",
        "        self.model = model\n",
        "        self.train_loader = train_loader\n",
        "        self.val_loader = val_loader\n",
        "        self.test_loader = test_loader\n",
        "        self.config = config\n",
        "        self.device = device\n",
        "\n",
        "        self.optimizer = torch.optim.Adam(model.parameters(),\n",
        "                                        lr=config.learning_rate,\n",
        "                                        weight_decay=config.weight_decay)\n",
        "        self.criterion = nn.MSELoss()\n",
        "        self.scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "        self.best_val_loss = float('inf')\n",
        "        self.not_improved_count = 0\n",
        "\n",
        "        logger.info(\"Trainer initialized\")\n",
        "\n",
        "    def train_epoch(self, epoch):\n",
        "        self.model.train()\n",
        "        total_loss = 0\n",
        "        for batch_idx, (data, target) in enumerate(self.train_loader):\n",
        "            data, target = data.to(self.device), target.to(self.device)\n",
        "\n",
        "            self.optimizer.zero_grad()\n",
        "            with torch.cuda.amp.autocast():\n",
        "                output = self.model(data)\n",
        "                loss = self.criterion(output, target)\n",
        "\n",
        "            # Backward and optimize\n",
        "            self.scaler.scale(loss).backward()\n",
        "            if self.config.grad_norm:\n",
        "                self.scaler.unscale_(self.optimizer)\n",
        "                torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.config.max_grad_norm)\n",
        "            self.scaler.step(self.optimizer)\n",
        "            self.scaler.update()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            if batch_idx % self.config.log_step == 0:\n",
        "                logger.info(f'Train Epoch: {epoch} [{batch_idx}/{len(self.train_loader)} '\n",
        "                          f'({100. * batch_idx / len(self.train_loader):.0f}%)]\\tLoss: {loss.item():.6f}')\n",
        "\n",
        "        return total_loss / len(self.train_loader)\n",
        "\n",
        "    def validate(self, epoch):\n",
        "        self.model.eval()\n",
        "        total_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for batch_idx, (data, target) in enumerate(self.val_loader):\n",
        "                data, target = data.to(self.device), target.to(self.device)\n",
        "                output = self.model(data)\n",
        "                loss = self.criterion(output, target)\n",
        "                total_loss += loss.item()\n",
        "\n",
        "        val_loss = total_loss / len(self.val_loader)\n",
        "        logger.info(f'Validation Epoch: {epoch}\\tLoss: {val_loss:.6f}')\n",
        "        return val_loss\n",
        "\n",
        "    def train(self):\n",
        "        train_losses = []\n",
        "        val_losses = []\n",
        "\n",
        "        for epoch in range(1, self.config.epochs + 1):\n",
        "            train_loss = self.train_epoch(epoch)\n",
        "            val_loss = self.validate(epoch)\n",
        "\n",
        "            train_losses.append(train_loss)\n",
        "            val_losses.append(val_loss)\n",
        "\n",
        "            # Early stopping\n",
        "            if val_loss < self.best_val_loss:\n",
        "                self.best_val_loss = val_loss\n",
        "                torch.save(self.model.state_dict(), '/content/checkpoints/best_model.pth')\n",
        "                self.not_improved_count = 0\n",
        "            else:\n",
        "                self.not_improved_count += 1\n",
        "                if self.not_improved_count == self.config.early_stop_patience:\n",
        "                    logger.info(f\"Early stopping triggered after {epoch} epochs\")\n",
        "                    break\n",
        "\n",
        "        return train_losses, val_losses"
      ],
      "metadata": {
        "id": "6P-SnF2AtfCw"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 11: Model Testing và Initial Run"
      ],
      "metadata": {
        "id": "AZot2slbtfIE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_model():\n",
        "    logger.info(\"Initializing model test...\")\n",
        "\n",
        "    # Initialize model\n",
        "    model = AGCRN(\n",
        "        num_nodes=config.num_nodes,\n",
        "        input_dim=config.input_dim,\n",
        "        hidden_dim=config.hidden_dim,\n",
        "        output_dim=config.output_dim,\n",
        "        horizon=config.horizon,\n",
        "        num_layers=config.num_layers,\n",
        "        cheb_k=config.cheb_k,\n",
        "        embed_dim=config.embed_dim\n",
        "    ).to(device)\n",
        "\n",
        "    # Initialize trainer\n",
        "    trainer = Trainer(model, train_loader, val_loader, test_loader, config, device)\n",
        "\n",
        "    # Train model for a few epochs as test\n",
        "    logger.info(\"Starting test training...\")\n",
        "    train_losses, val_losses = trainer.train()\n",
        "\n",
        "    # Plot results\n",
        "    visualizer.plot_training_progress(train_losses, val_losses)\n",
        "\n",
        "    # Test prediction on a sample\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        sample_data, sample_target = next(iter(test_loader))\n",
        "        sample_data = sample_data.to(device)\n",
        "        predictions = model(sample_data)\n",
        "        predictions = predictions.cpu().numpy()\n",
        "        sample_target = sample_target.numpy()\n",
        "\n",
        "    # Plot sample predictions\n",
        "    visualizer.plot_prediction_comparison(predictions, sample_target)\n",
        "\n",
        "    return model, train_losses, val_losses\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    logger.info(\"Starting model test...\")\n",
        "    model, train_losses, val_losses = test_model()\n",
        "    logger.info(\"Model test completed!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 755
        },
        "id": "qR4Kf6TjtfOL",
        "outputId": "8b2fb4d3-5fa6-4ae7-e0e7-4072573e65e8"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-05-02 10:06:50,579 - INFO - Starting model test...\n",
            "INFO:AGCRN:Starting model test...\n",
            "2025-05-02 10:06:50,581 - INFO - Initializing model test...\n",
            "INFO:AGCRN:Initializing model test...\n",
            "2025-05-02 10:06:50,597 - INFO - AVWGCN initialized with dim_in=65, dim_out=128, cheb_k=2\n",
            "INFO:AGCRN:AVWGCN initialized with dim_in=65, dim_out=128, cheb_k=2\n",
            "2025-05-02 10:06:50,601 - INFO - AVWGCN initialized with dim_in=65, dim_out=64, cheb_k=2\n",
            "INFO:AGCRN:AVWGCN initialized with dim_in=65, dim_out=64, cheb_k=2\n",
            "2025-05-02 10:06:50,603 - INFO - AGCRNCell initialized with node_num=207, dim_in=1, dim_out=64\n",
            "INFO:AGCRN:AGCRNCell initialized with node_num=207, dim_in=1, dim_out=64\n",
            "2025-05-02 10:06:50,609 - INFO - AVWGCN initialized with dim_in=128, dim_out=128, cheb_k=2\n",
            "INFO:AGCRN:AVWGCN initialized with dim_in=128, dim_out=128, cheb_k=2\n",
            "2025-05-02 10:06:50,613 - INFO - AVWGCN initialized with dim_in=128, dim_out=64, cheb_k=2\n",
            "INFO:AGCRN:AVWGCN initialized with dim_in=128, dim_out=64, cheb_k=2\n",
            "2025-05-02 10:06:50,615 - INFO - AGCRNCell initialized with node_num=207, dim_in=64, dim_out=64\n",
            "INFO:AGCRN:AGCRNCell initialized with node_num=207, dim_in=64, dim_out=64\n",
            "2025-05-02 10:06:50,618 - INFO - AGCRN initialized with 2 layers\n",
            "INFO:AGCRN:AGCRN initialized with 2 layers\n",
            "2025-05-02 10:06:57,100 - INFO - Trainer initialized\n",
            "INFO:AGCRN:Trainer initialized\n",
            "2025-05-02 10:06:57,102 - INFO - Starting test training...\n",
            "INFO:AGCRN:Starting test training...\n",
            "2025-05-02 10:07:05,539 - INFO - Train Epoch: 1 [0/375 (0%)]\tLoss: 1.306010\n",
            "INFO:AGCRN:Train Epoch: 1 [0/375 (0%)]\tLoss: 1.306010\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-cc7c28b69d5f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Starting model test...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Model test completed!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-cc7c28b69d5f>\u001b[0m in \u001b[0;36mtest_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m# Train model for a few epochs as test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Starting test training...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mtrain_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;31m# Plot results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-a2775835ea6a>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m             \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m             \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-a2775835ea6a>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(self, epoch)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;31m# Backward and optimize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad_norm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munscale_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    624\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m             )\n\u001b[0;32m--> 626\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    627\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    824\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hoàn thành phần 1\n",
        "|\n",
        "|\n",
        "|\n",
        "|\n",
        "|\n",
        "|\n",
        "v\n",
        "Phần 2: Data Pipeline\n"
      ],
      "metadata": {
        "id": "-SOUiAg9tfTc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 12: Enhace Data Processing"
      ],
      "metadata": {
        "id": "xuhDkI5y5hVW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DataProcessor:\n",
        "    def __init__(self, data_path):\n",
        "        self.data_path = data_path\n",
        "        logger.info(f\"Initializing DataProcessor with path: {data_path}\")\n",
        "\n",
        "    def load_and_preprocess(self):\n",
        "        \"\"\"\n",
        "        Load và xử lý nâng cao cho dữ liệu METR-LA\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # Load data\n",
        "            df = pd.read_csv(os.path.join(self.data_path, 'metr-la.csv'), index_col=0)\n",
        "            df.index = pd.to_datetime(df.index)\n",
        "            sensor_df = pd.read_csv(os.path.join(self.data_path, 'sensor_locations.csv'))\n",
        "\n",
        "            # Fill missing values\n",
        "            df = self._handle_missing_values(df)\n",
        "\n",
        "            # Remove outliers\n",
        "            df = self._remove_outliers(df)\n",
        "\n",
        "            # Add time features\n",
        "            df = self._add_time_features(df)\n",
        "\n",
        "            logger.info(f\"Data processed successfully:\")\n",
        "            logger.info(f\"Shape: {df.shape}\")\n",
        "            logger.info(f\"Time range: {df.index[0]} to {df.index[-1]}\")\n",
        "\n",
        "            return df, sensor_df\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error in data processing: {e}\")\n",
        "            raise\n",
        "\n",
        "    def _handle_missing_values(self, df):\n",
        "        \"\"\"\n",
        "        Xử lý missing values với các phương pháp nâng cao\n",
        "        \"\"\"\n",
        "        # Calculate missing value statistics\n",
        "        missing_stats = df.isnull().sum()\n",
        "        logger.info(f\"Missing values before processing:\\n{missing_stats}\")\n",
        "\n",
        "        # Linear interpolation for small gaps\n",
        "        df = df.interpolate(method='linear', limit=6)\n",
        "\n",
        "        # Forward fill for remaining gaps\n",
        "        df = df.fillna(method='ffill', limit=24)\n",
        "\n",
        "        # Backward fill for any remaining values\n",
        "        df = df.fillna(method='bfill')\n",
        "\n",
        "        logger.info(\"Missing values handled\")\n",
        "        return df\n",
        "\n",
        "    def _remove_outliers(self, df):\n",
        "        \"\"\"\n",
        "        Loại bỏ outliers using IQR method\n",
        "        \"\"\"\n",
        "        Q1 = df.quantile(0.25)\n",
        "        Q3 = df.quantile(0.75)\n",
        "        IQR = Q3 - Q1\n",
        "\n",
        "        lower_bound = Q1 - 1.5 * IQR\n",
        "        upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "        # Replace outliers with boundary values\n",
        "        df = df.clip(lower=lower_bound, upper=upper_bound, axis=1)\n",
        "\n",
        "        logger.info(\"Outliers removed\")\n",
        "        return df\n",
        "\n",
        "    def _add_time_features(self, df):\n",
        "        \"\"\"\n",
        "        Thêm time-based features\n",
        "        \"\"\"\n",
        "        df['hour'] = df.index.hour\n",
        "        df['day_of_week'] = df.index.dayofweek\n",
        "        df['month'] = df.index.month\n",
        "        df['is_weekend'] = df.index.dayofweek.isin([5, 6]).astype(int)\n",
        "\n",
        "        logger.info(\"Time features added\")\n",
        "        return df"
      ],
      "metadata": {
        "id": "NAe_nLdFtfZZ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 13: Enhanced DataLoader với Data Augmentation"
      ],
      "metadata": {
        "id": "vejbjtDVtfeM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class EnhancedTrafficDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, data, seq_len, horizon, num_nodes, scaler, augment=False):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            data: pandas DataFrame\n",
        "            seq_len: input sequence length\n",
        "            horizon: prediction horizon\n",
        "            num_nodes: number of nodes/sensors\n",
        "            scaler: StandardScaler object\n",
        "            augment: whether to apply data augmentation\n",
        "        \"\"\"\n",
        "        self.data = data\n",
        "        self.seq_len = seq_len\n",
        "        self.horizon = horizon\n",
        "        self.num_nodes = num_nodes\n",
        "        self.scaler = scaler\n",
        "        self.augment = augment\n",
        "        self.samples = self._generate_samples()\n",
        "\n",
        "    def _generate_samples(self):\n",
        "        \"\"\"\n",
        "        Generate samples for training/testing\n",
        "        \"\"\"\n",
        "        num_samples = len(self.data) - self.seq_len - self.horizon + 1\n",
        "        samples = []\n",
        "        for i in range(num_samples):\n",
        "            x = self.data.iloc[i:i+self.seq_len].values\n",
        "            y = self.data.iloc[i+self.seq_len:i+self.seq_len+self.horizon].values\n",
        "\n",
        "            # Apply scaling\n",
        "            x = self.scaler.transform(x)\n",
        "            y = self.scaler.transform(y)\n",
        "\n",
        "            # Apply augmentation if enabled\n",
        "            if self.augment:\n",
        "                x, y = self._augment_data(x, y)\n",
        "\n",
        "            # Convert to tensors\n",
        "            x = torch.FloatTensor(x)\n",
        "            y = torch.FloatTensor(y)\n",
        "\n",
        "            samples.append((x, y))\n",
        "        return samples\n",
        "\n",
        "    def _augment_data(self, x, y):\n",
        "        \"\"\"\n",
        "        Apply data augmentation (e.g., random noise, scaling)\n",
        "        \"\"\"\n",
        "        # Example: Add random noise\n",
        "        noise_factor = 0.05\n",
        "        x += np.random.normal(scale=noise_factor, size=x.shape)\n",
        "        y += np.random.normal(scale=noise_factor, size=y.shape)\n",
        "        return x, y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.samples[idx]\n",
        "\n",
        "\n",
        "class DataPipeline:\n",
        "    def __init__(self, config):\n",
        "        self.config = config\n",
        "        self.processor = DataProcessor(config.data_path)\n",
        "\n",
        "    def create_data_loaders(self):\n",
        "        \"\"\"\n",
        "        Create enhanced data loaders with augmentation\n",
        "        \"\"\"\n",
        "        # Load and process data\n",
        "        df, sensor_df = self.processor.load_and_preprocess()\n",
        "\n",
        "        # Create scaler\n",
        "        scaler = StandardScaler()\n",
        "        scaler.fit(df.values)\n",
        "\n",
        "        # Split data\n",
        "        train_data, val_data, test_data = self._split_data(df)\n",
        "\n",
        "        # Create datasets\n",
        "        train_dataset = EnhancedTrafficDataset(\n",
        "            train_data,\n",
        "            self.config.seq_len,\n",
        "            self.config.horizon,\n",
        "            self.config.num_nodes,\n",
        "            scaler=scaler,\n",
        "            augment=True\n",
        "        )\n",
        "\n",
        "        val_dataset = EnhancedTrafficDataset(\n",
        "            val_data,\n",
        "            self.config.seq_len,\n",
        "            self.config.horizon,\n",
        "            self.config.num_nodes,\n",
        "            scaler=scaler,\n",
        "            augment=False\n",
        "        )\n",
        "\n",
        "        test_dataset = EnhancedTrafficDataset(\n",
        "            test_data,\n",
        "            self.config.seq_len,\n",
        "            self.config.horizon,\n",
        "            self.config.num_nodes,\n",
        "            scaler=scaler,\n",
        "            augment=False\n",
        "        )\n",
        "\n",
        "        # Create data loaders\n",
        "        train_loader = DataLoader(\n",
        "            train_dataset,\n",
        "            batch_size=self.config.batch_size,\n",
        "            shuffle=True,\n",
        "            num_workers=2,\n",
        "            pin_memory=True\n",
        "        )\n",
        "\n",
        "        val_loader = DataLoader(\n",
        "            val_dataset,\n",
        "            batch_size=self.config.batch_size,\n",
        "            shuffle=False,\n",
        "            num_workers=2\n",
        "        )\n",
        "\n",
        "        test_loader = DataLoader(\n",
        "            test_dataset,\n",
        "            batch_size=self.config.batch_size,\n",
        "            shuffle=False,\n",
        "            num_workers=2\n",
        "        )\n",
        "\n",
        "        return train_loader, val_loader, test_loader, scaler\n",
        "\n",
        "    def _split_data(self, df):\n",
        "        \"\"\"\n",
        "        Split data into train, validation, and test sets\n",
        "        \"\"\"\n",
        "        num_samples = len(df)\n",
        "        train_size = int(num_samples * 0.7)\n",
        "        val_size = int(num_samples * 0.1)\n",
        "\n",
        "        train_data = df[:train_size]\n",
        "        val_data = df[train_size:train_size+val_size]\n",
        "        test_data = df[train_size+val_size:]\n",
        "\n",
        "        return train_data, val_data, test_data"
      ],
      "metadata": {
        "id": "DrCrdyDPtfkQ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 14: Run Enhanced Data Pipeline"
      ],
      "metadata": {
        "id": "hv4MhJ5q5wqt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Update config with data path\n",
        "config.data_path = '/content/data'\n",
        "\n",
        "# Initialize and run pipeline\n",
        "pipeline = DataPipeline(config)\n",
        "train_loader, val_loader, test_loader, scaler = pipeline.create_data_loaders()\n",
        "\n",
        "# Print dataset statistics\n",
        "logger.info(\"\\nDataset Statistics:\")\n",
        "logger.info(f\"Training batches: {len(train_loader)}\")\n",
        "logger.info(f\"Validation batches: {len(val_loader)}\")\n",
        "logger.info(f\"Test batches: {len(test_loader)}\")\n",
        "\n",
        "# Test data augmentation\n",
        "sample_batch, sample_target = next(iter(train_loader))\n",
        "logger.info(f\"\\nSample batch shape: {sample_batch.shape}\")\n",
        "logger.info(f\"Sample target shape: {sample_target.shape}\")\n",
        "\n",
        "# Visualize augmented data\n",
        "def plot_augmented_samples(batch_data, num_samples=3):\n",
        "    plt.figure(figsize=(15, 5))\n",
        "    for i in range(num_samples):\n",
        "        plt.subplot(1, num_samples, i+1)\n",
        "        # Changed line to access correct dimension\n",
        "        plt.plot(batch_data[i, :, 0].numpy())\n",
        "        plt.title(f'Augmented Sample {i+1}')\n",
        "        plt.xlabel('Time Steps')\n",
        "        plt.ylabel('Traffic Flow')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('/content/results/augmented_samples.png')\n",
        "    plt.close()\n",
        "\n",
        "plot_augmented_samples(sample_batch)\n",
        "logger.info(\"Augmented samples visualization saved to /content/results/augmented_samples.png\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ba5aci15w35",
        "outputId": "91e19ff3-8ee6-402a-d071-f5ab36131816"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-05-02 10:07:27,212 - INFO - Initializing DataProcessor with path: /content/data\n",
            "INFO:AGCRN:Initializing DataProcessor with path: /content/data\n",
            "2025-05-02 10:07:28,457 - INFO - Missing values before processing:\n",
            "773869    0\n",
            "767541    0\n",
            "767542    0\n",
            "717447    0\n",
            "717446    0\n",
            "         ..\n",
            "717592    0\n",
            "717595    0\n",
            "772168    0\n",
            "718141    0\n",
            "769373    0\n",
            "Length: 207, dtype: int64\n",
            "INFO:AGCRN:Missing values before processing:\n",
            "773869    0\n",
            "767541    0\n",
            "767542    0\n",
            "717447    0\n",
            "717446    0\n",
            "         ..\n",
            "717592    0\n",
            "717595    0\n",
            "772168    0\n",
            "718141    0\n",
            "769373    0\n",
            "Length: 207, dtype: int64\n",
            "2025-05-02 10:07:28,662 - INFO - Missing values handled\n",
            "INFO:AGCRN:Missing values handled\n",
            "2025-05-02 10:07:29,997 - INFO - Outliers removed\n",
            "INFO:AGCRN:Outliers removed\n",
            "2025-05-02 10:07:30,041 - INFO - Time features added\n",
            "INFO:AGCRN:Time features added\n",
            "2025-05-02 10:07:30,047 - INFO - Data processed successfully:\n",
            "INFO:AGCRN:Data processed successfully:\n",
            "2025-05-02 10:07:30,051 - INFO - Shape: (34272, 211)\n",
            "INFO:AGCRN:Shape: (34272, 211)\n",
            "2025-05-02 10:07:30,058 - INFO - Time range: 2012-03-01 00:00:00 to 2012-06-27 23:55:00\n",
            "INFO:AGCRN:Time range: 2012-03-01 00:00:00 to 2012-06-27 23:55:00\n",
            "2025-05-02 10:08:00,596 - INFO - \n",
            "Dataset Statistics:\n",
            "INFO:AGCRN:\n",
            "Dataset Statistics:\n",
            "2025-05-02 10:08:00,598 - INFO - Training batches: 375\n",
            "INFO:AGCRN:Training batches: 375\n",
            "2025-05-02 10:08:00,599 - INFO - Validation batches: 54\n",
            "INFO:AGCRN:Validation batches: 54\n",
            "2025-05-02 10:08:00,601 - INFO - Test batches: 107\n",
            "INFO:AGCRN:Test batches: 107\n",
            "2025-05-02 10:08:00,817 - INFO - \n",
            "Sample batch shape: torch.Size([64, 12, 211])\n",
            "INFO:AGCRN:\n",
            "Sample batch shape: torch.Size([64, 12, 211])\n",
            "2025-05-02 10:08:00,821 - INFO - Sample target shape: torch.Size([64, 12, 211])\n",
            "INFO:AGCRN:Sample target shape: torch.Size([64, 12, 211])\n",
            "2025-05-02 10:08:01,345 - INFO - Augmented samples visualization saved to /content/results/augmented_samples.png\n",
            "INFO:AGCRN:Augmented samples visualization saved to /content/results/augmented_samples.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Phase 2: 2.1 Phân cụm và Fog**\n",
        "- HDBSCAN\n",
        "- Triển khai thuật toán phân cụm\n",
        "- Tối ưu hyperparameters\n",
        "- Visualization kết quả phân cụm\n"
      ],
      "metadata": {
        "id": "0zGvgG2G5w9z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 1: Import và Utilities"
      ],
      "metadata": {
        "id": "LEbGdJP4Ckcr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import hdbscan\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.colors import ListedColormap\n",
        "from tqdm import tqdm\n",
        "import logging\n",
        "\n",
        "logger = logging.getLogger('AGCRN.clustering')"
      ],
      "metadata": {
        "id": "6oDEg5Qr5xDL"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 2: Distance Calculator"
      ],
      "metadata": {
        "id": "ZlNC72GQ5xJp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DistanceCalculator:\n",
        "    def __init__(self):\n",
        "        self.R_e = 6371  # Earth radius in km\n",
        "\n",
        "    def haversine_distance(self, lat1, lon1, lat2, lon2):\n",
        "        \"\"\"Calculate Haversine distance between two points\"\"\"\n",
        "        lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\n",
        "        dlat = lat2 - lat1\n",
        "        dlon = lon2 - lon1\n",
        "        a = math.sin(dlat/2)**2 + math.cos(lat1) * math.cos(lat2) * math.sin(dlon/2)**2\n",
        "        c = 2 * math.asin(math.sqrt(a))\n",
        "        return self.R_e * c\n",
        "\n",
        "    def create_distance_matrix(self, coords):\n",
        "        \"\"\"Create distance matrix for all points\"\"\"\n",
        "        n = len(coords)\n",
        "        distances = np.zeros((n, n))\n",
        "        for i in range(n):\n",
        "            for j in range(i + 1, n):\n",
        "                dist = self.haversine_distance(\n",
        "                    coords[i][0], coords[i][1],\n",
        "                    coords[j][0], coords[j][1]\n",
        "                )\n",
        "                distances[i, j] = dist\n",
        "                distances[j, i] = dist\n",
        "        return distances"
      ],
      "metadata": {
        "id": "VUVH-KzN5xPq"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 3: HDBSCAN Clustering"
      ],
      "metadata": {
        "id": "e5BFOZ_d5xUy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TrafficClusterer:\n",
        "    def __init__(self, min_cluster_size=3, min_samples=2):\n",
        "        self.min_cluster_size = min_cluster_size\n",
        "        self.min_samples = min_samples\n",
        "        self.distance_calculator = DistanceCalculator()\n",
        "        self.clusterer = None\n",
        "        self.labels = None\n",
        "\n",
        "    def fit(self, location_df):\n",
        "        \"\"\"\n",
        "        Perform HDBSCAN clustering on sensor locations\n",
        "        \"\"\"\n",
        "        # Extract coordinates\n",
        "        coords = location_df[['latitude', 'longitude']].values\n",
        "\n",
        "        # Calculate distance matrix\n",
        "        logger.info(\"Calculating Haversine distance matrix...\")\n",
        "        distance_matrix = self.distance_calculator.create_distance_matrix(coords)\n",
        "\n",
        "        # Perform clustering\n",
        "        logger.info(\"Performing HDBSCAN clustering...\")\n",
        "        self.clusterer = hdbscan.HDBSCAN(\n",
        "            min_cluster_size=self.min_cluster_size,\n",
        "            min_samples=self.min_samples,\n",
        "            metric='precomputed'\n",
        "        )\n",
        "        self.labels = self.clusterer.fit_predict(distance_matrix)\n",
        "\n",
        "        # Add cluster labels to DataFrame\n",
        "        location_df['cluster'] = self.labels\n",
        "\n",
        "        # Assign noise points to nearest clusters\n",
        "        logger.info(\"Assigning noise points to nearest clusters...\")\n",
        "        location_df = self._assign_noise_points(location_df, coords)\n",
        "\n",
        "        return location_df\n",
        "\n",
        "    def _assign_noise_points(self, location_df, coords):\n",
        "        \"\"\"\n",
        "        Assign noise points (labeled as -1) to their nearest cluster\n",
        "        \"\"\"\n",
        "        # Get noise points\n",
        "        noise_points = location_df[location_df['cluster'] == -1]\n",
        "\n",
        "        if len(noise_points) > 0:\n",
        "            logger.info(f\"Found {len(noise_points)} noise points to assign\")\n",
        "\n",
        "            # Get cluster centers\n",
        "            cluster_centers = {}\n",
        "            for cluster_id in set(self.labels) - {-1}:\n",
        "                cluster_points = location_df[location_df['cluster'] == cluster_id]\n",
        "                cluster_centers[cluster_id] = (\n",
        "                    cluster_points['latitude'].mean(),\n",
        "                    cluster_points['longitude'].mean()\n",
        "                )\n",
        "\n",
        "            # Assign each noise point to nearest cluster\n",
        "            for idx in noise_points.index:\n",
        "                min_distance = float('inf')\n",
        "                nearest_cluster = None\n",
        "                point_lat = location_df.loc[idx, 'latitude']\n",
        "                point_lon = location_df.loc[idx, 'longitude']\n",
        "\n",
        "                # Find nearest cluster\n",
        "                for cluster_id, center in cluster_centers.items():\n",
        "                    dist = self.distance_calculator.haversine_distance(\n",
        "                        point_lat, point_lon,\n",
        "                        center[0], center[1]\n",
        "                    )\n",
        "                    if dist < min_distance:\n",
        "                        min_distance = dist\n",
        "                        nearest_cluster = cluster_id\n",
        "\n",
        "                # Assign to nearest cluster\n",
        "                if nearest_cluster is not None:\n",
        "                    location_df.loc[idx, 'cluster'] = nearest_cluster\n",
        "                    logger.info(f\"Assigned noise point {location_df.loc[idx, 'sensor_id']} \"\n",
        "                              f\"to cluster {nearest_cluster} (distance: {min_distance:.2f} km)\")\n",
        "\n",
        "        return location_df\n",
        "\n",
        "    def calculate_fog_nodes(self, location_df):\n",
        "        \"\"\"\n",
        "        Calculate Fog nodes for each cluster\n",
        "        \"\"\"\n",
        "        n_clusters = len(set(self.labels)) - (1 if -1 in self.labels else 0)\n",
        "        fog_nodes = []\n",
        "\n",
        "        logger.info(\"Calculating Fog nodes...\")\n",
        "        for cluster_id in range(n_clusters):\n",
        "            cluster_data = location_df[location_df['cluster'] == cluster_id]\n",
        "            if len(cluster_data) == 0:\n",
        "                continue\n",
        "\n",
        "            # Calculate cluster center\n",
        "            lat_center = cluster_data['latitude'].mean()\n",
        "            lon_center = cluster_data['longitude'].mean()\n",
        "            center = (lat_center, lon_center)\n",
        "\n",
        "            # Find nearest station to center\n",
        "            min_distance = float('inf')\n",
        "            nearest_station = None\n",
        "            for _, station in cluster_data.iterrows():\n",
        "                dist = self.distance_calculator.haversine_distance(\n",
        "                    station['latitude'],\n",
        "                    station['longitude'],\n",
        "                    center[0],\n",
        "                    center[1]\n",
        "                )\n",
        "                if dist < min_distance:\n",
        "                    min_distance = dist\n",
        "                    nearest_station = station\n",
        "\n",
        "            fog_nodes.append({\n",
        "                'cluster_id': cluster_id,\n",
        "                'latitude': nearest_station['latitude'],\n",
        "                'longitude': nearest_station['longitude'],\n",
        "                'num_stations': len(cluster_data),\n",
        "                'station_ids': cluster_data['sensor_id'].tolist(),\n",
        "                'center_distance': min_distance  # Added distance from center\n",
        "            })\n",
        "\n",
        "        return pd.DataFrame(fog_nodes)\n",
        "\n",
        "    def get_cluster_statistics(self, location_df):\n",
        "        \"\"\"\n",
        "        Get statistics about the clusters\n",
        "        \"\"\"\n",
        "        stats = {\n",
        "            'total_points': len(location_df),\n",
        "            'num_clusters': len(set(location_df['cluster'].unique())),\n",
        "            'cluster_sizes': location_df['cluster'].value_counts().to_dict(),\n",
        "            'avg_cluster_size': location_df['cluster'].value_counts().mean(),\n",
        "            'min_cluster_size': location_df['cluster'].value_counts().min(),\n",
        "            'max_cluster_size': location_df['cluster'].value_counts().max()\n",
        "        }\n",
        "\n",
        "        logger.info(\"Cluster Statistics:\")\n",
        "        for key, value in stats.items():\n",
        "            logger.info(f\"{key}: {value}\")\n",
        "\n",
        "        return stats"
      ],
      "metadata": {
        "id": "mVPYAxSk5xbI"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 4: Visualization"
      ],
      "metadata": {
        "id": "rXKjOd705xhC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ClusterVisualizer:\n",
        "    def __init__(self, save_dir='/content/results/clusters'):\n",
        "        self.save_dir = save_dir\n",
        "        os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "    def plot_clusters(self, location_df, fog_df):\n",
        "        \"\"\"\n",
        "        Plot clustering results with Fog nodes\n",
        "        \"\"\"\n",
        "        plt.figure(figsize=(12, 8))\n",
        "\n",
        "        # Plot clusters\n",
        "        unique_labels = set(location_df['cluster'])\n",
        "        colors = ListedColormap(plt.cm.Set1(np.linspace(0, 1, len(unique_labels))))\n",
        "\n",
        "        for i, label in enumerate(unique_labels):\n",
        "            cluster_data = location_df[location_df['cluster'] == label]\n",
        "            plt.scatter(\n",
        "                cluster_data['longitude'],\n",
        "                cluster_data['latitude'],\n",
        "                c=[colors.colors[i]],\n",
        "                s=50,\n",
        "                alpha=0.7,\n",
        "                label=f'Cluster {label}'\n",
        "            )\n",
        "\n",
        "        # Plot connections to Fog nodes\n",
        "        for _, station in location_df.iterrows():\n",
        "            cluster_id = station['cluster']\n",
        "            if cluster_id != -1:\n",
        "                fog_row = fog_df[fog_df['cluster_id'] == cluster_id]\n",
        "                if not fog_row.empty:\n",
        "                    fog_coords = fog_row[['longitude', 'latitude']].values[0]\n",
        "                    plt.plot(\n",
        "                        [station['longitude'], fog_coords[0]],\n",
        "                        [station['latitude'], fog_coords[1]],\n",
        "                        color='black',\n",
        "                        linestyle='--',\n",
        "                        linewidth=0.5,\n",
        "                        alpha=0.3\n",
        "                    )\n",
        "\n",
        "        # Plot Fog nodes\n",
        "        plt.scatter(\n",
        "            fog_df['longitude'],\n",
        "            fog_df['latitude'],\n",
        "            c='red',\n",
        "            marker='o',\n",
        "            s=60,\n",
        "            edgecolors='black',\n",
        "            label='Fog Nodes'\n",
        "        )\n",
        "\n",
        "        plt.title(\"Traffic Sensor Clustering (HDBSCAN)\")\n",
        "        plt.xlabel(\"Longitude\")\n",
        "        plt.ylabel(\"Latitude\")\n",
        "        plt.grid(True)\n",
        "        plt.legend(loc='best')\n",
        "\n",
        "        # Save plot\n",
        "        save_path = os.path.join(self.save_dir, 'traffic_clusters.png')\n",
        "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "        plt.close()\n",
        "\n",
        "        logger.info(f\"Clustering visualization saved to {save_path}\")"
      ],
      "metadata": {
        "id": "phfvOVR15xm1"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 5: Main Execution"
      ],
      "metadata": {
        "id": "m0GWf9C45xvO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    # Load sensor locations\n",
        "    location_df = pd.read_csv('/content/data/sensor_locations.csv')\n",
        "\n",
        "    # Initialize clusterer\n",
        "    clusterer = TrafficClusterer(min_cluster_size=3, min_samples=2)\n",
        "\n",
        "    # Perform clustering\n",
        "    location_df = clusterer.fit(location_df)\n",
        "\n",
        "    # Calculate Fog nodes\n",
        "    fog_df = clusterer.calculate_fog_nodes(location_df)\n",
        "\n",
        "    # Visualize results\n",
        "    visualizer = ClusterVisualizer()\n",
        "    visualizer.plot_clusters(location_df, fog_df)\n",
        "\n",
        "    # Save results\n",
        "    location_df.to_csv('/content/results/clusters/station_clusters.csv', index=False)\n",
        "    fog_df.to_csv('/content/results/clusters/fog_nodes.csv', index=False)\n",
        "\n",
        "    # Log summary\n",
        "    n_clusters = len(set(clusterer.labels)) - (1 if -1 in clusterer.labels else 0)\n",
        "    logger.info(f\"\\nClustering completed:\")\n",
        "    logger.info(f\"- Number of sensors: {len(location_df)}\")\n",
        "    logger.info(f\"- Number of clusters: {n_clusters}\")\n",
        "    logger.info(f\"- Number of Fog nodes: {len(fog_df)}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RQDwGCE85x1Q",
        "outputId": "d5844543-4631-4967-952e-8995db165b46"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-05-02 10:08:22,332 - INFO - Calculating Haversine distance matrix...\n",
            "INFO:AGCRN.clustering:Calculating Haversine distance matrix...\n",
            "2025-05-02 10:08:22,387 - INFO - Performing HDBSCAN clustering...\n",
            "INFO:AGCRN.clustering:Performing HDBSCAN clustering...\n",
            "2025-05-02 10:08:22,406 - INFO - Assigning noise points to nearest clusters...\n",
            "INFO:AGCRN.clustering:Assigning noise points to nearest clusters...\n",
            "2025-05-02 10:08:22,409 - INFO - Found 34 noise points to assign\n",
            "INFO:AGCRN.clustering:Found 34 noise points to assign\n",
            "2025-05-02 10:08:22,428 - INFO - Assigned noise point 717804 to cluster 18 (distance: 7.51 km)\n",
            "INFO:AGCRN.clustering:Assigned noise point 717804 to cluster 18 (distance: 7.51 km)\n",
            "2025-05-02 10:08:22,431 - INFO - Assigned noise point 767572 to cluster 33 (distance: 0.73 km)\n",
            "INFO:AGCRN.clustering:Assigned noise point 767572 to cluster 33 (distance: 0.73 km)\n",
            "2025-05-02 10:08:22,433 - INFO - Assigned noise point 767573 to cluster 33 (distance: 0.74 km)\n",
            "INFO:AGCRN.clustering:Assigned noise point 767573 to cluster 33 (distance: 0.74 km)\n",
            "2025-05-02 10:08:22,436 - INFO - Assigned noise point 774012 to cluster 32 (distance: 2.18 km)\n",
            "INFO:AGCRN.clustering:Assigned noise point 774012 to cluster 32 (distance: 2.18 km)\n",
            "2025-05-02 10:08:22,440 - INFO - Assigned noise point 774011 to cluster 32 (distance: 2.19 km)\n",
            "INFO:AGCRN.clustering:Assigned noise point 774011 to cluster 32 (distance: 2.19 km)\n",
            "2025-05-02 10:08:22,444 - INFO - Assigned noise point 767609 to cluster 1 (distance: 2.81 km)\n",
            "INFO:AGCRN.clustering:Assigned noise point 767609 to cluster 1 (distance: 2.81 km)\n",
            "2025-05-02 10:08:22,446 - INFO - Assigned noise point 767750 to cluster 14 (distance: 2.79 km)\n",
            "INFO:AGCRN.clustering:Assigned noise point 767750 to cluster 14 (distance: 2.79 km)\n",
            "2025-05-02 10:08:22,449 - INFO - Assigned noise point 767751 to cluster 14 (distance: 2.80 km)\n",
            "INFO:AGCRN.clustering:Assigned noise point 767751 to cluster 14 (distance: 2.80 km)\n",
            "2025-05-02 10:08:22,452 - INFO - Assigned noise point 767610 to cluster 1 (distance: 2.83 km)\n",
            "INFO:AGCRN.clustering:Assigned noise point 767610 to cluster 1 (distance: 2.83 km)\n",
            "2025-05-02 10:08:22,454 - INFO - Assigned noise point 717499 to cluster 13 (distance: 1.02 km)\n",
            "INFO:AGCRN.clustering:Assigned noise point 717499 to cluster 13 (distance: 1.02 km)\n",
            "2025-05-02 10:08:22,457 - INFO - Assigned noise point 718066 to cluster 25 (distance: 1.39 km)\n",
            "INFO:AGCRN.clustering:Assigned noise point 718066 to cluster 25 (distance: 1.39 km)\n",
            "2025-05-02 10:08:22,463 - INFO - Assigned noise point 769431 to cluster 18 (distance: 1.53 km)\n",
            "INFO:AGCRN.clustering:Assigned noise point 769431 to cluster 18 (distance: 1.53 km)\n",
            "2025-05-02 10:08:22,465 - INFO - Assigned noise point 769430 to cluster 18 (distance: 1.54 km)\n",
            "INFO:AGCRN.clustering:Assigned noise point 769430 to cluster 18 (distance: 1.54 km)\n",
            "2025-05-02 10:08:22,468 - INFO - Assigned noise point 767585 to cluster 17 (distance: 0.72 km)\n",
            "INFO:AGCRN.clustering:Assigned noise point 767585 to cluster 17 (distance: 0.72 km)\n",
            "2025-05-02 10:08:22,472 - INFO - Assigned noise point 718379 to cluster 31 (distance: 1.34 km)\n",
            "INFO:AGCRN.clustering:Assigned noise point 718379 to cluster 31 (distance: 1.34 km)\n",
            "2025-05-02 10:08:22,475 - INFO - Assigned noise point 717481 to cluster 29 (distance: 1.35 km)\n",
            "INFO:AGCRN.clustering:Assigned noise point 717481 to cluster 29 (distance: 1.35 km)\n",
            "2025-05-02 10:08:22,478 - INFO - Assigned noise point 717480 to cluster 29 (distance: 1.00 km)\n",
            "INFO:AGCRN.clustering:Assigned noise point 717480 to cluster 29 (distance: 1.00 km)\n",
            "2025-05-02 10:08:22,483 - INFO - Assigned noise point 761599 to cluster 31 (distance: 1.35 km)\n",
            "INFO:AGCRN.clustering:Assigned noise point 761599 to cluster 31 (distance: 1.35 km)\n",
            "2025-05-02 10:08:22,485 - INFO - Assigned noise point 716968 to cluster 30 (distance: 1.21 km)\n",
            "INFO:AGCRN.clustering:Assigned noise point 716968 to cluster 30 (distance: 1.21 km)\n",
            "2025-05-02 10:08:22,488 - INFO - Assigned noise point 717572 to cluster 24 (distance: 1.48 km)\n",
            "INFO:AGCRN.clustering:Assigned noise point 717572 to cluster 24 (distance: 1.48 km)\n",
            "2025-05-02 10:08:22,492 - INFO - Assigned noise point 718090 to cluster 31 (distance: 0.67 km)\n",
            "INFO:AGCRN.clustering:Assigned noise point 718090 to cluster 31 (distance: 0.67 km)\n",
            "2025-05-02 10:08:22,494 - INFO - Assigned noise point 717508 to cluster 6 (distance: 1.70 km)\n",
            "INFO:AGCRN.clustering:Assigned noise point 717508 to cluster 6 (distance: 1.70 km)\n",
            "2025-05-02 10:08:22,497 - INFO - Assigned noise point 773996 to cluster 32 (distance: 0.83 km)\n",
            "INFO:AGCRN.clustering:Assigned noise point 773996 to cluster 32 (distance: 0.83 km)\n",
            "2025-05-02 10:08:22,500 - INFO - Assigned noise point 773995 to cluster 32 (distance: 0.84 km)\n",
            "INFO:AGCRN.clustering:Assigned noise point 773995 to cluster 32 (distance: 0.84 km)\n",
            "2025-05-02 10:08:22,502 - INFO - Assigned noise point 717587 to cluster 22 (distance: 0.86 km)\n",
            "INFO:AGCRN.clustering:Assigned noise point 717587 to cluster 22 (distance: 0.86 km)\n",
            "2025-05-02 10:08:22,505 - INFO - Assigned noise point 717510 to cluster 6 (distance: 1.85 km)\n",
            "INFO:AGCRN.clustering:Assigned noise point 717510 to cluster 6 (distance: 1.85 km)\n",
            "2025-05-02 10:08:22,507 - INFO - Assigned noise point 717513 to cluster 6 (distance: 3.43 km)\n",
            "INFO:AGCRN.clustering:Assigned noise point 717513 to cluster 6 (distance: 3.43 km)\n",
            "2025-05-02 10:08:22,510 - INFO - Assigned noise point 717825 to cluster 4 (distance: 1.89 km)\n",
            "INFO:AGCRN.clustering:Assigned noise point 717825 to cluster 4 (distance: 1.89 km)\n",
            "2025-05-02 10:08:22,512 - INFO - Assigned noise point 717450 to cluster 27 (distance: 0.86 km)\n",
            "INFO:AGCRN.clustering:Assigned noise point 717450 to cluster 27 (distance: 0.86 km)\n",
            "2025-05-02 10:08:22,514 - INFO - Assigned noise point 717452 to cluster 27 (distance: 0.86 km)\n",
            "INFO:AGCRN.clustering:Assigned noise point 717452 to cluster 27 (distance: 0.86 km)\n",
            "2025-05-02 10:08:22,517 - INFO - Assigned noise point 717453 to cluster 23 (distance: 1.29 km)\n",
            "INFO:AGCRN.clustering:Assigned noise point 717453 to cluster 23 (distance: 1.29 km)\n",
            "2025-05-02 10:08:22,519 - INFO - Assigned noise point 759772 to cluster 24 (distance: 1.85 km)\n",
            "INFO:AGCRN.clustering:Assigned noise point 759772 to cluster 24 (distance: 1.85 km)\n",
            "2025-05-02 10:08:22,521 - INFO - Assigned noise point 717590 to cluster 32 (distance: 0.76 km)\n",
            "INFO:AGCRN.clustering:Assigned noise point 717590 to cluster 32 (distance: 0.76 km)\n",
            "2025-05-02 10:08:22,524 - INFO - Assigned noise point 717595 to cluster 32 (distance: 3.89 km)\n",
            "INFO:AGCRN.clustering:Assigned noise point 717595 to cluster 32 (distance: 3.89 km)\n",
            "2025-05-02 10:08:22,525 - INFO - Calculating Fog nodes...\n",
            "INFO:AGCRN.clustering:Calculating Fog nodes...\n",
            "2025-05-02 10:08:25,209 - INFO - Clustering visualization saved to /content/results/clusters/traffic_clusters.png\n",
            "INFO:AGCRN.clustering:Clustering visualization saved to /content/results/clusters/traffic_clusters.png\n",
            "2025-05-02 10:08:25,220 - INFO - \n",
            "Clustering completed:\n",
            "INFO:AGCRN.clustering:\n",
            "Clustering completed:\n",
            "2025-05-02 10:08:25,221 - INFO - - Number of sensors: 207\n",
            "INFO:AGCRN.clustering:- Number of sensors: 207\n",
            "2025-05-02 10:08:25,223 - INFO - - Number of clusters: 34\n",
            "INFO:AGCRN.clustering:- Number of clusters: 34\n",
            "2025-05-02 10:08:25,225 - INFO - - Number of Fog nodes: 34\n",
            "INFO:AGCRN.clustering:- Number of Fog nodes: 34\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2.2 Fog computing**\n",
        "- Xây dựng class Fognode\n",
        "- Triển khai fog alliance formation\n",
        "- Quản lý trạng thái nút"
      ],
      "metadata": {
        "id": "Cm70xVQL5x5s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 1: Fog Node Class"
      ],
      "metadata": {
        "id": "H1xB41ArD_yc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.colors import ListedColormap\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import logging\n",
        "\n",
        "logger = logging.getLogger('AGCRN.fog')\n",
        "\n",
        "# Kiểm tra và tạo thư mục kết quả\n",
        "os.makedirs('/content/results/fog', exist_ok=True)"
      ],
      "metadata": {
        "id": "3zOHS0rkUk5I"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FogNode:\n",
        "    def __init__(self, node_id, latitude, longitude, capacity=100):\n",
        "        self.node_id = node_id\n",
        "        self.latitude = latitude\n",
        "        self.longitude = longitude\n",
        "        self.capacity = capacity\n",
        "        self.current_load = 0\n",
        "        self.status = 'active'  # active, overloaded, inactive\n",
        "        self.sensors = []  # List of connected sensors\n",
        "        self.alliance_id = None\n",
        "        self.is_aggregator = False\n",
        "        self.neighbors = []  # Other fog nodes in the same alliance\n",
        "\n",
        "        logger.info(f\"FogNode {node_id} initialized at ({latitude}, {longitude})\")\n",
        "\n",
        "    def add_sensor(self, sensor_id):\n",
        "        \"\"\"Add a sensor to this fog node\"\"\"\n",
        "        if self.current_load < self.capacity:\n",
        "            self.sensors.append(sensor_id)\n",
        "            self.current_load += 1\n",
        "            self._update_status()\n",
        "            return True\n",
        "        return False\n",
        "\n",
        "    def remove_sensor(self, sensor_id):\n",
        "        \"\"\"Remove a sensor from this fog node\"\"\"\n",
        "        if sensor_id in self.sensors:\n",
        "            self.sensors.remove(sensor_id)\n",
        "            self.current_load -= 1\n",
        "            self._update_status()\n",
        "            return True\n",
        "        return False\n",
        "\n",
        "    def _update_status(self):\n",
        "        \"\"\"Update node status based on current load\"\"\"\n",
        "        load_ratio = self.current_load / self.capacity\n",
        "        if load_ratio >= 0.9:\n",
        "            self.status = 'overloaded'\n",
        "        elif load_ratio <= 0.1:\n",
        "            self.status = 'inactive'\n",
        "        else:\n",
        "            self.status = 'active'\n",
        "\n",
        "    def get_state(self):\n",
        "        \"\"\"Return current state of the fog node\"\"\"\n",
        "        return {\n",
        "            'node_id': self.node_id,\n",
        "            'location': (self.latitude, self.longitude),\n",
        "            'capacity': self.capacity,\n",
        "            'current_load': self.current_load,\n",
        "            'status': self.status,\n",
        "            'num_sensors': len(self.sensors),\n",
        "            'alliance_id': self.alliance_id,\n",
        "            'is_aggregator': self.is_aggregator\n",
        "        }"
      ],
      "metadata": {
        "id": "OU2-MDa95x_Y"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 2: Fog Alliance Manager"
      ],
      "metadata": {
        "id": "n7TZcCi25yD2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FogAllianceManager:\n",
        "    def __init__(self, max_distance=5):\n",
        "        self.max_distance = max_distance\n",
        "        self.fog_nodes = {}  # Dictionary of FogNode objects\n",
        "        self.alliances = {}  # Dictionary of alliance_id: [fog_node_ids]\n",
        "        self.aggregators = {}  # Dictionary of alliance_id: aggregator_node_id\n",
        "\n",
        "    def add_fog_node(self, node_id, latitude, longitude):\n",
        "        \"\"\"Add a new fog node to the network\"\"\"\n",
        "        self.fog_nodes[node_id] = FogNode(node_id, latitude, longitude)\n",
        "\n",
        "    def form_alliances(self, fog_df, n_clusters=None):\n",
        "        \"\"\"Form alliances using K-Means clustering\"\"\"\n",
        "        # Prepare coordinates for clustering\n",
        "        coords = fog_df[['latitude', 'longitude']].values\n",
        "        scaler = StandardScaler()\n",
        "        coords_scaled = scaler.fit_transform(coords)\n",
        "\n",
        "        # Determine number of clusters if not specified\n",
        "        if n_clusters is None:\n",
        "            n_clusters = max(1, len(fog_df) // 2)\n",
        "\n",
        "        # Perform K-Means clustering\n",
        "        kmeans = KMeans(n_clusters=n_clusters, random_state=0)\n",
        "        alliance_labels = kmeans.fit_predict(coords_scaled)\n",
        "        cluster_centers = scaler.inverse_transform(kmeans.cluster_centers_)\n",
        "\n",
        "        # Assign alliance IDs and find aggregators\n",
        "        for idx, row in fog_df.iterrows():\n",
        "            node_id = row['cluster_id']\n",
        "            alliance_id = alliance_labels[idx]\n",
        "\n",
        "            # Create alliance if it doesn't exist\n",
        "            if alliance_id not in self.alliances:\n",
        "                self.alliances[alliance_id] = []\n",
        "\n",
        "            # Add node to alliance\n",
        "            self.alliances[alliance_id].append(node_id)\n",
        "            self.fog_nodes[node_id].alliance_id = alliance_id\n",
        "\n",
        "            # Check if this node should be aggregator (closest to cluster center)\n",
        "            center_lat, center_lon = cluster_centers[alliance_id]\n",
        "            dist = self._haversine_distance(\n",
        "                row['latitude'], row['longitude'],\n",
        "                center_lat, center_lon\n",
        "            )\n",
        "\n",
        "            if alliance_id not in self.aggregators or dist < self._haversine_distance(\n",
        "                self.fog_nodes[self.aggregators[alliance_id]].latitude,\n",
        "                self.fog_nodes[self.aggregators[alliance_id]].longitude,\n",
        "                center_lat, center_lon\n",
        "            ):\n",
        "                self.aggregators[alliance_id] = node_id\n",
        "\n",
        "        # Set aggregator flags and update neighbors\n",
        "        for alliance_id, members in self.alliances.items():\n",
        "            aggregator_id = self.aggregators[alliance_id]\n",
        "            self.fog_nodes[aggregator_id].is_aggregator = True\n",
        "\n",
        "            # Set neighbors for each node in alliance\n",
        "            for node_id in members:\n",
        "                self.fog_nodes[node_id].neighbors = [\n",
        "                    m for m in members if m != node_id\n",
        "                ]\n",
        "\n",
        "        return self._create_alliance_graph()\n",
        "\n",
        "    def _haversine_distance(self, lat1, lon1, lat2, lon2):\n",
        "        \"\"\"Calculate Haversine distance between two points\"\"\"\n",
        "        R_e = 6371\n",
        "        lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\n",
        "        dlat = lat2 - lat1\n",
        "        dlon = lon2 - lon1\n",
        "        a = math.sin(dlat/2)**2 + math.cos(lat1) * math.cos(lat2) * math.sin(dlon/2)**2\n",
        "        c = 2 * math.asin(math.sqrt(a))\n",
        "        return R_e * c\n",
        "\n",
        "    def _create_alliance_graph(self):\n",
        "        \"\"\"Create a NetworkX graph of the alliance structure\"\"\"\n",
        "        G = nx.Graph()\n",
        "\n",
        "        # Add nodes\n",
        "        for node_id, fog_node in self.fog_nodes.items():\n",
        "            G.add_node(node_id,\n",
        "                      pos=(fog_node.longitude, fog_node.latitude),\n",
        "                      alliance_id=fog_node.alliance_id,\n",
        "                      is_aggregator=fog_node.is_aggregator)\n",
        "\n",
        "        # Add edges within alliances\n",
        "        for alliance_members in self.alliances.values():\n",
        "            aggregator = next(n for n in alliance_members\n",
        "                            if self.fog_nodes[n].is_aggregator)\n",
        "            for member in alliance_members:\n",
        "                if member != aggregator:\n",
        "                    G.add_edge(member, aggregator)\n",
        "\n",
        "        return G"
      ],
      "metadata": {
        "id": "CQMHsV2-5yJS"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 3: Visualization and State Management"
      ],
      "metadata": {
        "id": "B8XBoaQM5yOd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FogVisualizer:\n",
        "    def __init__(self, save_dir='/content/results/fog'):\n",
        "        self.save_dir = save_dir\n",
        "        os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "    def plot_alliance_graph(self, G, title=\"Fog Alliances\"):\n",
        "        \"\"\"Plot the alliance graph\"\"\"\n",
        "        plt.figure(figsize=(12, 8))\n",
        "\n",
        "        # Get node positions\n",
        "        pos = nx.get_node_attributes(G, 'pos')\n",
        "\n",
        "        # Color nodes by alliance\n",
        "        alliance_ids = [G.nodes[n]['alliance_id'] for n in G.nodes()]\n",
        "        unique_alliances = sorted(set(alliance_ids))\n",
        "        colors = plt.cm.Set1(np.linspace(0, 1, len(unique_alliances)))\n",
        "\n",
        "        # Draw regular nodes\n",
        "        nx.draw_networkx_nodes(G, pos,\n",
        "                             node_color=[colors[aid] for aid in alliance_ids],\n",
        "                             node_size=100,\n",
        "                             alpha=0.8)\n",
        "\n",
        "        # Draw aggregator nodes with different style\n",
        "        aggregators = [n for n in G.nodes() if G.nodes[n]['is_aggregator']]\n",
        "        nx.draw_networkx_nodes(G, pos,\n",
        "                             nodelist=aggregators,\n",
        "                             node_color='red',\n",
        "                             node_size=200,\n",
        "                             node_shape='s')\n",
        "\n",
        "        # Draw edges\n",
        "        nx.draw_networkx_edges(G, pos, alpha=0.5)\n",
        "\n",
        "        # Add labels\n",
        "        nx.draw_networkx_labels(G, pos, font_size=8)\n",
        "\n",
        "        plt.title(title)\n",
        "        plt.xlabel(\"Longitude\")\n",
        "        plt.ylabel(\"Latitude\")\n",
        "        plt.grid(True)\n",
        "\n",
        "        # Save plot\n",
        "        save_path = os.path.join(self.save_dir, 'fog_alliances.png')\n",
        "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "        plt.close()\n",
        "\n",
        "        logger.info(f\"Alliance graph saved to {save_path}\")"
      ],
      "metadata": {
        "id": "vMWYDwaP5yTb"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 4: Main Execution"
      ],
      "metadata": {
        "id": "jMEaiGXgEKRS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    # Load fog nodes from previous clustering\n",
        "    fog_df = pd.read_csv('/content/results/clusters/fog_nodes.csv')\n",
        "\n",
        "    # Initialize alliance manager\n",
        "    alliance_manager = FogAllianceManager(max_distance=5)\n",
        "\n",
        "    # Add fog nodes\n",
        "    for _, row in fog_df.iterrows():\n",
        "        alliance_manager.add_fog_node(\n",
        "            row['cluster_id'],\n",
        "            row['latitude'],\n",
        "            row['longitude']\n",
        "        )\n",
        "\n",
        "    # Form alliances\n",
        "    G = alliance_manager.form_alliances(fog_df, n_clusters=5)\n",
        "\n",
        "    # Visualize results\n",
        "    visualizer = FogVisualizer()\n",
        "    visualizer.plot_alliance_graph(G)\n",
        "\n",
        "    # Save alliance information\n",
        "    alliance_info = {\n",
        "        'alliances': alliance_manager.alliances,\n",
        "        'aggregators': alliance_manager.aggregators\n",
        "    }\n",
        "\n",
        "    with open('/content/results/fog/alliance_info.txt', 'w') as f:\n",
        "        f.write(\"Alliance Information:\\n\")\n",
        "        for alliance_id, members in alliance_info['alliances'].items():\n",
        "            f.write(f\"\\nAlliance {alliance_id}:\\n\")\n",
        "            f.write(f\"Aggregator: {alliance_info['aggregators'][alliance_id]}\\n\")\n",
        "            f.write(f\"Members: {members}\\n\")\n",
        "\n",
        "    logger.info(\"Fog computing setup completed successfully\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l_W33MKgEKYz",
        "outputId": "335c19a0-7ea9-4e8e-f329-b646ee7b8bc4"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-05-02 10:08:44,779 - INFO - FogNode 0 initialized at (34.20164, -118.40366)\n",
            "INFO:AGCRN.fog:FogNode 0 initialized at (34.20164, -118.40366)\n",
            "2025-05-02 10:08:44,781 - INFO - FogNode 1 initialized at (34.20663, -118.20101)\n",
            "INFO:AGCRN.fog:FogNode 1 initialized at (34.20663, -118.20101)\n",
            "2025-05-02 10:08:44,783 - INFO - FogNode 2 initialized at (34.21356, -118.23113)\n",
            "INFO:AGCRN.fog:FogNode 2 initialized at (34.21356, -118.23113)\n",
            "2025-05-02 10:08:44,784 - INFO - FogNode 3 initialized at (34.05767, -118.21435)\n",
            "INFO:AGCRN.fog:FogNode 3 initialized at (34.05767, -118.21435)\n",
            "2025-05-02 10:08:44,786 - INFO - FogNode 4 initialized at (34.21216, -118.47341)\n",
            "INFO:AGCRN.fog:FogNode 4 initialized at (34.21216, -118.47341)\n",
            "2025-05-02 10:08:44,788 - INFO - FogNode 5 initialized at (34.15367, -118.3484)\n",
            "INFO:AGCRN.fog:FogNode 5 initialized at (34.15367, -118.3484)\n",
            "2025-05-02 10:08:44,789 - INFO - FogNode 6 initialized at (34.17109, -118.50495)\n",
            "INFO:AGCRN.fog:FogNode 6 initialized at (34.17109, -118.50495)\n",
            "2025-05-02 10:08:44,791 - INFO - FogNode 7 initialized at (34.15133, -118.37456)\n",
            "INFO:AGCRN.fog:FogNode 7 initialized at (34.15133, -118.37456)\n",
            "2025-05-02 10:08:44,793 - INFO - FogNode 8 initialized at (34.17154, -118.38812)\n",
            "INFO:AGCRN.fog:FogNode 8 initialized at (34.17154, -118.38812)\n",
            "2025-05-02 10:08:44,795 - INFO - FogNode 9 initialized at (34.15664, -118.41326)\n",
            "INFO:AGCRN.fog:FogNode 9 initialized at (34.15664, -118.41326)\n",
            "2025-05-02 10:08:44,797 - INFO - FogNode 10 initialized at (34.18529, -118.47395)\n",
            "INFO:AGCRN.fog:FogNode 10 initialized at (34.18529, -118.47395)\n",
            "2025-05-02 10:08:44,798 - INFO - FogNode 11 initialized at (34.12121, -118.27164)\n",
            "INFO:AGCRN.fog:FogNode 11 initialized at (34.12121, -118.27164)\n",
            "2025-05-02 10:08:44,800 - INFO - FogNode 12 initialized at (34.05773, -118.24348)\n",
            "INFO:AGCRN.fog:FogNode 12 initialized at (34.05773, -118.24348)\n",
            "2025-05-02 10:08:44,801 - INFO - FogNode 13 initialized at (34.15574, -118.43931)\n",
            "INFO:AGCRN.fog:FogNode 13 initialized at (34.15574, -118.43931)\n",
            "2025-05-02 10:08:44,803 - INFO - FogNode 14 initialized at (34.08406, -118.22974)\n",
            "INFO:AGCRN.fog:FogNode 14 initialized at (34.08406, -118.22974)\n",
            "2025-05-02 10:08:44,804 - INFO - FogNode 15 initialized at (34.13338, -118.3535)\n",
            "INFO:AGCRN.fog:FogNode 15 initialized at (34.13338, -118.3535)\n",
            "2025-05-02 10:08:44,805 - INFO - FogNode 16 initialized at (34.11684, -118.33698)\n",
            "INFO:AGCRN.fog:FogNode 16 initialized at (34.11684, -118.33698)\n",
            "2025-05-02 10:08:44,807 - INFO - FogNode 17 initialized at (34.16339, -118.2253)\n",
            "INFO:AGCRN.fog:FogNode 17 initialized at (34.16339, -118.2253)\n",
            "2025-05-02 10:08:44,808 - INFO - FogNode 18 initialized at (34.15562, -118.4686)\n",
            "INFO:AGCRN.fog:FogNode 18 initialized at (34.15562, -118.4686)\n",
            "2025-05-02 10:08:44,810 - INFO - FogNode 19 initialized at (34.17091, -118.46775)\n",
            "INFO:AGCRN.fog:FogNode 19 initialized at (34.17091, -118.46775)\n",
            "2025-05-02 10:08:44,812 - INFO - FogNode 20 initialized at (34.10377, -118.24992)\n",
            "INFO:AGCRN.fog:FogNode 20 initialized at (34.10377, -118.24992)\n",
            "2025-05-02 10:08:44,813 - INFO - FogNode 21 initialized at (34.15597, -118.2666)\n",
            "INFO:AGCRN.fog:FogNode 21 initialized at (34.15597, -118.2666)\n",
            "2025-05-02 10:08:44,814 - INFO - FogNode 22 initialized at (34.15648, -118.24674)\n",
            "INFO:AGCRN.fog:FogNode 22 initialized at (34.15648, -118.24674)\n",
            "2025-05-02 10:08:44,816 - INFO - FogNode 23 initialized at (34.08102, -118.29325)\n",
            "INFO:AGCRN.fog:FogNode 23 initialized at (34.08102, -118.29325)\n",
            "2025-05-02 10:08:44,817 - INFO - FogNode 24 initialized at (34.15469, -118.31253)\n",
            "INFO:AGCRN.fog:FogNode 24 initialized at (34.15469, -118.31253)\n",
            "2025-05-02 10:08:44,818 - INFO - FogNode 25 initialized at (34.11641, -118.23819)\n",
            "INFO:AGCRN.fog:FogNode 25 initialized at (34.11641, -118.23819)\n",
            "2025-05-02 10:08:44,820 - INFO - FogNode 26 initialized at (34.06664, -118.25397)\n",
            "INFO:AGCRN.fog:FogNode 26 initialized at (34.06664, -118.25397)\n",
            "2025-05-02 10:08:44,821 - INFO - FogNode 27 initialized at (34.07248, -118.26772)\n",
            "INFO:AGCRN.fog:FogNode 27 initialized at (34.07248, -118.26772)\n",
            "2025-05-02 10:08:44,823 - INFO - FogNode 28 initialized at (34.09359, -118.30918)\n",
            "INFO:AGCRN.fog:FogNode 28 initialized at (34.09359, -118.30918)\n",
            "2025-05-02 10:08:44,824 - INFO - FogNode 29 initialized at (34.10262, -118.31747)\n",
            "INFO:AGCRN.fog:FogNode 29 initialized at (34.10262, -118.31747)\n",
            "2025-05-02 10:08:44,825 - INFO - FogNode 30 initialized at (34.15559, -118.2957)\n",
            "INFO:AGCRN.fog:FogNode 30 initialized at (34.15559, -118.2957)\n",
            "2025-05-02 10:08:44,827 - INFO - FogNode 31 initialized at (34.14847, -118.27969)\n",
            "INFO:AGCRN.fog:FogNode 31 initialized at (34.14847, -118.27969)\n",
            "2025-05-02 10:08:44,828 - INFO - FogNode 32 initialized at (34.14511, -118.21587)\n",
            "INFO:AGCRN.fog:FogNode 32 initialized at (34.14511, -118.21587)\n",
            "2025-05-02 10:08:44,829 - INFO - FogNode 33 initialized at (34.13486, -118.22932)\n",
            "INFO:AGCRN.fog:FogNode 33 initialized at (34.13486, -118.22932)\n",
            "2025-05-02 10:08:45,550 - INFO - Alliance graph saved to /content/results/fog/fog_alliances.png\n",
            "INFO:AGCRN.fog:Alliance graph saved to /content/results/fog/fog_alliances.png\n",
            "2025-05-02 10:08:45,554 - INFO - Fog computing setup completed successfully\n",
            "INFO:AGCRN.fog:Fog computing setup completed successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Phase 3: Decentralized Laerning ***\n",
        "3.1 Parameter sharing\n",
        "- Triển khai cơ chế chia sẻ\n",
        "- Bảo mật và mã hoá\n",
        "- xử lý lỗi và recovery"
      ],
      "metadata": {
        "id": "8YJ30XpeEKfe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 1: Import Libraries và Setup\n",
        "\n"
      ],
      "metadata": {
        "id": "nuvTrvgWFUZA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from cryptography.fernet import Fernet\n",
        "from base64 import b64encode, b64decode\n",
        "import json\n",
        "import hashlib\n",
        "import threading\n",
        "import queue\n",
        "import time\n",
        "from typing import Dict, List, Optional\n",
        "import logging\n",
        "\n",
        "logger = logging.getLogger('AGCRN.parameter_sharing')\n",
        "\n",
        "class ParameterSharingConfig:\n",
        "    def __init__(self):\n",
        "        self.encryption_key = Fernet.generate_key()\n",
        "        self.sharing_interval = 10  # seconds\n",
        "        self.retry_attempts = 3\n",
        "        self.timeout = 5  # seconds\n",
        "        self.min_participants = 2\n",
        "        self.recovery_mode = 'latest'  # 'latest' or 'average'\n",
        "\n",
        "        # Paths\n",
        "        self.checkpoint_dir = '/content/checkpoints/parameter_sharing'\n",
        "        os.makedirs(self.checkpoint_dir, exist_ok=True)\n",
        "\n",
        "        logger.info(\"Parameter sharing configuration initialized\")"
      ],
      "metadata": {
        "id": "r2S_d-kAEKmX"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 2: Security Manager"
      ],
      "metadata": {
        "id": "QU4knegcEKuD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SecurityManager:\n",
        "    def __init__(self, config: ParameterSharingConfig):\n",
        "        self.config = config\n",
        "        self.fernet = Fernet(config.encryption_key)\n",
        "\n",
        "    def encrypt_parameters(self, parameters: Dict[str, torch.Tensor]) -> bytes:\n",
        "        \"\"\"\n",
        "        Encrypt model parameters\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # Convert parameters to bytes\n",
        "            param_bytes = self._serialize_parameters(parameters)\n",
        "\n",
        "            # Add checksum\n",
        "            checksum = hashlib.sha256(param_bytes).digest()\n",
        "            data = checksum + param_bytes\n",
        "\n",
        "            # Encrypt\n",
        "            encrypted_data = self.fernet.encrypt(data)\n",
        "            logger.debug(\"Parameters encrypted successfully\")\n",
        "            return encrypted_data\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Encryption failed: {e}\")\n",
        "            raise\n",
        "\n",
        "    def decrypt_parameters(self, encrypted_data: bytes) -> Dict[str, torch.Tensor]:\n",
        "        \"\"\"\n",
        "        Decrypt and verify parameters\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # Decrypt\n",
        "            decrypted_data = self.fernet.decrypt(encrypted_data)\n",
        "\n",
        "            # Verify checksum\n",
        "            checksum = decrypted_data[:32]\n",
        "            param_bytes = decrypted_data[32:]\n",
        "            if hashlib.sha256(param_bytes).digest() != checksum:\n",
        "                raise ValueError(\"Checksum verification failed\")\n",
        "\n",
        "            # Deserialize parameters\n",
        "            parameters = self._deserialize_parameters(param_bytes)\n",
        "            logger.debug(\"Parameters decrypted and verified successfully\")\n",
        "            return parameters\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Decryption failed: {e}\")\n",
        "            raise\n",
        "\n",
        "    def _serialize_parameters(self, parameters: Dict[str, torch.Tensor]) -> bytes:\n",
        "        \"\"\"\n",
        "        Serialize parameters to bytes\n",
        "        \"\"\"\n",
        "        serialized = {}\n",
        "        for name, param in parameters.items():\n",
        "            serialized[name] = {\n",
        "                'data': b64encode(param.cpu().numpy().tobytes()).decode('utf-8'),\n",
        "                'shape': param.shape,\n",
        "                'dtype': str(param.dtype)\n",
        "            }\n",
        "        return json.dumps(serialized).encode('utf-8')\n",
        "\n",
        "    def _deserialize_parameters(self, param_bytes: bytes) -> Dict[str, torch.Tensor]:\n",
        "        \"\"\"\n",
        "        Deserialize parameters from bytes\n",
        "        \"\"\"\n",
        "        serialized = json.loads(param_bytes.decode('utf-8'))\n",
        "        parameters = {}\n",
        "        for name, param_data in serialized.items():\n",
        "            data = np.frombuffer(\n",
        "                b64decode(param_data['data']),\n",
        "                dtype=np.dtype(param_data['dtype'])\n",
        "            ).reshape(param_data['shape'])\n",
        "            parameters[name] = torch.from_numpy(data)\n",
        "        return parameters"
      ],
      "metadata": {
        "id": "eSphA2-DEK1w"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 3: Parameter Sharing Manager"
      ],
      "metadata": {
        "id": "miC0o_Y_EK84"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ParameterSharingManager:\n",
        "    def __init__(self, config: ParameterSharingConfig, security_manager: SecurityManager):\n",
        "        self.config = config\n",
        "        self.security_manager = security_manager\n",
        "        self.parameter_queue = queue.Queue()\n",
        "        self.shared_parameters = {}\n",
        "        self.sharing_lock = threading.Lock()\n",
        "        self.is_sharing = False\n",
        "        self.failed_attempts = {}\n",
        "\n",
        "    def start_sharing(self):\n",
        "        \"\"\"\n",
        "        Start parameter sharing process\n",
        "        \"\"\"\n",
        "        self.is_sharing = True\n",
        "        self.sharing_thread = threading.Thread(target=self._sharing_loop)\n",
        "        self.sharing_thread.daemon = True\n",
        "        self.sharing_thread.start()\n",
        "        logger.info(\"Parameter sharing started\")\n",
        "\n",
        "    def stop_sharing(self):\n",
        "        \"\"\"\n",
        "        Stop parameter sharing process\n",
        "        \"\"\"\n",
        "        self.is_sharing = False\n",
        "        self.sharing_thread.join()\n",
        "        logger.info(\"Parameter sharing stopped\")\n",
        "\n",
        "    def share_parameters(self, node_id: str, parameters: Dict[str, torch.Tensor]):\n",
        "        \"\"\"\n",
        "        Share parameters from a node\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # Encrypt parameters\n",
        "            encrypted_params = self.security_manager.encrypt_parameters(parameters)\n",
        "\n",
        "            # Add to queue\n",
        "            self.parameter_queue.put((node_id, encrypted_params))\n",
        "            logger.debug(f\"Parameters from node {node_id} queued for sharing\")\n",
        "\n",
        "            # Reset failed attempts\n",
        "            self.failed_attempts[node_id] = 0\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Failed to share parameters from node {node_id}: {e}\")\n",
        "            self._handle_failure(node_id)\n",
        "\n",
        "    def get_shared_parameters(self, node_id: str) -> Optional[Dict[str, torch.Tensor]]:\n",
        "        \"\"\"\n",
        "        Get latest shared parameters\n",
        "        \"\"\"\n",
        "        with self.sharing_lock:\n",
        "            if node_id in self.shared_parameters:\n",
        "                return self.shared_parameters[node_id]\n",
        "        return None\n",
        "\n",
        "    def _sharing_loop(self):\n",
        "        \"\"\"\n",
        "        Main parameter sharing loop\n",
        "        \"\"\"\n",
        "        while self.is_sharing:\n",
        "            try:\n",
        "                # Process queued parameters\n",
        "                while not self.parameter_queue.empty():\n",
        "                    node_id, encrypted_params = self.parameter_queue.get()\n",
        "                    self._process_parameters(node_id, encrypted_params)\n",
        "\n",
        "                # Checkpoint current state\n",
        "                self._save_checkpoint()\n",
        "\n",
        "                time.sleep(self.config.sharing_interval)\n",
        "\n",
        "            except Exception as e:\n",
        "                logger.error(f\"Error in sharing loop: {e}\")\n",
        "\n",
        "    def _process_parameters(self, node_id: str, encrypted_params: bytes):\n",
        "        \"\"\"\n",
        "        Process received parameters\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # Decrypt parameters\n",
        "            parameters = self.security_manager.decrypt_parameters(encrypted_params)\n",
        "\n",
        "            # Update shared parameters\n",
        "            with self.sharing_lock:\n",
        "                self.shared_parameters[node_id] = parameters\n",
        "\n",
        "            logger.debug(f\"Processed parameters from node {node_id}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Failed to process parameters from node {node_id}: {e}\")\n",
        "            self._handle_failure(node_id)\n",
        "\n",
        "    def _handle_failure(self, node_id: str):\n",
        "        \"\"\"\n",
        "        Handle parameter sharing failures\n",
        "        \"\"\"\n",
        "        self.failed_attempts[node_id] = self.failed_attempts.get(node_id, 0) + 1\n",
        "\n",
        "        if self.failed_attempts[node_id] >= self.config.retry_attempts:\n",
        "            logger.warning(f\"Node {node_id} exceeded maximum retry attempts\")\n",
        "            self._initiate_recovery(node_id)\n",
        "\n",
        "    def _initiate_recovery(self, node_id: str):\n",
        "        \"\"\"\n",
        "        Initiate recovery process for failed node\n",
        "        \"\"\"\n",
        "        try:\n",
        "            if self.config.recovery_mode == 'latest':\n",
        "                # Use latest successful parameters\n",
        "                self._recover_from_checkpoint(node_id)\n",
        "            else:\n",
        "                # Use average of other nodes' parameters\n",
        "                self._recover_from_average(node_id)\n",
        "\n",
        "            logger.info(f\"Recovery completed for node {node_id}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Recovery failed for node {node_id}: {e}\")\n",
        "\n",
        "    def _save_checkpoint(self):\n",
        "        \"\"\"\n",
        "        Save current state to checkpoint\n",
        "        \"\"\"\n",
        "        checkpoint_path = os.path.join(\n",
        "            self.config.checkpoint_dir,\n",
        "            f'sharing_checkpoint_{int(time.time())}.pt'\n",
        "        )\n",
        "\n",
        "        try:\n",
        "            with self.sharing_lock:\n",
        "                torch.save({\n",
        "                    'shared_parameters': self.shared_parameters,\n",
        "                    'failed_attempts': self.failed_attempts,\n",
        "                    'timestamp': time.time()\n",
        "                }, checkpoint_path)\n",
        "\n",
        "            logger.debug(f\"Checkpoint saved: {checkpoint_path}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Failed to save checkpoint: {e}\")"
      ],
      "metadata": {
        "id": "njg0hDtRELEI"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 4: Usage Example"
      ],
      "metadata": {
        "id": "tCto6fwhELLq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    # Initialize configuration\n",
        "    config = ParameterSharingConfig()\n",
        "\n",
        "    # Initialize security manager\n",
        "    security_manager = SecurityManager(config)\n",
        "\n",
        "    # Initialize parameter sharing manager\n",
        "    sharing_manager = ParameterSharingManager(config, security_manager)\n",
        "\n",
        "    # Start parameter sharing\n",
        "    sharing_manager.start_sharing()\n",
        "\n",
        "    try:\n",
        "        # Example: Share parameters from multiple nodes\n",
        "        for i in range(3):\n",
        "            # Simulate parameters from a node\n",
        "            parameters = {\n",
        "                'weight': torch.randn(64, 64),\n",
        "                'bias': torch.randn(64)\n",
        "            }\n",
        "\n",
        "            # Share parameters\n",
        "            sharing_manager.share_parameters(f'node_{i}', parameters)\n",
        "\n",
        "            # Get shared parameters\n",
        "            shared_params = sharing_manager.get_shared_parameters(f'node_{i}')\n",
        "            if shared_params is not None:\n",
        "                logger.info(f\"Retrieved parameters from node_{i}\")\n",
        "\n",
        "            time.sleep(2)\n",
        "\n",
        "    finally:\n",
        "        # Stop parameter sharing\n",
        "        sharing_manager.stop_sharing()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PDyPf8t2ELS8",
        "outputId": "ceb8c977-3071-49e0-8261-ea122884d0a3"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-05-02 10:09:02,961 - INFO - Parameter sharing configuration initialized\n",
            "INFO:AGCRN.parameter_sharing:Parameter sharing configuration initialized\n",
            "2025-05-02 10:09:02,966 - INFO - Parameter sharing started\n",
            "INFO:AGCRN.parameter_sharing:Parameter sharing started\n",
            "2025-05-02 10:09:12,965 - INFO - Parameter sharing stopped\n",
            "INFO:AGCRN.parameter_sharing:Parameter sharing stopped\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3.2 DFL Integration**\n",
        "- Tích hợp DFL với AGCRN\n",
        "- Cơ chế aggregation\n",
        "- Đồng bộ hoá mô hình"
      ],
      "metadata": {
        "id": "It1ADTmVELaD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 1: Imports và Cấu hình"
      ],
      "metadata": {
        "id": "eGgZQSpnGsoy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from typing import Dict, List, Optional\n",
        "from collections import OrderedDict\n",
        "import threading\n",
        "import time\n",
        "import copy\n",
        "import logging\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Set up device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Set up logging\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
        ")\n",
        "logger = logging.getLogger('AGCRN.dfl')\n",
        "\n",
        "class DFLConfig:\n",
        "    def __init__(self):\n",
        "        # DFL parameters\n",
        "        self.num_local_epochs = 5\n",
        "        self.num_rounds = 100\n",
        "        self.local_batch_size = 32\n",
        "        self.learning_rate = 0.001\n",
        "        self.min_clients = 2\n",
        "        self.aggregation_method = 'fedavg'\n",
        "        self.sync_interval = 10\n",
        "        self.timeout = 30\n",
        "\n",
        "        # Model parameters\n",
        "        self.seq_len = 12\n",
        "        self.horizon = 12\n",
        "        self.input_dim = 1\n",
        "        self.hidden_dim = 64\n",
        "        self.output_dim = 1\n",
        "        self.num_layers = 2\n",
        "        self.cheb_k = 2\n",
        "        self.embed_dim = 10\n",
        "\n",
        "        # Paths\n",
        "        self.model_dir = '/content/models/dfl'\n",
        "        os.makedirs(self.model_dir, exist_ok=True)\n",
        "\n",
        "        logger.info(\"DFL configuration initialized\")"
      ],
      "metadata": {
        "id": "HDAd6sncELhh"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 2: Dataset và Model State Management"
      ],
      "metadata": {
        "id": "g2R_zT4TELpB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TrafficDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, data, seq_len, horizon, num_nodes):\n",
        "        self.data = torch.FloatTensor(data)  # Shape: [time_steps, num_nodes]\n",
        "        self.seq_len = seq_len\n",
        "        self.horizon = horizon\n",
        "        self.num_nodes = num_nodes\n",
        "        self.samples = self._generate_samples()\n",
        "\n",
        "    def _generate_samples(self):\n",
        "        num_samples = len(self.data) - self.seq_len - self.horizon + 1\n",
        "        samples = []\n",
        "        for i in range(num_samples):\n",
        "            x = self.data[i:i+self.seq_len]  # Shape: [seq_len, num_nodes]\n",
        "            y = self.data[i+self.seq_len:i+self.seq_len+self.horizon]  # Shape: [horizon, num_nodes]\n",
        "            # Reshape x to [seq_len, num_nodes, 1]\n",
        "            x = x.unsqueeze(-1)\n",
        "            # Reshape y to [horizon, num_nodes, 1]\n",
        "            y = y.unsqueeze(-1)\n",
        "            samples.append((x, y))\n",
        "        return samples\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.samples[idx]\n",
        "\n",
        "class ModelState:\n",
        "    def __init__(self, model: nn.Module):\n",
        "        self.state_dict = OrderedDict({\n",
        "            k: v.clone().detach().cpu()\n",
        "            for k, v in model.state_dict().items()\n",
        "        })\n",
        "\n",
        "    def apply_to_model(self, model: nn.Module):\n",
        "        model.load_state_dict(self.state_dict)\n",
        "\n",
        "    @staticmethod\n",
        "    def aggregate_states(states: List['ModelState'], weights: Optional[List[float]] = None) -> 'ModelState':\n",
        "        if not states:\n",
        "            raise ValueError(\"No states to aggregate\")\n",
        "\n",
        "        if weights is None:\n",
        "            weights = [1.0 / len(states)] * len(states)\n",
        "\n",
        "        if len(weights) != len(states):\n",
        "            raise ValueError(\"Number of weights must match number of states\")\n",
        "\n",
        "        if not np.isclose(sum(weights), 1.0):\n",
        "            weights = [w / sum(weights) for w in weights]\n",
        "\n",
        "        aggregated_state = OrderedDict()\n",
        "        for key in states[0].state_dict.keys():\n",
        "            # Initialize with the first weighted state\n",
        "            aggregated_state[key] = states[0].state_dict[key] * weights[0]\n",
        "\n",
        "            # Add remaining weighted states\n",
        "            for state, weight in zip(states[1:], weights[1:]):\n",
        "                aggregated_state[key] += state.state_dict[key] * weight\n",
        "\n",
        "        result = ModelState(None)\n",
        "        result.state_dict = aggregated_state\n",
        "        return result"
      ],
      "metadata": {
        "id": "6U8fhBznELwU"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 3: Local Training Manager"
      ],
      "metadata": {
        "id": "GNleBpYXEL4P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LocalTrainingManager:\n",
        "    def __init__(self, model, optimizer, train_loader, config):\n",
        "        self.model = model\n",
        "        self.optimizer = optimizer\n",
        "        self.train_loader = train_loader\n",
        "        self.config = config\n",
        "        self.criterion = nn.MSELoss()\n",
        "        self.current_state = ModelState(model)\n",
        "\n",
        "    def train_local_epoch(self) -> float:\n",
        "        \"\"\"\n",
        "        Train model for one local epoch\n",
        "        \"\"\"\n",
        "        self.model.train()\n",
        "        total_loss = 0\n",
        "        num_batches = 0\n",
        "\n",
        "        for batch_idx, (data, target) in enumerate(self.train_loader):\n",
        "            # data shape: [batch_size, seq_len, num_nodes, 1]\n",
        "            # target shape: [batch_size, horizon, num_nodes, 1]\n",
        "            data = data.to(device)\n",
        "            target = target.to(device)\n",
        "\n",
        "            self.optimizer.zero_grad()\n",
        "            output = self.model(data)  # shape: [batch_size, horizon, num_nodes, 1]\n",
        "\n",
        "            loss = self.criterion(output, target)\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            num_batches += 1\n",
        "\n",
        "        avg_loss = total_loss / num_batches\n",
        "        # Update current state after training\n",
        "        self.current_state = ModelState(self.model)\n",
        "        logger.debug(f\"Local epoch completed with average loss: {avg_loss:.4f}\")\n",
        "        return avg_loss\n",
        "\n",
        "    def update_model(self, new_state: ModelState):\n",
        "        \"\"\"\n",
        "        Update local model with new state\n",
        "        \"\"\"\n",
        "        new_state.apply_to_model(self.model)\n",
        "        self.current_state = ModelState(self.model)"
      ],
      "metadata": {
        "id": "MXnfh_deEL_i"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 4: DFL Coordinator"
      ],
      "metadata": {
        "id": "4kRh7rcLEMG0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DFLCoordinator:\n",
        "    def __init__(self, config: DFLConfig):\n",
        "        self.config = config\n",
        "        self.clients: Dict[str, LocalTrainingManager] = {}\n",
        "        self.global_state: Optional[ModelState] = None\n",
        "        self._round = 0\n",
        "        self._lock = threading.Lock()\n",
        "\n",
        "    def add_client(self, client_id: str, client: LocalTrainingManager):\n",
        "        \"\"\"Add a client to the federation\"\"\"\n",
        "        self.clients[client_id] = client\n",
        "        if self.global_state is None:\n",
        "            self.global_state = ModelState(client.model)\n",
        "        logger.info(f\"Added client {client_id} to federation\")\n",
        "\n",
        "    def _train_client(self, client_id: str, client: LocalTrainingManager):\n",
        "        \"\"\"Train a single client for one round\"\"\"\n",
        "        try:\n",
        "            for _ in range(self.config.num_local_epochs):\n",
        "                loss = client.train_local_epoch()\n",
        "            logger.info(f\"Client {client_id} completed training with final loss: {loss:.4f}\")\n",
        "            return True\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Client {client_id} failed in round {self._round}: {str(e)}\")\n",
        "            return False\n",
        "\n",
        "    def _aggregate_models(self, successful_clients: Dict[str, LocalTrainingManager]):\n",
        "        \"\"\"Aggregate models from successful clients\"\"\"\n",
        "        if not successful_clients:\n",
        "            return None\n",
        "\n",
        "        states = [client.current_state for client in successful_clients.values()]\n",
        "        weights = [1.0 / len(successful_clients)] * len(successful_clients)\n",
        "\n",
        "        return ModelState.aggregate_states(states, weights)\n",
        "\n",
        "    def start_training(self):\n",
        "        \"\"\"Start federated learning process\"\"\"\n",
        "        logger.info(\"Started federated learning\")\n",
        "\n",
        "        for round_num in range(self.config.num_rounds):\n",
        "            self._round = round_num\n",
        "            logger.info(f\"Starting round {round_num}\")\n",
        "\n",
        "            # Train clients in parallel\n",
        "            successful_clients = {}\n",
        "            for client_id, client in self.clients.items():\n",
        "                if self._train_client(client_id, client):\n",
        "                    successful_clients[client_id] = client\n",
        "\n",
        "            # Check if we have enough successful clients\n",
        "            if len(successful_clients) < self.config.min_clients:\n",
        "                logger.warning(f\"Insufficient clients for round {round_num}\")\n",
        "                continue\n",
        "\n",
        "            # Aggregate models\n",
        "            new_global_state = self._aggregate_models(successful_clients)\n",
        "            if new_global_state is None:\n",
        "                continue\n",
        "\n",
        "            # Update global state\n",
        "            self.global_state = new_global_state\n",
        "\n",
        "            # Synchronize all clients\n",
        "            for client in self.clients.values():\n",
        "                client.update_model(self.global_state)\n",
        "\n",
        "            # Save checkpoint\n",
        "            if round_num % self.config.sync_interval == 0:\n",
        "                self._save_checkpoint(round_num)\n",
        "\n",
        "        logger.info(\"Federated learning completed\")\n",
        "\n",
        "    def _save_checkpoint(self, round_num: int):\n",
        "        \"\"\"Save checkpoint of global model\"\"\"\n",
        "        checkpoint_path = os.path.join(self.config.model_dir, f'checkpoint_round_{round_num}.pt')\n",
        "        torch.save(self.global_state.state_dict, checkpoint_path)\n",
        "        logger.info(f\"Saved checkpoint for round {round_num}\")"
      ],
      "metadata": {
        "id": "fgFHMOkrEMN6"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 5: Data Loading Functions"
      ],
      "metadata": {
        "id": "yJvpw8aYGEkC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_fog_nodes():\n",
        "    \"\"\"\n",
        "    Load fog nodes from saved results\n",
        "    \"\"\"\n",
        "    try:\n",
        "        fog_nodes_path = '/content/results/clusters/fog_nodes.csv'\n",
        "        fog_df = pd.read_csv(fog_nodes_path)\n",
        "\n",
        "        fog_nodes = {}\n",
        "        for _, row in fog_df.iterrows():\n",
        "            fog_nodes[str(row['cluster_id'])] = {\n",
        "                'latitude': row['latitude'],\n",
        "                'longitude': row['longitude'],\n",
        "                'num_stations': row['num_stations'],\n",
        "                'station_ids': eval(row['station_ids']) if isinstance(row['station_ids'], str) else row['station_ids']\n",
        "            }\n",
        "\n",
        "        logger.info(f\"Loaded {len(fog_nodes)} fog nodes\")\n",
        "        return fog_nodes\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Failed to load fog nodes: {e}\")\n",
        "        raise\n",
        "\n",
        "def prepare_data_loaders(fog_nodes, config):\n",
        "    \"\"\"\n",
        "    Prepare data loaders for each fog node\n",
        "    \"\"\"\n",
        "    try:\n",
        "        data_path = '/content/data/metr-la.csv'\n",
        "        df = pd.read_csv(data_path, index_col=0)\n",
        "\n",
        "        df.columns = df.columns.astype(str)\n",
        "        logger.info(f\"Data loaded with shape: {df.shape}\")\n",
        "        logger.info(f\"Sample columns: {list(df.columns[:5])}\")\n",
        "\n",
        "        train_loaders = {}\n",
        "        for node_id, node_info in fog_nodes.items():\n",
        "            station_ids = [str(sid) for sid in node_info['station_ids']]\n",
        "            valid_stations = [sid for sid in station_ids if sid in df.columns]\n",
        "\n",
        "            if not valid_stations:\n",
        "                logger.warning(f\"No valid stations found for node {node_id}\")\n",
        "                continue\n",
        "\n",
        "            node_data = df[valid_stations]\n",
        "\n",
        "            dataset = TrafficDataset(\n",
        "                data=node_data.values,\n",
        "                seq_len=config.seq_len,\n",
        "                horizon=config.horizon,\n",
        "                num_nodes=len(valid_stations)\n",
        "            )\n",
        "\n",
        "            train_loaders[node_id] = DataLoader(\n",
        "                dataset,\n",
        "                batch_size=config.local_batch_size,\n",
        "                shuffle=True,\n",
        "                num_workers=2,\n",
        "                pin_memory=True if torch.cuda.is_available() else False\n",
        "            )\n",
        "\n",
        "            logger.info(f\"Created dataloader for node {node_id} with {len(valid_stations)} stations\")\n",
        "\n",
        "        if not train_loaders:\n",
        "            raise ValueError(\"No valid data loaders could be created\")\n",
        "\n",
        "        logger.info(f\"Prepared data loaders for {len(train_loaders)} fog nodes\")\n",
        "        return train_loaders\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Failed to prepare data loaders: {e}\")\n",
        "        logger.error(f\"Data info: {df.shape if 'df' in locals() else 'Not loaded'}\")\n",
        "        logger.error(f\"Sample stations: {next(iter(fog_nodes.values()))['station_ids'][:5]}\")\n",
        "        raise"
      ],
      "metadata": {
        "id": "cfV9Z9hoGEsq"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 6: Model Setup and Main"
      ],
      "metadata": {
        "id": "XqOMEiZQb57R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def setup_dfl_with_agcrn(fog_nodes, train_loaders, config):\n",
        "    \"\"\"\n",
        "    Setup DFL system with AGCRN models for each fog node\n",
        "    \"\"\"\n",
        "    dfl_coordinator = DFLCoordinator(config)\n",
        "\n",
        "    for node_id, fog_node in fog_nodes.items():\n",
        "        if node_id not in train_loaders:\n",
        "            continue\n",
        "\n",
        "        num_nodes = len(fog_node['station_ids'])\n",
        "\n",
        "        model = AGCRN(\n",
        "            num_nodes=num_nodes,\n",
        "            input_dim=1,\n",
        "            hidden_dim=config.hidden_dim,\n",
        "            output_dim=1,\n",
        "            horizon=config.horizon,\n",
        "            num_layers=config.num_layers,\n",
        "            cheb_k=config.cheb_k,\n",
        "            embed_dim=config.embed_dim\n",
        "        ).to(device)\n",
        "\n",
        "        optimizer = torch.optim.Adam(\n",
        "            model.parameters(),\n",
        "            lr=config.learning_rate\n",
        "        )\n",
        "\n",
        "        client = LocalTrainingManager(\n",
        "            model=model,\n",
        "            optimizer=optimizer,\n",
        "            train_loader=train_loaders[node_id],\n",
        "            config=config\n",
        "        )\n",
        "\n",
        "        dfl_coordinator.add_client(node_id, client)\n",
        "        logger.info(f\"Added client {node_id} with {num_nodes} nodes\")\n",
        "\n",
        "    return dfl_coordinator\n",
        "\n",
        "def main():\n",
        "    # Load configuration\n",
        "    config = DFLConfig()\n",
        "\n",
        "    # Setup data and fog nodes\n",
        "    fog_nodes = load_fog_nodes()\n",
        "    train_loaders = prepare_data_loaders(fog_nodes, config)\n",
        "\n",
        "    # Setup DFL system\n",
        "    coordinator = setup_dfl_with_agcrn(fog_nodes, train_loaders, config)\n",
        "\n",
        "    # Start federated learning\n",
        "    coordinator.start_training()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "dxk9pAQ0b6Ek",
        "outputId": "651c83d9-3a72-41ad-c254-c64641bd338f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-05-02 10:09:38,466 - INFO - DFL configuration initialized\n",
            "INFO:AGCRN.dfl:DFL configuration initialized\n",
            "2025-05-02 10:09:38,476 - INFO - Loaded 34 fog nodes\n",
            "INFO:AGCRN.dfl:Loaded 34 fog nodes\n",
            "2025-05-02 10:09:39,730 - INFO - Data loaded with shape: (34272, 207)\n",
            "INFO:AGCRN.dfl:Data loaded with shape: (34272, 207)\n",
            "2025-05-02 10:09:39,732 - INFO - Sample columns: ['773869', '767541', '767542', '717447', '717446']\n",
            "INFO:AGCRN.dfl:Sample columns: ['773869', '767541', '767542', '717447', '717446']\n",
            "2025-05-02 10:09:40,142 - INFO - Created dataloader for node 0 with 3 stations\n",
            "INFO:AGCRN.dfl:Created dataloader for node 0 with 3 stations\n",
            "2025-05-02 10:09:41,015 - INFO - Created dataloader for node 1 with 7 stations\n",
            "INFO:AGCRN.dfl:Created dataloader for node 1 with 7 stations\n",
            "2025-05-02 10:09:41,645 - INFO - Created dataloader for node 2 with 3 stations\n",
            "INFO:AGCRN.dfl:Created dataloader for node 2 with 3 stations\n",
            "2025-05-02 10:09:42,750 - INFO - Created dataloader for node 3 with 4 stations\n",
            "INFO:AGCRN.dfl:Created dataloader for node 3 with 4 stations\n",
            "2025-05-02 10:09:43,280 - INFO - Created dataloader for node 4 with 5 stations\n",
            "INFO:AGCRN.dfl:Created dataloader for node 4 with 5 stations\n",
            "2025-05-02 10:09:43,722 - INFO - Created dataloader for node 5 with 6 stations\n",
            "INFO:AGCRN.dfl:Created dataloader for node 5 with 6 stations\n",
            "2025-05-02 10:09:44,574 - INFO - Created dataloader for node 6 with 8 stations\n",
            "INFO:AGCRN.dfl:Created dataloader for node 6 with 8 stations\n",
            "2025-05-02 10:09:45,037 - INFO - Created dataloader for node 7 with 7 stations\n",
            "INFO:AGCRN.dfl:Created dataloader for node 7 with 7 stations\n",
            "2025-05-02 10:09:45,497 - INFO - Created dataloader for node 8 with 6 stations\n",
            "INFO:AGCRN.dfl:Created dataloader for node 8 with 6 stations\n",
            "2025-05-02 10:09:46,467 - INFO - Created dataloader for node 9 with 8 stations\n",
            "INFO:AGCRN.dfl:Created dataloader for node 9 with 8 stations\n",
            "2025-05-02 10:09:46,918 - INFO - Created dataloader for node 10 with 5 stations\n",
            "INFO:AGCRN.dfl:Created dataloader for node 10 with 5 stations\n",
            "2025-05-02 10:09:47,408 - INFO - Created dataloader for node 11 with 5 stations\n",
            "INFO:AGCRN.dfl:Created dataloader for node 11 with 5 stations\n",
            "2025-05-02 10:09:47,867 - INFO - Created dataloader for node 12 with 3 stations\n",
            "INFO:AGCRN.dfl:Created dataloader for node 12 with 3 stations\n",
            "2025-05-02 10:09:48,976 - INFO - Created dataloader for node 13 with 4 stations\n",
            "INFO:AGCRN.dfl:Created dataloader for node 13 with 4 stations\n",
            "2025-05-02 10:09:49,471 - INFO - Created dataloader for node 14 with 15 stations\n",
            "INFO:AGCRN.dfl:Created dataloader for node 14 with 15 stations\n",
            "2025-05-02 10:09:49,927 - INFO - Created dataloader for node 15 with 10 stations\n",
            "INFO:AGCRN.dfl:Created dataloader for node 15 with 10 stations\n",
            "2025-05-02 10:09:50,388 - INFO - Created dataloader for node 16 with 4 stations\n",
            "INFO:AGCRN.dfl:Created dataloader for node 16 with 4 stations\n",
            "2025-05-02 10:09:50,853 - INFO - Created dataloader for node 17 with 4 stations\n",
            "INFO:AGCRN.dfl:Created dataloader for node 17 with 4 stations\n",
            "2025-05-02 10:09:52,121 - INFO - Created dataloader for node 18 with 12 stations\n",
            "INFO:AGCRN.dfl:Created dataloader for node 18 with 12 stations\n",
            "2025-05-02 10:09:52,594 - INFO - Created dataloader for node 19 with 3 stations\n",
            "INFO:AGCRN.dfl:Created dataloader for node 19 with 3 stations\n",
            "2025-05-02 10:09:53,049 - INFO - Created dataloader for node 20 with 3 stations\n",
            "INFO:AGCRN.dfl:Created dataloader for node 20 with 3 stations\n",
            "2025-05-02 10:09:53,726 - INFO - Created dataloader for node 21 with 4 stations\n",
            "INFO:AGCRN.dfl:Created dataloader for node 21 with 4 stations\n",
            "2025-05-02 10:09:54,397 - INFO - Created dataloader for node 22 with 4 stations\n",
            "INFO:AGCRN.dfl:Created dataloader for node 22 with 4 stations\n",
            "2025-05-02 10:09:55,068 - INFO - Created dataloader for node 23 with 9 stations\n",
            "INFO:AGCRN.dfl:Created dataloader for node 23 with 9 stations\n",
            "2025-05-02 10:09:56,632 - INFO - Created dataloader for node 24 with 8 stations\n",
            "INFO:AGCRN.dfl:Created dataloader for node 24 with 8 stations\n",
            "2025-05-02 10:09:57,032 - INFO - Created dataloader for node 25 with 7 stations\n",
            "INFO:AGCRN.dfl:Created dataloader for node 25 with 7 stations\n",
            "2025-05-02 10:09:57,434 - INFO - Created dataloader for node 26 with 4 stations\n",
            "INFO:AGCRN.dfl:Created dataloader for node 26 with 4 stations\n",
            "2025-05-02 10:09:57,853 - INFO - Created dataloader for node 27 with 5 stations\n",
            "INFO:AGCRN.dfl:Created dataloader for node 27 with 5 stations\n",
            "2025-05-02 10:09:58,289 - INFO - Created dataloader for node 28 with 4 stations\n",
            "INFO:AGCRN.dfl:Created dataloader for node 28 with 4 stations\n",
            "2025-05-02 10:09:58,745 - INFO - Created dataloader for node 29 with 8 stations\n",
            "INFO:AGCRN.dfl:Created dataloader for node 29 with 8 stations\n",
            "2025-05-02 10:09:59,220 - INFO - Created dataloader for node 30 with 5 stations\n",
            "INFO:AGCRN.dfl:Created dataloader for node 30 with 5 stations\n",
            "2025-05-02 10:09:59,681 - INFO - Created dataloader for node 31 with 7 stations\n",
            "INFO:AGCRN.dfl:Created dataloader for node 31 with 7 stations\n",
            "2025-05-02 10:10:01,336 - INFO - Created dataloader for node 32 with 12 stations\n",
            "INFO:AGCRN.dfl:Created dataloader for node 32 with 12 stations\n",
            "2025-05-02 10:10:01,788 - INFO - Created dataloader for node 33 with 5 stations\n",
            "INFO:AGCRN.dfl:Created dataloader for node 33 with 5 stations\n",
            "2025-05-02 10:10:01,790 - INFO - Prepared data loaders for 34 fog nodes\n",
            "INFO:AGCRN.dfl:Prepared data loaders for 34 fog nodes\n",
            "2025-05-02 10:10:01,797 - INFO - AVWGCN initialized with dim_in=65, dim_out=128, cheb_k=2\n",
            "INFO:AGCRN.dfl:AVWGCN initialized with dim_in=65, dim_out=128, cheb_k=2\n",
            "2025-05-02 10:10:01,801 - INFO - AVWGCN initialized with dim_in=65, dim_out=64, cheb_k=2\n",
            "INFO:AGCRN.dfl:AVWGCN initialized with dim_in=65, dim_out=64, cheb_k=2\n",
            "2025-05-02 10:10:01,803 - INFO - AGCRNCell initialized with node_num=3, dim_in=1, dim_out=64\n",
            "INFO:AGCRN.dfl:AGCRNCell initialized with node_num=3, dim_in=1, dim_out=64\n",
            "2025-05-02 10:10:01,810 - INFO - AVWGCN initialized with dim_in=128, dim_out=128, cheb_k=2\n",
            "INFO:AGCRN.dfl:AVWGCN initialized with dim_in=128, dim_out=128, cheb_k=2\n",
            "2025-05-02 10:10:01,815 - INFO - AVWGCN initialized with dim_in=128, dim_out=64, cheb_k=2\n",
            "INFO:AGCRN.dfl:AVWGCN initialized with dim_in=128, dim_out=64, cheb_k=2\n",
            "2025-05-02 10:10:01,816 - INFO - AGCRNCell initialized with node_num=3, dim_in=64, dim_out=64\n",
            "INFO:AGCRN.dfl:AGCRNCell initialized with node_num=3, dim_in=64, dim_out=64\n",
            "2025-05-02 10:10:01,819 - INFO - AGCRN initialized with 2 layers\n",
            "INFO:AGCRN.dfl:AGCRN initialized with 2 layers\n",
            "2025-05-02 10:10:01,825 - INFO - Added client 0 to federation\n",
            "INFO:AGCRN.dfl:Added client 0 to federation\n",
            "2025-05-02 10:10:01,827 - INFO - Added client 0 with 3 nodes\n",
            "INFO:AGCRN.dfl:Added client 0 with 3 nodes\n",
            "2025-05-02 10:10:01,831 - INFO - AVWGCN initialized with dim_in=65, dim_out=128, cheb_k=2\n",
            "INFO:AGCRN.dfl:AVWGCN initialized with dim_in=65, dim_out=128, cheb_k=2\n",
            "2025-05-02 10:10:01,835 - INFO - AVWGCN initialized with dim_in=65, dim_out=64, cheb_k=2\n",
            "INFO:AGCRN.dfl:AVWGCN initialized with dim_in=65, dim_out=64, cheb_k=2\n",
            "2025-05-02 10:10:01,837 - INFO - AGCRNCell initialized with node_num=7, dim_in=1, dim_out=64\n",
            "INFO:AGCRN.dfl:AGCRNCell initialized with node_num=7, dim_in=1, dim_out=64\n",
            "2025-05-02 10:10:01,843 - INFO - AVWGCN initialized with dim_in=128, dim_out=128, cheb_k=2\n",
            "INFO:AGCRN.dfl:AVWGCN initialized with dim_in=128, dim_out=128, cheb_k=2\n",
            "2025-05-02 10:10:01,848 - INFO - AVWGCN initialized with dim_in=128, dim_out=64, cheb_k=2\n",
            "INFO:AGCRN.dfl:AVWGCN initialized with dim_in=128, dim_out=64, cheb_k=2\n",
            "2025-05-02 10:10:01,851 - INFO - AGCRNCell initialized with node_num=7, dim_in=64, dim_out=64\n",
            "INFO:AGCRN.dfl:AGCRNCell initialized with node_num=7, dim_in=64, dim_out=64\n",
            "2025-05-02 10:10:01,853 - INFO - AGCRN initialized with 2 layers\n",
            "INFO:AGCRN.dfl:AGCRN initialized with 2 layers\n",
            "2025-05-02 10:10:01,857 - INFO - Added client 1 to federation\n",
            "INFO:AGCRN.dfl:Added client 1 to federation\n",
            "2025-05-02 10:10:01,859 - INFO - Added client 1 with 7 nodes\n",
            "INFO:AGCRN.dfl:Added client 1 with 7 nodes\n",
            "2025-05-02 10:10:01,864 - INFO - AVWGCN initialized with dim_in=65, dim_out=128, cheb_k=2\n",
            "INFO:AGCRN.dfl:AVWGCN initialized with dim_in=65, dim_out=128, cheb_k=2\n",
            "2025-05-02 10:10:01,867 - INFO - AVWGCN initialized with dim_in=65, dim_out=64, cheb_k=2\n",
            "INFO:AGCRN.dfl:AVWGCN initialized with dim_in=65, dim_out=64, cheb_k=2\n",
            "2025-05-02 10:10:01,869 - INFO - AGCRNCell initialized with node_num=3, dim_in=1, dim_out=64\n",
            "INFO:AGCRN.dfl:AGCRNCell initialized with node_num=3, dim_in=1, dim_out=64\n",
            "2025-05-02 10:10:01,875 - INFO - AVWGCN initialized with dim_in=128, dim_out=128, cheb_k=2\n",
            "INFO:AGCRN.dfl:AVWGCN initialized with dim_in=128, dim_out=128, cheb_k=2\n",
            "2025-05-02 10:10:01,880 - INFO - AVWGCN initialized with dim_in=128, dim_out=64, cheb_k=2\n",
            "INFO:AGCRN.dfl:AVWGCN initialized with dim_in=128, dim_out=64, cheb_k=2\n",
            "2025-05-02 10:10:01,882 - INFO - AGCRNCell initialized with node_num=3, dim_in=64, dim_out=64\n",
            "INFO:AGCRN.dfl:AGCRNCell initialized with node_num=3, dim_in=64, dim_out=64\n",
            "2025-05-02 10:10:01,883 - INFO - AGCRN initialized with 2 layers\n",
            "INFO:AGCRN.dfl:AGCRN initialized with 2 layers\n",
            "2025-05-02 10:10:01,888 - INFO - Added client 2 to federation\n",
            "INFO:AGCRN.dfl:Added client 2 to federation\n",
            "2025-05-02 10:10:01,890 - INFO - Added client 2 with 3 nodes\n",
            "INFO:AGCRN.dfl:Added client 2 with 3 nodes\n",
            "2025-05-02 10:10:01,894 - INFO - AVWGCN initialized with dim_in=65, dim_out=128, cheb_k=2\n",
            "INFO:AGCRN.dfl:AVWGCN initialized with dim_in=65, dim_out=128, cheb_k=2\n",
            "2025-05-02 10:10:01,898 - INFO - AVWGCN initialized with dim_in=65, dim_out=64, cheb_k=2\n",
            "INFO:AGCRN.dfl:AVWGCN initialized with dim_in=65, dim_out=64, cheb_k=2\n",
            "2025-05-02 10:10:01,900 - INFO - AGCRNCell initialized with node_num=4, dim_in=1, dim_out=64\n",
            "INFO:AGCRN.dfl:AGCRNCell initialized with node_num=4, dim_in=1, dim_out=64\n",
            "2025-05-02 10:10:01,906 - INFO - AVWGCN initialized with dim_in=128, dim_out=128, cheb_k=2\n",
            "INFO:AGCRN.dfl:AVWGCN initialized with dim_in=128, dim_out=128, cheb_k=2\n",
            "2025-05-02 10:10:01,911 - INFO - AVWGCN initialized with dim_in=128, dim_out=64, cheb_k=2\n",
            "INFO:AGCRN.dfl:AVWGCN initialized with dim_in=128, dim_out=64, cheb_k=2\n",
            "2025-05-02 10:10:01,913 - INFO - AGCRNCell initialized with node_num=4, dim_in=64, dim_out=64\n",
            "INFO:AGCRN.dfl:AGCRNCell initialized with node_num=4, dim_in=64, dim_out=64\n",
            "2025-05-02 10:10:01,915 - INFO - AGCRN initialized with 2 layers\n",
            "INFO:AGCRN.dfl:AGCRN initialized with 2 layers\n",
            "2025-05-02 10:10:01,919 - INFO - Added client 3 to federation\n",
            "INFO:AGCRN.dfl:Added client 3 to federation\n",
            "2025-05-02 10:10:01,921 - INFO - Added client 3 with 4 nodes\n",
            "INFO:AGCRN.dfl:Added client 3 with 4 nodes\n",
            "2025-05-02 10:10:01,929 - INFO - AVWGCN initialized with dim_in=65, dim_out=128, cheb_k=2\n",
            "INFO:AGCRN.dfl:AVWGCN initialized with dim_in=65, dim_out=128, cheb_k=2\n",
            "2025-05-02 10:10:01,933 - INFO - AVWGCN initialized with dim_in=65, dim_out=64, cheb_k=2\n",
            "INFO:AGCRN.dfl:AVWGCN initialized with dim_in=65, dim_out=64, cheb_k=2\n",
            "2025-05-02 10:10:01,935 - INFO - AGCRNCell initialized with node_num=5, dim_in=1, dim_out=64\n",
            "INFO:AGCRN.dfl:AGCRNCell initialized with node_num=5, dim_in=1, dim_out=64\n",
            "2025-05-02 10:10:01,941 - INFO - AVWGCN initialized with dim_in=128, dim_out=128, cheb_k=2\n",
            "INFO:AGCRN.dfl:AVWGCN initialized with dim_in=128, dim_out=128, cheb_k=2\n",
            "2025-05-02 10:10:01,949 - INFO - AVWGCN initialized with dim_in=128, dim_out=64, cheb_k=2\n",
            "INFO:AGCRN.dfl:AVWGCN initialized with dim_in=128, dim_out=64, cheb_k=2\n",
            "2025-05-02 10:10:01,951 - INFO - AGCRNCell initialized with node_num=5, dim_in=64, dim_out=64\n",
            "INFO:AGCRN.dfl:AGCRNCell initialized with node_num=5, dim_in=64, dim_out=64\n",
            "2025-05-02 10:10:01,954 - INFO - AGCRN initialized with 2 layers\n",
            "INFO:AGCRN.dfl:AGCRN initialized with 2 layers\n",
            "2025-05-02 10:10:01,959 - INFO - Added client 4 to federation\n",
            "INFO:AGCRN.dfl:Added client 4 to federation\n",
            "2025-05-02 10:10:01,960 - INFO - Added client 4 with 5 nodes\n",
            "INFO:AGCRN.dfl:Added client 4 with 5 nodes\n",
            "2025-05-02 10:10:01,964 - INFO - AVWGCN initialized with dim_in=65, dim_out=128, cheb_k=2\n",
            "INFO:AGCRN.dfl:AVWGCN initialized with dim_in=65, dim_out=128, cheb_k=2\n",
            "2025-05-02 10:10:01,968 - INFO - AVWGCN initialized with dim_in=65, dim_out=64, cheb_k=2\n",
            "INFO:AGCRN.dfl:AVWGCN initialized with dim_in=65, dim_out=64, cheb_k=2\n",
            "2025-05-02 10:10:01,969 - INFO - AGCRNCell initialized with node_num=6, dim_in=1, dim_out=64\n",
            "INFO:AGCRN.dfl:AGCRNCell initialized with node_num=6, dim_in=1, dim_out=64\n",
            "2025-05-02 10:10:01,976 - INFO - AVWGCN initialized with dim_in=128, dim_out=128, cheb_k=2\n",
            "INFO:AGCRN.dfl:AVWGCN initialized with dim_in=128, dim_out=128, cheb_k=2\n",
            "2025-05-02 10:10:01,980 - INFO - AVWGCN initialized with dim_in=128, dim_out=64, cheb_k=2\n",
            "INFO:AGCRN.dfl:AVWGCN initialized with dim_in=128, dim_out=64, cheb_k=2\n",
            "2025-05-02 10:10:01,982 - INFO - AGCRNCell initialized with node_num=6, dim_in=64, dim_out=64\n",
            "INFO:AGCRN.dfl:AGCRNCell initialized with node_num=6, dim_in=64, dim_out=64\n",
            "2025-05-02 10:10:01,985 - INFO - AGCRN initialized with 2 layers\n",
            "INFO:AGCRN.dfl:AGCRN initialized with 2 layers\n",
            "2025-05-02 10:10:01,989 - INFO - Added client 5 to federation\n",
            "INFO:AGCRN.dfl:Added client 5 to federation\n",
            "2025-05-02 10:10:01,990 - INFO - Added client 5 with 6 nodes\n",
            "INFO:AGCRN.dfl:Added client 5 with 6 nodes\n",
            "2025-05-02 10:10:01,995 - INFO - AVWGCN initialized with dim_in=65, dim_out=128, cheb_k=2\n",
            "INFO:AGCRN.dfl:AVWGCN initialized with dim_in=65, dim_out=128, cheb_k=2\n",
            "2025-05-02 10:10:01,998 - INFO - AVWGCN initialized with dim_in=65, dim_out=64, cheb_k=2\n",
            "INFO:AGCRN.dfl:AVWGCN initialized with dim_in=65, dim_out=64, cheb_k=2\n",
            "2025-05-02 10:10:02,001 - INFO - AGCRNCell initialized with node_num=8, dim_in=1, dim_out=64\n",
            "INFO:AGCRN.dfl:AGCRNCell initialized with node_num=8, dim_in=1, dim_out=64\n",
            "2025-05-02 10:10:02,008 - INFO - AVWGCN initialized with dim_in=128, dim_out=128, cheb_k=2\n",
            "INFO:AGCRN.dfl:AVWGCN initialized with dim_in=128, dim_out=128, cheb_k=2\n",
            "2025-05-02 10:10:02,013 - INFO - AVWGCN initialized with dim_in=128, dim_out=64, cheb_k=2\n",
            "INFO:AGCRN.dfl:AVWGCN initialized with dim_in=128, dim_out=64, cheb_k=2\n",
            "2025-05-02 10:10:02,015 - INFO - AGCRNCell initialized with node_num=8, dim_in=64, dim_out=64\n",
            "INFO:AGCRN.dfl:AGCRNCell initialized with node_num=8, dim_in=64, dim_out=64\n",
            "2025-05-02 10:10:02,017 - INFO - AGCRN initialized with 2 layers\n",
            "INFO:AGCRN.dfl:AGCRN initialized with 2 layers\n",
            "2025-05-02 10:10:02,021 - INFO - Added client 6 to federation\n",
            "INFO:AGCRN.dfl:Added client 6 to federation\n",
            "2025-05-02 10:10:02,023 - INFO - Added client 6 with 8 nodes\n",
            "INFO:AGCRN.dfl:Added client 6 with 8 nodes\n",
            "2025-05-02 10:10:02,027 - INFO - AVWGCN initialized with dim_in=65, dim_out=128, cheb_k=2\n",
            "INFO:AGCRN.dfl:AVWGCN initialized with dim_in=65, dim_out=128, cheb_k=2\n",
            "2025-05-02 10:10:02,030 - INFO - AVWGCN initialized with dim_in=65, dim_out=64, cheb_k=2\n",
            "INFO:AGCRN.dfl:AVWGCN initialized with dim_in=65, dim_out=64, cheb_k=2\n",
            "2025-05-02 10:10:02,032 - INFO - AGCRNCell initialized with node_num=7, dim_in=1, dim_out=64\n",
            "INFO:AGCRN.dfl:AGCRNCell initialized with node_num=7, dim_in=1, dim_out=64\n",
            "2025-05-02 10:10:02,039 - INFO - AVWGCN initialized with dim_in=128, dim_out=128, cheb_k=2\n",
            "INFO:AGCRN.dfl:AVWGCN initialized with dim_in=128, dim_out=128, cheb_k=2\n",
            "2025-05-02 10:10:02,043 - INFO - AVWGCN initialized with dim_in=128, dim_out=64, cheb_k=2\n",
            "INFO:AGCRN.dfl:AVWGCN initialized with dim_in=128, dim_out=64, cheb_k=2\n",
            "2025-05-02 10:10:02,045 - INFO - AGCRNCell initialized with node_num=7, dim_in=64, dim_out=64\n",
            "INFO:AGCRN.dfl:AGCRNCell initialized with node_num=7, dim_in=64, dim_out=64\n",
            "2025-05-02 10:10:02,047 - INFO - AGCRN initialized with 2 layers\n",
            "INFO:AGCRN.dfl:AGCRN initialized with 2 layers\n",
            "2025-05-02 10:10:02,051 - INFO - Added client 7 to federation\n",
            "INFO:AGCRN.dfl:Added client 7 to federation\n",
            "2025-05-02 10:10:02,053 - INFO - Added client 7 with 7 nodes\n",
            "INFO:AGCRN.dfl:Added client 7 with 7 nodes\n",
            "2025-05-02 10:10:02,058 - INFO - AVWGCN initialized with dim_in=65, dim_out=128, cheb_k=2\n",
            "INFO:AGCRN.dfl:AVWGCN initialized with dim_in=65, dim_out=128, cheb_k=2\n",
            "2025-05-02 10:10:02,061 - INFO - AVWGCN initialized with dim_in=65, dim_out=64, cheb_k=2\n",
            "INFO:AGCRN.dfl:AVWGCN initialized with dim_in=65, dim_out=64, cheb_k=2\n",
            "2025-05-02 10:10:02,063 - INFO - AGCRNCell initialized with node_num=6, dim_in=1, dim_out=64\n",
            "INFO:AGCRN.dfl:AGCRNCell initialized with node_num=6, dim_in=1, dim_out=64\n",
            "2025-05-02 10:10:02,070 - INFO - AVWGCN initialized with dim_in=128, dim_out=128, cheb_k=2\n",
            "INFO:AGCRN.dfl:AVWGCN initialized with dim_in=128, dim_out=128, cheb_k=2\n",
            "2025-05-02 10:10:02,074 - INFO - AVWGCN initialized with dim_in=128, dim_out=64, cheb_k=2\n",
            "INFO:AGCRN.dfl:AVWGCN initialized with dim_in=128, dim_out=64, cheb_k=2\n",
            "2025-05-02 10:10:02,076 - INFO - AGCRNCell initialized with node_num=6, dim_in=64, dim_out=64\n",
            "INFO:AGCRN.dfl:AGCRNCell initialized with node_num=6, dim_in=64, dim_out=64\n",
            "2025-05-02 10:10:02,078 - INFO - AGCRN initialized with 2 layers\n",
            "INFO:AGCRN.dfl:AGCRN initialized with 2 layers\n",
            "2025-05-02 10:10:02,082 - INFO - Added client 8 to federation\n",
            "INFO:AGCRN.dfl:Added client 8 to federation\n",
            "2025-05-02 10:10:02,083 - INFO - Added client 8 with 6 nodes\n",
            "INFO:AGCRN.dfl:Added client 8 with 6 nodes\n",
            "2025-05-02 10:10:02,088 - INFO - AVWGCN initialized with dim_in=65, dim_out=128, cheb_k=2\n",
            "INFO:AGCRN.dfl:AVWGCN initialized with dim_in=65, dim_out=128, cheb_k=2\n",
            "2025-05-02 10:10:02,091 - INFO - AVWGCN initialized with dim_in=65, dim_out=64, cheb_k=2\n",
            "INFO:AGCRN.dfl:AVWGCN initialized with dim_in=65, dim_out=64, cheb_k=2\n",
            "2025-05-02 10:10:02,093 - INFO - AGCRNCell initialized with node_num=8, dim_in=1, dim_out=64\n",
            "INFO:AGCRN.dfl:AGCRNCell initialized with node_num=8, dim_in=1, dim_out=64\n",
            "2025-05-02 10:10:02,100 - INFO - AVWGCN initialized with dim_in=128, dim_out=128, cheb_k=2\n",
            "INFO:AGCRN.dfl:AVWGCN initialized with dim_in=128, dim_out=128, cheb_k=2\n",
            "2025-05-02 10:10:02,104 - INFO - AVWGCN initialized with dim_in=128, dim_out=64, cheb_k=2\n",
            "INFO:AGCRN.dfl:AVWGCN initialized with dim_in=128, dim_out=64, cheb_k=2\n",
            "2025-05-02 10:10:02,106 - INFO - AGCRNCell initialized with node_num=8, dim_in=64, dim_out=64\n",
            "INFO:AGCRN.dfl:AGCRNCell initialized with node_num=8, dim_in=64, dim_out=64\n",
            "2025-05-02 10:10:02,108 - INFO - AGCRN initialized with 2 layers\n",
            "INFO:AGCRN.dfl:AGCRN initialized with 2 layers\n",
            "2025-05-02 10:10:02,112 - INFO - Added client 9 to federation\n",
            "INFO:AGCRN.dfl:Added client 9 to federation\n",
            "2025-05-02 10:10:02,114 - INFO - Added client 9 with 8 nodes\n",
            "INFO:AGCRN.dfl:Added client 9 with 8 nodes\n",
            "2025-05-02 10:10:02,121 - INFO - AVWGCN initialized with dim_in=65, dim_out=128, cheb_k=2\n",
            "INFO:AGCRN.dfl:AVWGCN initialized with dim_in=65, dim_out=128, cheb_k=2\n",
            "2025-05-02 10:10:02,125 - INFO - AVWGCN initialized with dim_in=65, dim_out=64, cheb_k=2\n",
            "INFO:AGCRN.dfl:AVWGCN initialized with dim_in=65, dim_out=64, cheb_k=2\n",
            "2025-05-02 10:10:02,128 - INFO - AGCRNCell initialized with node_num=5, dim_in=1, dim_out=64\n",
            "INFO:AGCRN.dfl:AGCRNCell initialized with node_num=5, dim_in=1, dim_out=64\n",
            "2025-05-02 10:10:02,138 - INFO - AVWGCN initialized with dim_in=128, dim_out=128, cheb_k=2\n",
            "INFO:AGCRN.dfl:AVWGCN initialized with dim_in=128, dim_out=128, cheb_k=2\n",
            "2025-05-02 10:10:02,143 - INFO - AVWGCN initialized with dim_in=128, dim_out=64, cheb_k=2\n",
            "INFO:AGCRN.dfl:AVWGCN initialized with dim_in=128, dim_out=64, cheb_k=2\n",
            "2025-05-02 10:10:02,145 - INFO - AGCRNCell initialized with node_num=5, dim_in=64, dim_out=64\n",
            "INFO:AGCRN.dfl:AGCRNCell initialized with node_num=5, dim_in=64, dim_out=64\n",
            "2025-05-02 10:10:02,147 - INFO - AGCRN initialized with 2 layers\n",
            "INFO:AGCRN.dfl:AGCRN initialized with 2 layers\n",
            "2025-05-02 10:10:02,151 - INFO - Added client 10 to federation\n",
            "INFO:AGCRN.dfl:Added client 10 to federation\n",
            "2025-05-02 10:10:02,153 - INFO - Added client 10 with 5 nodes\n",
            "INFO:AGCRN.dfl:Added client 10 with 5 nodes\n",
            "2025-05-02 10:10:02,157 - INFO - AVWGCN initialized with dim_in=65, dim_out=128, cheb_k=2\n",
            "INFO:AGCRN.dfl:AVWGCN initialized with dim_in=65, dim_out=128, cheb_k=2\n",
            "2025-05-02 10:10:02,160 - INFO - AVWGCN initialized with dim_in=65, dim_out=64, cheb_k=2\n",
            "INFO:AGCRN.dfl:AVWGCN initialized with dim_in=65, dim_out=64, cheb_k=2\n",
            "2025-05-02 10:10:02,162 - INFO - AGCRNCell initialized with node_num=5, dim_in=1, dim_out=64\n",
            "INFO:AGCRN.dfl:AGCRNCell initialized with node_num=5, dim_in=1, dim_out=64\n",
            "2025-05-02 10:10:02,169 - INFO - AVWGCN initialized with dim_in=128, dim_out=128, cheb_k=2\n",
            "INFO:AGCRN.dfl:AVWGCN initialized with dim_in=128, dim_out=128, cheb_k=2\n",
            "2025-05-02 10:10:02,173 - INFO - AVWGCN initialized with dim_in=128, dim_out=64, cheb_k=2\n",
            "INFO:AGCRN.dfl:AVWGCN initialized with dim_in=128, dim_out=64, cheb_k=2\n",
            "2025-05-02 10:10:02,175 - INFO - AGCRNCell initialized with node_num=5, dim_in=64, dim_out=64\n",
            "INFO:AGCRN.dfl:AGCRNCell initialized with node_num=5, dim_in=64, dim_out=64\n",
            "2025-05-02 10:10:02,177 - INFO - AGCRN initialized with 2 layers\n",
            "INFO:AGCRN.dfl:AGCRN initialized with 2 layers\n",
            "2025-05-02 10:10:02,181 - INFO - Added client 11 to federation\n",
            "INFO:AGCRN.dfl:Added client 11 to federation\n",
            "2025-05-02 10:10:02,183 - INFO - Added client 11 with 5 nodes\n",
            "INFO:AGCRN.dfl:Added client 11 with 5 nodes\n",
            "2025-05-02 10:10:02,187 - INFO - AVWGCN initialized with dim_in=65, dim_out=128, cheb_k=2\n",
            "INFO:AGCRN.dfl:AVWGCN initialized with dim_in=65, dim_out=128, cheb_k=2\n",
            "2025-05-02 10:10:02,191 - INFO - AVWGCN initialized with dim_in=65, dim_out=64, cheb_k=2\n",
            "INFO:AGCRN.dfl:AVWGCN initialized with dim_in=65, dim_out=64, cheb_k=2\n",
            "2025-05-02 10:10:02,192 - INFO - AGCRNCell initialized with node_num=3, dim_in=1, dim_out=64\n",
            "INFO:AGCRN.dfl:AGCRNCell initialized with node_num=3, dim_in=1, dim_out=64\n",
            "2025-05-02 10:10:02,198 - INFO - AVWGCN initialized with dim_in=128, dim_out=128, cheb_k=2\n",
            "INFO:AGCRN.dfl:AVWGCN initialized with dim_in=128, dim_out=128, cheb_k=2\n",
            "2025-05-02 10:10:02,204 - INFO - AVWGCN initialized with dim_in=128, dim_out=64, cheb_k=2\n",
            "INFO:AGCRN.dfl:AVWGCN initialized with dim_in=128, dim_out=64, cheb_k=2\n",
            "2025-05-02 10:10:02,205 - INFO - AGCRNCell initialized with node_num=3, dim_in=64, dim_out=64\n",
            "INFO:AGCRN.dfl:AGCRNCell initialized with node_num=3, dim_in=64, dim_out=64\n",
            "2025-05-02 10:10:02,207 - INFO - AGCRN initialized with 2 layers\n",
            "INFO:AGCRN.dfl:AGCRN initialized with 2 layers\n",
            "2025-05-02 10:10:02,212 - INFO - Added client 12 to federation\n",
            "INFO:AGCRN.dfl:Added client 12 to federation\n",
            "2025-05-02 10:10:02,213 - INFO - Added client 12 with 3 nodes\n",
            "INFO:AGCRN.dfl:Added client 12 with 3 nodes\n",
            "2025-05-02 10:10:02,218 - INFO - AVWGCN initialized with dim_in=65, dim_out=128, cheb_k=2\n",
            "INFO:AGCRN.dfl:AVWGCN initialized with dim_in=65, dim_out=128, cheb_k=2\n",
            "2025-05-02 10:10:02,221 - INFO - AVWGCN initialized with dim_in=65, dim_out=64, cheb_k=2\n",
            "INFO:AGCRN.dfl:AVWGCN initialized with dim_in=65, dim_out=64, cheb_k=2\n",
            "2025-05-02 10:10:02,223 - INFO - AGCRNCell initialized with node_num=4, dim_in=1, dim_out=64\n",
            "INFO:AGCRN.dfl:AGCRNCell initialized with node_num=4, dim_in=1, dim_out=64\n",
            "2025-05-02 10:10:02,229 - INFO - AVWGCN initialized with dim_in=128, dim_out=128, cheb_k=2\n",
            "INFO:AGCRN.dfl:AVWGCN initialized with dim_in=128, dim_out=128, cheb_k=2\n",
            "2025-05-02 10:10:02,234 - INFO - AVWGCN initialized with dim_in=128, dim_out=64, cheb_k=2\n",
            "INFO:AGCRN.dfl:AVWGCN initialized with dim_in=128, dim_out=64, cheb_k=2\n",
            "2025-05-02 10:10:02,236 - INFO - AGCRNCell initialized with node_num=4, dim_in=64, dim_out=64\n",
            "INFO:AGCRN.dfl:AGCRNCell initialized with node_num=4, dim_in=64, dim_out=64\n",
            "2025-05-02 10:10:02,238 - INFO - AGCRN initialized with 2 layers\n",
            "INFO:AGCRN.dfl:AGCRN initialized with 2 layers\n",
            "2025-05-02 10:10:02,242 - INFO - Added client 13 to federation\n",
            "INFO:AGCRN.dfl:Added client 13 to federation\n",
            "2025-05-02 10:10:02,245 - INFO - Added client 13 with 4 nodes\n",
            "INFO:AGCRN.dfl:Added client 13 with 4 nodes\n",
            "2025-05-02 10:10:02,251 - INFO - AVWGCN initialized with dim_in=65, dim_out=128, cheb_k=2\n",
            "INFO:AGCRN.dfl:AVWGCN initialized with dim_in=65, dim_out=128, cheb_k=2\n",
            "2025-05-02 10:10:02,255 - INFO - AVWGCN initialized with dim_in=65, dim_out=64, cheb_k=2\n",
            "INFO:AGCRN.dfl:AVWGCN initialized with dim_in=65, dim_out=64, cheb_k=2\n",
            "2025-05-02 10:10:02,257 - INFO - AGCRNCell initialized with node_num=15, dim_in=1, dim_out=64\n",
            "INFO:AGCRN.dfl:AGCRNCell initialized with node_num=15, dim_in=1, dim_out=64\n",
            "2025-05-02 10:10:02,264 - INFO - AVWGCN initialized with dim_in=128, dim_out=128, cheb_k=2\n",
            "INFO:AGCRN.dfl:AVWGCN initialized with dim_in=128, dim_out=128, cheb_k=2\n",
            "2025-05-02 10:10:02,270 - INFO - AVWGCN initialized with dim_in=128, dim_out=64, cheb_k=2\n",
            "INFO:AGCRN.dfl:AVWGCN initialized with dim_in=128, dim_out=64, cheb_k=2\n",
            "2025-05-02 10:10:02,273 - INFO - AGCRNCell initialized with node_num=15, dim_in=64, dim_out=64\n",
            "INFO:AGCRN.dfl:AGCRNCell initialized with node_num=15, dim_in=64, dim_out=64\n",
            "2025-05-02 10:10:02,278 - INFO - AGCRN initialized with 2 layers\n",
            "INFO:AGCRN.dfl:AGCRN initialized with 2 layers\n",
            "2025-05-02 10:10:02,282 - INFO - Added client 14 to federation\n",
            "INFO:AGCRN.dfl:Added client 14 to federation\n",
            "2025-05-02 10:10:02,284 - INFO - Added client 14 with 15 nodes\n",
            "INFO:AGCRN.dfl:Added client 14 with 15 nodes\n",
            "2025-05-02 10:10:02,288 - INFO - AVWGCN initialized with dim_in=65, dim_out=128, cheb_k=2\n",
            "INFO:AGCRN.dfl:AVWGCN initialized with dim_in=65, dim_out=128, cheb_k=2\n",
            "2025-05-02 10:10:02,292 - INFO - AVWGCN initialized with dim_in=65, dim_out=64, cheb_k=2\n",
            "INFO:AGCRN.dfl:AVWGCN initialized with dim_in=65, dim_out=64, cheb_k=2\n",
            "2025-05-02 10:10:02,294 - INFO - AGCRNCell initialized with node_num=10, dim_in=1, dim_out=64\n",
            "INFO:AGCRN.dfl:AGCRNCell initialized with node_num=10, dim_in=1, dim_out=64\n",
            "2025-05-02 10:10:02,308 - INFO - AVWGCN initialized with dim_in=128, dim_out=128, cheb_k=2\n",
            "INFO:AGCRN.dfl:AVWGCN initialized with dim_in=128, dim_out=128, cheb_k=2\n",
            "2025-05-02 10:10:02,312 - INFO - AVWGCN initialized with dim_in=128, dim_out=64, cheb_k=2\n",
            "INFO:AGCRN.dfl:AVWGCN initialized with dim_in=128, dim_out=64, cheb_k=2\n",
            "2025-05-02 10:10:02,314 - INFO - AGCRNCell initialized with node_num=10, dim_in=64, dim_out=64\n",
            "INFO:AGCRN.dfl:AGCRNCell initialized with node_num=10, dim_in=64, dim_out=64\n",
            "2025-05-02 10:10:02,316 - INFO - AGCRN initialized with 2 layers\n",
            "INFO:AGCRN.dfl:AGCRN initialized with 2 layers\n",
            "2025-05-02 10:10:02,320 - INFO - Added client 15 to federation\n",
            "INFO:AGCRN.dfl:Added client 15 to federation\n",
            "2025-05-02 10:10:02,321 - INFO - Added client 15 with 10 nodes\n",
            "INFO:AGCRN.dfl:Added client 15 with 10 nodes\n",
            "2025-05-02 10:10:02,325 - INFO - AVWGCN initialized with dim_in=65, dim_out=128, cheb_k=2\n",
            "INFO:AGCRN.dfl:AVWGCN initialized with dim_in=65, dim_out=128, cheb_k=2\n",
            "2025-05-02 10:10:02,329 - INFO - AVWGCN initialized with dim_in=65, dim_out=64, cheb_k=2\n",
            "INFO:AGCRN.dfl:AVWGCN initialized with dim_in=65, dim_out=64, cheb_k=2\n",
            "2025-05-02 10:10:02,330 - INFO - AGCRNCell initialized with node_num=4, dim_in=1, dim_out=64\n",
            "INFO:AGCRN.dfl:AGCRNCell initialized with node_num=4, dim_in=1, dim_out=64\n",
            "2025-05-02 10:10:02,337 - INFO - AVWGCN initialized with dim_in=128, dim_out=128, cheb_k=2\n",
            "INFO:AGCRN.dfl:AVWGCN initialized with dim_in=128, dim_out=128, cheb_k=2\n",
            "2025-05-02 10:10:02,342 - INFO - AVWGCN initialized with dim_in=128, dim_out=64, cheb_k=2\n",
            "INFO:AGCRN.dfl:AVWGCN initialized with dim_in=128, dim_out=64, cheb_k=2\n",
            "2025-05-02 10:10:02,344 - INFO - AGCRNCell initialized with node_num=4, dim_in=64, dim_out=64\n",
            "INFO:AGCRN.dfl:AGCRNCell initialized with node_num=4, dim_in=64, dim_out=64\n",
            "2025-05-02 10:10:02,348 - INFO - AGCRN initialized with 2 layers\n",
            "INFO:AGCRN.dfl:AGCRN initialized with 2 layers\n",
            "2025-05-02 10:10:02,352 - INFO - Added client 16 to federation\n",
            "INFO:AGCRN.dfl:Added client 16 to federation\n",
            "2025-05-02 10:10:02,353 - INFO - Added client 16 with 4 nodes\n",
            "INFO:AGCRN.dfl:Added client 16 with 4 nodes\n",
            "2025-05-02 10:10:02,358 - INFO - AVWGCN initialized with dim_in=65, dim_out=128, cheb_k=2\n",
            "INFO:AGCRN.dfl:AVWGCN initialized with dim_in=65, dim_out=128, cheb_k=2\n",
            "2025-05-02 10:10:02,361 - INFO - AVWGCN initialized with dim_in=65, dim_out=64, cheb_k=2\n",
            "INFO:AGCRN.dfl:AVWGCN initialized with dim_in=65, dim_out=64, cheb_k=2\n",
            "2025-05-02 10:10:02,363 - INFO - AGCRNCell initialized with node_num=4, dim_in=1, dim_out=64\n",
            "INFO:AGCRN.dfl:AGCRNCell initialized with node_num=4, dim_in=1, dim_out=64\n",
            "2025-05-02 10:10:02,369 - INFO - AVWGCN initialized with dim_in=128, dim_out=128, cheb_k=2\n",
            "INFO:AGCRN.dfl:AVWGCN initialized with dim_in=128, dim_out=128, cheb_k=2\n",
            "2025-05-02 10:10:02,374 - INFO - AVWGCN initialized with dim_in=128, dim_out=64, cheb_k=2\n",
            "INFO:AGCRN.dfl:AVWGCN initialized with dim_in=128, dim_out=64, cheb_k=2\n",
            "2025-05-02 10:10:02,376 - INFO - AGCRNCell initialized with node_num=4, dim_in=64, dim_out=64\n",
            "INFO:AGCRN.dfl:AGCRNCell initialized with node_num=4, dim_in=64, dim_out=64\n",
            "2025-05-02 10:10:02,378 - INFO - AGCRN initialized with 2 layers\n",
            "INFO:AGCRN.dfl:AGCRN initialized with 2 layers\n",
            "2025-05-02 10:10:02,382 - INFO - Added client 17 to federation\n",
            "INFO:AGCRN.dfl:Added client 17 to federation\n",
            "2025-05-02 10:10:02,384 - INFO - Added client 17 with 4 nodes\n",
            "INFO:AGCRN.dfl:Added client 17 with 4 nodes\n",
            "2025-05-02 10:10:02,389 - INFO - AVWGCN initialized with dim_in=65, dim_out=128, cheb_k=2\n",
            "INFO:AGCRN.dfl:AVWGCN initialized with dim_in=65, dim_out=128, cheb_k=2\n",
            "2025-05-02 10:10:02,392 - INFO - AVWGCN initialized with dim_in=65, dim_out=64, cheb_k=2\n",
            "INFO:AGCRN.dfl:AVWGCN initialized with dim_in=65, dim_out=64, cheb_k=2\n",
            "2025-05-02 10:10:02,394 - INFO - AGCRNCell initialized with node_num=12, dim_in=1, dim_out=64\n",
            "INFO:AGCRN.dfl:AGCRNCell initialized with node_num=12, dim_in=1, dim_out=64\n",
            "2025-05-02 10:10:02,400 - INFO - AVWGCN initialized with dim_in=128, dim_out=128, cheb_k=2\n",
            "INFO:AGCRN.dfl:AVWGCN initialized with dim_in=128, dim_out=128, cheb_k=2\n",
            "2025-05-02 10:10:02,404 - INFO - AVWGCN initialized with dim_in=128, dim_out=64, cheb_k=2\n",
            "INFO:AGCRN.dfl:AVWGCN initialized with dim_in=128, dim_out=64, cheb_k=2\n",
            "2025-05-02 10:10:02,406 - INFO - AGCRNCell initialized with node_num=12, dim_in=64, dim_out=64\n",
            "INFO:AGCRN.dfl:AGCRNCell initialized with node_num=12, dim_in=64, dim_out=64\n",
            "2025-05-02 10:10:02,408 - INFO - AGCRN initialized with 2 layers\n",
            "INFO:AGCRN.dfl:AGCRN initialized with 2 layers\n",
            "2025-05-02 10:10:02,412 - INFO - Added client 18 to federation\n",
            "INFO:AGCRN.dfl:Added client 18 to federation\n",
            "2025-05-02 10:10:02,413 - INFO - Added client 18 with 12 nodes\n",
            "INFO:AGCRN.dfl:Added client 18 with 12 nodes\n",
            "2025-05-02 10:10:02,418 - INFO - AVWGCN initialized with dim_in=65, dim_out=128, cheb_k=2\n",
            "INFO:AGCRN.dfl:AVWGCN initialized with dim_in=65, dim_out=128, cheb_k=2\n",
            "2025-05-02 10:10:02,421 - INFO - AVWGCN initialized with dim_in=65, dim_out=64, cheb_k=2\n",
            "INFO:AGCRN.dfl:AVWGCN initialized with dim_in=65, dim_out=64, cheb_k=2\n",
            "2025-05-02 10:10:02,422 - INFO - AGCRNCell initialized with node_num=3, dim_in=1, dim_out=64\n",
            "INFO:AGCRN.dfl:AGCRNCell initialized with node_num=3, dim_in=1, dim_out=64\n",
            "2025-05-02 10:10:02,429 - INFO - AVWGCN initialized with dim_in=128, dim_out=128, cheb_k=2\n",
            "INFO:AGCRN.dfl:AVWGCN initialized with dim_in=128, dim_out=128, cheb_k=2\n",
            "2025-05-02 10:10:02,433 - INFO - AVWGCN initialized with dim_in=128, dim_out=64, cheb_k=2\n",
            "INFO:AGCRN.dfl:AVWGCN initialized with dim_in=128, dim_out=64, cheb_k=2\n",
            "2025-05-02 10:10:02,437 - INFO - AGCRNCell initialized with node_num=3, dim_in=64, dim_out=64\n",
            "INFO:AGCRN.dfl:AGCRNCell initialized with node_num=3, dim_in=64, dim_out=64\n",
            "2025-05-02 10:10:02,439 - INFO - AGCRN initialized with 2 layers\n",
            "INFO:AGCRN.dfl:AGCRN initialized with 2 layers\n",
            "2025-05-02 10:10:02,444 - INFO - Added client 19 to federation\n",
            "INFO:AGCRN.dfl:Added client 19 to federation\n",
            "2025-05-02 10:10:02,448 - INFO - Added client 19 with 3 nodes\n",
            "INFO:AGCRN.dfl:Added client 19 with 3 nodes\n",
            "2025-05-02 10:10:02,453 - INFO - AVWGCN initialized with dim_in=65, dim_out=128, cheb_k=2\n",
            "INFO:AGCRN.dfl:AVWGCN initialized with dim_in=65, dim_out=128, cheb_k=2\n",
            "2025-05-02 10:10:02,456 - INFO - AVWGCN initialized with dim_in=65, dim_out=64, cheb_k=2\n",
            "INFO:AGCRN.dfl:AVWGCN initialized with dim_in=65, dim_out=64, cheb_k=2\n",
            "2025-05-02 10:10:02,460 - INFO - AGCRNCell initialized with node_num=3, dim_in=1, dim_out=64\n",
            "INFO:AGCRN.dfl:AGCRNCell initialized with node_num=3, dim_in=1, dim_out=64\n",
            "2025-05-02 10:10:02,467 - INFO - AVWGCN initialized with dim_in=128, dim_out=128, cheb_k=2\n",
            "INFO:AGCRN.dfl:AVWGCN initialized with dim_in=128, dim_out=128, cheb_k=2\n",
            "2025-05-02 10:10:02,471 - INFO - AVWGCN initialized with dim_in=128, dim_out=64, cheb_k=2\n",
            "INFO:AGCRN.dfl:AVWGCN initialized with dim_in=128, dim_out=64, cheb_k=2\n",
            "2025-05-02 10:10:02,473 - INFO - AGCRNCell initialized with node_num=3, dim_in=64, dim_out=64\n",
            "INFO:AGCRN.dfl:AGCRNCell initialized with node_num=3, dim_in=64, dim_out=64\n",
            "2025-05-02 10:10:02,475 - INFO - AGCRN initialized with 2 layers\n",
            "INFO:AGCRN.dfl:AGCRN initialized with 2 layers\n",
            "2025-05-02 10:10:02,480 - INFO - Added client 20 to federation\n",
            "INFO:AGCRN.dfl:Added client 20 to federation\n",
            "2025-05-02 10:10:02,481 - INFO - Added client 20 with 3 nodes\n",
            "INFO:AGCRN.dfl:Added client 20 with 3 nodes\n",
            "2025-05-02 10:10:02,486 - INFO - AVWGCN initialized with dim_in=65, dim_out=128, cheb_k=2\n",
            "INFO:AGCRN.dfl:AVWGCN initialized with dim_in=65, dim_out=128, cheb_k=2\n",
            "2025-05-02 10:10:02,489 - INFO - AVWGCN initialized with dim_in=65, dim_out=64, cheb_k=2\n",
            "INFO:AGCRN.dfl:AVWGCN initialized with dim_in=65, dim_out=64, cheb_k=2\n",
            "2025-05-02 10:10:02,491 - INFO - AGCRNCell initialized with node_num=4, dim_in=1, dim_out=64\n",
            "INFO:AGCRN.dfl:AGCRNCell initialized with node_num=4, dim_in=1, dim_out=64\n",
            "2025-05-02 10:10:02,497 - INFO - AVWGCN initialized with dim_in=128, dim_out=128, cheb_k=2\n",
            "INFO:AGCRN.dfl:AVWGCN initialized with dim_in=128, dim_out=128, cheb_k=2\n",
            "2025-05-02 10:10:02,501 - INFO - AVWGCN initialized with dim_in=128, dim_out=64, cheb_k=2\n",
            "INFO:AGCRN.dfl:AVWGCN initialized with dim_in=128, dim_out=64, cheb_k=2\n",
            "2025-05-02 10:10:02,503 - INFO - AGCRNCell initialized with node_num=4, dim_in=64, dim_out=64\n",
            "INFO:AGCRN.dfl:AGCRNCell initialized with node_num=4, dim_in=64, dim_out=64\n",
            "2025-05-02 10:10:02,505 - INFO - AGCRN initialized with 2 layers\n",
            "INFO:AGCRN.dfl:AGCRN initialized with 2 layers\n",
            "2025-05-02 10:10:02,509 - INFO - Added client 21 to federation\n",
            "INFO:AGCRN.dfl:Added client 21 to federation\n",
            "2025-05-02 10:10:02,510 - INFO - Added client 21 with 4 nodes\n",
            "INFO:AGCRN.dfl:Added client 21 with 4 nodes\n",
            "2025-05-02 10:10:02,515 - INFO - AVWGCN initialized with dim_in=65, dim_out=128, cheb_k=2\n",
            "INFO:AGCRN.dfl:AVWGCN initialized with dim_in=65, dim_out=128, cheb_k=2\n",
            "2025-05-02 10:10:02,518 - INFO - AVWGCN initialized with dim_in=65, dim_out=64, cheb_k=2\n",
            "INFO:AGCRN.dfl:AVWGCN initialized with dim_in=65, dim_out=64, cheb_k=2\n",
            "2025-05-02 10:10:02,519 - INFO - AGCRNCell initialized with node_num=4, dim_in=1, dim_out=64\n",
            "INFO:AGCRN.dfl:AGCRNCell initialized with node_num=4, dim_in=1, dim_out=64\n",
            "2025-05-02 10:10:02,526 - INFO - AVWGCN initialized with dim_in=128, dim_out=128, cheb_k=2\n",
            "INFO:AGCRN.dfl:AVWGCN initialized with dim_in=128, dim_out=128, cheb_k=2\n",
            "2025-05-02 10:10:02,530 - INFO - AVWGCN initialized with dim_in=128, dim_out=64, cheb_k=2\n",
            "INFO:AGCRN.dfl:AVWGCN initialized with dim_in=128, dim_out=64, cheb_k=2\n",
            "2025-05-02 10:10:02,532 - INFO - AGCRNCell initialized with node_num=4, dim_in=64, dim_out=64\n",
            "INFO:AGCRN.dfl:AGCRNCell initialized with node_num=4, dim_in=64, dim_out=64\n",
            "2025-05-02 10:10:02,534 - INFO - AGCRN initialized with 2 layers\n",
            "INFO:AGCRN.dfl:AGCRN initialized with 2 layers\n",
            "2025-05-02 10:10:02,538 - INFO - Added client 22 to federation\n",
            "INFO:AGCRN.dfl:Added client 22 to federation\n",
            "2025-05-02 10:10:02,540 - INFO - Added client 22 with 4 nodes\n",
            "INFO:AGCRN.dfl:Added client 22 with 4 nodes\n",
            "2025-05-02 10:10:02,544 - INFO - AVWGCN initialized with dim_in=65, dim_out=128, cheb_k=2\n",
            "INFO:AGCRN.dfl:AVWGCN initialized with dim_in=65, dim_out=128, cheb_k=2\n",
            "2025-05-02 10:10:02,550 - INFO - AVWGCN initialized with dim_in=65, dim_out=64, cheb_k=2\n",
            "INFO:AGCRN.dfl:AVWGCN initialized with dim_in=65, dim_out=64, cheb_k=2\n",
            "2025-05-02 10:10:02,554 - INFO - AGCRNCell initialized with node_num=9, dim_in=1, dim_out=64\n",
            "INFO:AGCRN.dfl:AGCRNCell initialized with node_num=9, dim_in=1, dim_out=64\n",
            "2025-05-02 10:10:02,560 - INFO - AVWGCN initialized with dim_in=128, dim_out=128, cheb_k=2\n",
            "INFO:AGCRN.dfl:AVWGCN initialized with dim_in=128, dim_out=128, cheb_k=2\n",
            "2025-05-02 10:10:02,565 - INFO - AVWGCN initialized with dim_in=128, dim_out=64, cheb_k=2\n",
            "INFO:AGCRN.dfl:AVWGCN initialized with dim_in=128, dim_out=64, cheb_k=2\n",
            "2025-05-02 10:10:02,567 - INFO - AGCRNCell initialized with node_num=9, dim_in=64, dim_out=64\n",
            "INFO:AGCRN.dfl:AGCRNCell initialized with node_num=9, dim_in=64, dim_out=64\n",
            "2025-05-02 10:10:02,569 - INFO - AGCRN initialized with 2 layers\n",
            "INFO:AGCRN.dfl:AGCRN initialized with 2 layers\n",
            "2025-05-02 10:10:02,573 - INFO - Added client 23 to federation\n",
            "INFO:AGCRN.dfl:Added client 23 to federation\n",
            "2025-05-02 10:10:02,574 - INFO - Added client 23 with 9 nodes\n",
            "INFO:AGCRN.dfl:Added client 23 with 9 nodes\n",
            "2025-05-02 10:10:02,579 - INFO - AVWGCN initialized with dim_in=65, dim_out=128, cheb_k=2\n",
            "INFO:AGCRN.dfl:AVWGCN initialized with dim_in=65, dim_out=128, cheb_k=2\n",
            "2025-05-02 10:10:02,582 - INFO - AVWGCN initialized with dim_in=65, dim_out=64, cheb_k=2\n",
            "INFO:AGCRN.dfl:AVWGCN initialized with dim_in=65, dim_out=64, cheb_k=2\n",
            "2025-05-02 10:10:02,584 - INFO - AGCRNCell initialized with node_num=8, dim_in=1, dim_out=64\n",
            "INFO:AGCRN.dfl:AGCRNCell initialized with node_num=8, dim_in=1, dim_out=64\n",
            "2025-05-02 10:10:02,591 - INFO - AVWGCN initialized with dim_in=128, dim_out=128, cheb_k=2\n",
            "INFO:AGCRN.dfl:AVWGCN initialized with dim_in=128, dim_out=128, cheb_k=2\n",
            "2025-05-02 10:10:02,595 - INFO - AVWGCN initialized with dim_in=128, dim_out=64, cheb_k=2\n",
            "INFO:AGCRN.dfl:AVWGCN initialized with dim_in=128, dim_out=64, cheb_k=2\n",
            "2025-05-02 10:10:02,597 - INFO - AGCRNCell initialized with node_num=8, dim_in=64, dim_out=64\n",
            "INFO:AGCRN.dfl:AGCRNCell initialized with node_num=8, dim_in=64, dim_out=64\n",
            "2025-05-02 10:10:02,599 - INFO - AGCRN initialized with 2 layers\n",
            "INFO:AGCRN.dfl:AGCRN initialized with 2 layers\n",
            "2025-05-02 10:10:02,603 - INFO - Added client 24 to federation\n",
            "INFO:AGCRN.dfl:Added client 24 to federation\n",
            "2025-05-02 10:10:02,604 - INFO - Added client 24 with 8 nodes\n",
            "INFO:AGCRN.dfl:Added client 24 with 8 nodes\n",
            "2025-05-02 10:10:02,609 - INFO - AVWGCN initialized with dim_in=65, dim_out=128, cheb_k=2\n",
            "INFO:AGCRN.dfl:AVWGCN initialized with dim_in=65, dim_out=128, cheb_k=2\n",
            "2025-05-02 10:10:02,612 - INFO - AVWGCN initialized with dim_in=65, dim_out=64, cheb_k=2\n",
            "INFO:AGCRN.dfl:AVWGCN initialized with dim_in=65, dim_out=64, cheb_k=2\n",
            "2025-05-02 10:10:02,614 - INFO - AGCRNCell initialized with node_num=7, dim_in=1, dim_out=64\n",
            "INFO:AGCRN.dfl:AGCRNCell initialized with node_num=7, dim_in=1, dim_out=64\n",
            "2025-05-02 10:10:02,620 - INFO - AVWGCN initialized with dim_in=128, dim_out=128, cheb_k=2\n",
            "INFO:AGCRN.dfl:AVWGCN initialized with dim_in=128, dim_out=128, cheb_k=2\n",
            "2025-05-02 10:10:02,625 - INFO - AVWGCN initialized with dim_in=128, dim_out=64, cheb_k=2\n",
            "INFO:AGCRN.dfl:AVWGCN initialized with dim_in=128, dim_out=64, cheb_k=2\n",
            "2025-05-02 10:10:02,626 - INFO - AGCRNCell initialized with node_num=7, dim_in=64, dim_out=64\n",
            "INFO:AGCRN.dfl:AGCRNCell initialized with node_num=7, dim_in=64, dim_out=64\n",
            "2025-05-02 10:10:02,628 - INFO - AGCRN initialized with 2 layers\n",
            "INFO:AGCRN.dfl:AGCRN initialized with 2 layers\n",
            "2025-05-02 10:10:02,632 - INFO - Added client 25 to federation\n",
            "INFO:AGCRN.dfl:Added client 25 to federation\n",
            "2025-05-02 10:10:02,634 - INFO - Added client 25 with 7 nodes\n",
            "INFO:AGCRN.dfl:Added client 25 with 7 nodes\n",
            "2025-05-02 10:10:02,638 - INFO - AVWGCN initialized with dim_in=65, dim_out=128, cheb_k=2\n",
            "INFO:AGCRN.dfl:AVWGCN initialized with dim_in=65, dim_out=128, cheb_k=2\n",
            "2025-05-02 10:10:02,642 - INFO - AVWGCN initialized with dim_in=65, dim_out=64, cheb_k=2\n",
            "INFO:AGCRN.dfl:AVWGCN initialized with dim_in=65, dim_out=64, cheb_k=2\n",
            "2025-05-02 10:10:02,643 - INFO - AGCRNCell initialized with node_num=4, dim_in=1, dim_out=64\n",
            "INFO:AGCRN.dfl:AGCRNCell initialized with node_num=4, dim_in=1, dim_out=64\n",
            "2025-05-02 10:10:02,650 - INFO - AVWGCN initialized with dim_in=128, dim_out=128, cheb_k=2\n",
            "INFO:AGCRN.dfl:AVWGCN initialized with dim_in=128, dim_out=128, cheb_k=2\n",
            "2025-05-02 10:10:02,654 - INFO - AVWGCN initialized with dim_in=128, dim_out=64, cheb_k=2\n",
            "INFO:AGCRN.dfl:AVWGCN initialized with dim_in=128, dim_out=64, cheb_k=2\n",
            "2025-05-02 10:10:02,656 - INFO - AGCRNCell initialized with node_num=4, dim_in=64, dim_out=64\n",
            "INFO:AGCRN.dfl:AGCRNCell initialized with node_num=4, dim_in=64, dim_out=64\n",
            "2025-05-02 10:10:02,658 - INFO - AGCRN initialized with 2 layers\n",
            "INFO:AGCRN.dfl:AGCRN initialized with 2 layers\n",
            "2025-05-02 10:10:02,662 - INFO - Added client 26 to federation\n",
            "INFO:AGCRN.dfl:Added client 26 to federation\n",
            "2025-05-02 10:10:02,663 - INFO - Added client 26 with 4 nodes\n",
            "INFO:AGCRN.dfl:Added client 26 with 4 nodes\n",
            "2025-05-02 10:10:02,668 - INFO - AVWGCN initialized with dim_in=65, dim_out=128, cheb_k=2\n",
            "INFO:AGCRN.dfl:AVWGCN initialized with dim_in=65, dim_out=128, cheb_k=2\n",
            "2025-05-02 10:10:02,674 - INFO - AVWGCN initialized with dim_in=65, dim_out=64, cheb_k=2\n",
            "INFO:AGCRN.dfl:AVWGCN initialized with dim_in=65, dim_out=64, cheb_k=2\n",
            "2025-05-02 10:10:02,675 - INFO - AGCRNCell initialized with node_num=5, dim_in=1, dim_out=64\n",
            "INFO:AGCRN.dfl:AGCRNCell initialized with node_num=5, dim_in=1, dim_out=64\n",
            "2025-05-02 10:10:02,682 - INFO - AVWGCN initialized with dim_in=128, dim_out=128, cheb_k=2\n",
            "INFO:AGCRN.dfl:AVWGCN initialized with dim_in=128, dim_out=128, cheb_k=2\n",
            "2025-05-02 10:10:02,686 - INFO - AVWGCN initialized with dim_in=128, dim_out=64, cheb_k=2\n",
            "INFO:AGCRN.dfl:AVWGCN initialized with dim_in=128, dim_out=64, cheb_k=2\n",
            "2025-05-02 10:10:02,688 - INFO - AGCRNCell initialized with node_num=5, dim_in=64, dim_out=64\n",
            "INFO:AGCRN.dfl:AGCRNCell initialized with node_num=5, dim_in=64, dim_out=64\n",
            "2025-05-02 10:10:02,690 - INFO - AGCRN initialized with 2 layers\n",
            "INFO:AGCRN.dfl:AGCRN initialized with 2 layers\n",
            "2025-05-02 10:10:02,694 - INFO - Added client 27 to federation\n",
            "INFO:AGCRN.dfl:Added client 27 to federation\n",
            "2025-05-02 10:10:02,696 - INFO - Added client 27 with 5 nodes\n",
            "INFO:AGCRN.dfl:Added client 27 with 5 nodes\n",
            "2025-05-02 10:10:02,700 - INFO - AVWGCN initialized with dim_in=65, dim_out=128, cheb_k=2\n",
            "INFO:AGCRN.dfl:AVWGCN initialized with dim_in=65, dim_out=128, cheb_k=2\n",
            "2025-05-02 10:10:02,703 - INFO - AVWGCN initialized with dim_in=65, dim_out=64, cheb_k=2\n",
            "INFO:AGCRN.dfl:AVWGCN initialized with dim_in=65, dim_out=64, cheb_k=2\n",
            "2025-05-02 10:10:02,705 - INFO - AGCRNCell initialized with node_num=4, dim_in=1, dim_out=64\n",
            "INFO:AGCRN.dfl:AGCRNCell initialized with node_num=4, dim_in=1, dim_out=64\n",
            "2025-05-02 10:10:02,711 - INFO - AVWGCN initialized with dim_in=128, dim_out=128, cheb_k=2\n",
            "INFO:AGCRN.dfl:AVWGCN initialized with dim_in=128, dim_out=128, cheb_k=2\n",
            "2025-05-02 10:10:02,716 - INFO - AVWGCN initialized with dim_in=128, dim_out=64, cheb_k=2\n",
            "INFO:AGCRN.dfl:AVWGCN initialized with dim_in=128, dim_out=64, cheb_k=2\n",
            "2025-05-02 10:10:02,717 - INFO - AGCRNCell initialized with node_num=4, dim_in=64, dim_out=64\n",
            "INFO:AGCRN.dfl:AGCRNCell initialized with node_num=4, dim_in=64, dim_out=64\n",
            "2025-05-02 10:10:02,719 - INFO - AGCRN initialized with 2 layers\n",
            "INFO:AGCRN.dfl:AGCRN initialized with 2 layers\n",
            "2025-05-02 10:10:02,723 - INFO - Added client 28 to federation\n",
            "INFO:AGCRN.dfl:Added client 28 to federation\n",
            "2025-05-02 10:10:02,725 - INFO - Added client 28 with 4 nodes\n",
            "INFO:AGCRN.dfl:Added client 28 with 4 nodes\n",
            "2025-05-02 10:10:02,729 - INFO - AVWGCN initialized with dim_in=65, dim_out=128, cheb_k=2\n",
            "INFO:AGCRN.dfl:AVWGCN initialized with dim_in=65, dim_out=128, cheb_k=2\n",
            "2025-05-02 10:10:02,733 - INFO - AVWGCN initialized with dim_in=65, dim_out=64, cheb_k=2\n",
            "INFO:AGCRN.dfl:AVWGCN initialized with dim_in=65, dim_out=64, cheb_k=2\n",
            "2025-05-02 10:10:02,734 - INFO - AGCRNCell initialized with node_num=8, dim_in=1, dim_out=64\n",
            "INFO:AGCRN.dfl:AGCRNCell initialized with node_num=8, dim_in=1, dim_out=64\n",
            "2025-05-02 10:10:02,741 - INFO - AVWGCN initialized with dim_in=128, dim_out=128, cheb_k=2\n",
            "INFO:AGCRN.dfl:AVWGCN initialized with dim_in=128, dim_out=128, cheb_k=2\n",
            "2025-05-02 10:10:02,745 - INFO - AVWGCN initialized with dim_in=128, dim_out=64, cheb_k=2\n",
            "INFO:AGCRN.dfl:AVWGCN initialized with dim_in=128, dim_out=64, cheb_k=2\n",
            "2025-05-02 10:10:02,747 - INFO - AGCRNCell initialized with node_num=8, dim_in=64, dim_out=64\n",
            "INFO:AGCRN.dfl:AGCRNCell initialized with node_num=8, dim_in=64, dim_out=64\n",
            "2025-05-02 10:10:02,749 - INFO - AGCRN initialized with 2 layers\n",
            "INFO:AGCRN.dfl:AGCRN initialized with 2 layers\n",
            "2025-05-02 10:10:02,753 - INFO - Added client 29 to federation\n",
            "INFO:AGCRN.dfl:Added client 29 to federation\n",
            "2025-05-02 10:10:02,755 - INFO - Added client 29 with 8 nodes\n",
            "INFO:AGCRN.dfl:Added client 29 with 8 nodes\n",
            "2025-05-02 10:10:02,759 - INFO - AVWGCN initialized with dim_in=65, dim_out=128, cheb_k=2\n",
            "INFO:AGCRN.dfl:AVWGCN initialized with dim_in=65, dim_out=128, cheb_k=2\n",
            "2025-05-02 10:10:02,762 - INFO - AVWGCN initialized with dim_in=65, dim_out=64, cheb_k=2\n",
            "INFO:AGCRN.dfl:AVWGCN initialized with dim_in=65, dim_out=64, cheb_k=2\n",
            "2025-05-02 10:10:02,764 - INFO - AGCRNCell initialized with node_num=5, dim_in=1, dim_out=64\n",
            "INFO:AGCRN.dfl:AGCRNCell initialized with node_num=5, dim_in=1, dim_out=64\n",
            "2025-05-02 10:10:02,771 - INFO - AVWGCN initialized with dim_in=128, dim_out=128, cheb_k=2\n",
            "INFO:AGCRN.dfl:AVWGCN initialized with dim_in=128, dim_out=128, cheb_k=2\n",
            "2025-05-02 10:10:02,775 - INFO - AVWGCN initialized with dim_in=128, dim_out=64, cheb_k=2\n",
            "INFO:AGCRN.dfl:AVWGCN initialized with dim_in=128, dim_out=64, cheb_k=2\n",
            "2025-05-02 10:10:02,777 - INFO - AGCRNCell initialized with node_num=5, dim_in=64, dim_out=64\n",
            "INFO:AGCRN.dfl:AGCRNCell initialized with node_num=5, dim_in=64, dim_out=64\n",
            "2025-05-02 10:10:02,780 - INFO - AGCRN initialized with 2 layers\n",
            "INFO:AGCRN.dfl:AGCRN initialized with 2 layers\n",
            "2025-05-02 10:10:02,784 - INFO - Added client 30 to federation\n",
            "INFO:AGCRN.dfl:Added client 30 to federation\n",
            "2025-05-02 10:10:02,785 - INFO - Added client 30 with 5 nodes\n",
            "INFO:AGCRN.dfl:Added client 30 with 5 nodes\n",
            "2025-05-02 10:10:02,790 - INFO - AVWGCN initialized with dim_in=65, dim_out=128, cheb_k=2\n",
            "INFO:AGCRN.dfl:AVWGCN initialized with dim_in=65, dim_out=128, cheb_k=2\n",
            "2025-05-02 10:10:02,793 - INFO - AVWGCN initialized with dim_in=65, dim_out=64, cheb_k=2\n",
            "INFO:AGCRN.dfl:AVWGCN initialized with dim_in=65, dim_out=64, cheb_k=2\n",
            "2025-05-02 10:10:02,795 - INFO - AGCRNCell initialized with node_num=7, dim_in=1, dim_out=64\n",
            "INFO:AGCRN.dfl:AGCRNCell initialized with node_num=7, dim_in=1, dim_out=64\n",
            "2025-05-02 10:10:02,804 - INFO - AVWGCN initialized with dim_in=128, dim_out=128, cheb_k=2\n",
            "INFO:AGCRN.dfl:AVWGCN initialized with dim_in=128, dim_out=128, cheb_k=2\n",
            "2025-05-02 10:10:02,812 - INFO - AVWGCN initialized with dim_in=128, dim_out=64, cheb_k=2\n",
            "INFO:AGCRN.dfl:AVWGCN initialized with dim_in=128, dim_out=64, cheb_k=2\n",
            "2025-05-02 10:10:02,814 - INFO - AGCRNCell initialized with node_num=7, dim_in=64, dim_out=64\n",
            "INFO:AGCRN.dfl:AGCRNCell initialized with node_num=7, dim_in=64, dim_out=64\n",
            "2025-05-02 10:10:02,816 - INFO - AGCRN initialized with 2 layers\n",
            "INFO:AGCRN.dfl:AGCRN initialized with 2 layers\n",
            "2025-05-02 10:10:02,820 - INFO - Added client 31 to federation\n",
            "INFO:AGCRN.dfl:Added client 31 to federation\n",
            "2025-05-02 10:10:02,822 - INFO - Added client 31 with 7 nodes\n",
            "INFO:AGCRN.dfl:Added client 31 with 7 nodes\n",
            "2025-05-02 10:10:02,826 - INFO - AVWGCN initialized with dim_in=65, dim_out=128, cheb_k=2\n",
            "INFO:AGCRN.dfl:AVWGCN initialized with dim_in=65, dim_out=128, cheb_k=2\n",
            "2025-05-02 10:10:02,829 - INFO - AVWGCN initialized with dim_in=65, dim_out=64, cheb_k=2\n",
            "INFO:AGCRN.dfl:AVWGCN initialized with dim_in=65, dim_out=64, cheb_k=2\n",
            "2025-05-02 10:10:02,831 - INFO - AGCRNCell initialized with node_num=12, dim_in=1, dim_out=64\n",
            "INFO:AGCRN.dfl:AGCRNCell initialized with node_num=12, dim_in=1, dim_out=64\n",
            "2025-05-02 10:10:02,838 - INFO - AVWGCN initialized with dim_in=128, dim_out=128, cheb_k=2\n",
            "INFO:AGCRN.dfl:AVWGCN initialized with dim_in=128, dim_out=128, cheb_k=2\n",
            "2025-05-02 10:10:02,842 - INFO - AVWGCN initialized with dim_in=128, dim_out=64, cheb_k=2\n",
            "INFO:AGCRN.dfl:AVWGCN initialized with dim_in=128, dim_out=64, cheb_k=2\n",
            "2025-05-02 10:10:02,844 - INFO - AGCRNCell initialized with node_num=12, dim_in=64, dim_out=64\n",
            "INFO:AGCRN.dfl:AGCRNCell initialized with node_num=12, dim_in=64, dim_out=64\n",
            "2025-05-02 10:10:02,846 - INFO - AGCRN initialized with 2 layers\n",
            "INFO:AGCRN.dfl:AGCRN initialized with 2 layers\n",
            "2025-05-02 10:10:02,850 - INFO - Added client 32 to federation\n",
            "INFO:AGCRN.dfl:Added client 32 to federation\n",
            "2025-05-02 10:10:02,851 - INFO - Added client 32 with 12 nodes\n",
            "INFO:AGCRN.dfl:Added client 32 with 12 nodes\n",
            "2025-05-02 10:10:02,856 - INFO - AVWGCN initialized with dim_in=65, dim_out=128, cheb_k=2\n",
            "INFO:AGCRN.dfl:AVWGCN initialized with dim_in=65, dim_out=128, cheb_k=2\n",
            "2025-05-02 10:10:02,859 - INFO - AVWGCN initialized with dim_in=65, dim_out=64, cheb_k=2\n",
            "INFO:AGCRN.dfl:AVWGCN initialized with dim_in=65, dim_out=64, cheb_k=2\n",
            "2025-05-02 10:10:02,861 - INFO - AGCRNCell initialized with node_num=5, dim_in=1, dim_out=64\n",
            "INFO:AGCRN.dfl:AGCRNCell initialized with node_num=5, dim_in=1, dim_out=64\n",
            "2025-05-02 10:10:02,869 - INFO - AVWGCN initialized with dim_in=128, dim_out=128, cheb_k=2\n",
            "INFO:AGCRN.dfl:AVWGCN initialized with dim_in=128, dim_out=128, cheb_k=2\n",
            "2025-05-02 10:10:02,873 - INFO - AVWGCN initialized with dim_in=128, dim_out=64, cheb_k=2\n",
            "INFO:AGCRN.dfl:AVWGCN initialized with dim_in=128, dim_out=64, cheb_k=2\n",
            "2025-05-02 10:10:02,875 - INFO - AGCRNCell initialized with node_num=5, dim_in=64, dim_out=64\n",
            "INFO:AGCRN.dfl:AGCRNCell initialized with node_num=5, dim_in=64, dim_out=64\n",
            "2025-05-02 10:10:02,877 - INFO - AGCRN initialized with 2 layers\n",
            "INFO:AGCRN.dfl:AGCRN initialized with 2 layers\n",
            "2025-05-02 10:10:02,881 - INFO - Added client 33 to federation\n",
            "INFO:AGCRN.dfl:Added client 33 to federation\n",
            "2025-05-02 10:10:02,883 - INFO - Added client 33 with 5 nodes\n",
            "INFO:AGCRN.dfl:Added client 33 with 5 nodes\n",
            "2025-05-02 10:10:02,884 - INFO - Started federated learning\n",
            "INFO:AGCRN.dfl:Started federated learning\n",
            "2025-05-02 10:10:02,886 - INFO - Starting round 0\n",
            "INFO:AGCRN.dfl:Starting round 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Phase 4: Evaluation**\n",
        "- Accuracy metrics\n",
        "- Communication cost\n",
        "- Convergence analysis"
      ],
      "metadata": {
        "id": "IXaCrnsdGEx8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 1: Import và Setup"
      ],
      "metadata": {
        "id": "XfbHIIctITVy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "import time\n",
        "from typing import Dict, List, Tuple\n",
        "import logging\n",
        "from datetime import datetime\n",
        "\n",
        "logger = logging.getLogger('AGCRN.evaluation')\n",
        "\n",
        "class EvaluationConfig:\n",
        "    def __init__(self):\n",
        "        self.metrics_log_interval = 100  # batches\n",
        "        self.save_dir = '/content/results/evaluation'\n",
        "        self.plot_dir = f'{self.save_dir}/plots'\n",
        "\n",
        "        os.makedirs(self.save_dir, exist_ok=True)\n",
        "        os.makedirs(self.plot_dir, exist_ok=True)\n",
        "\n",
        "        logger.info(\"Evaluation configuration initialized\")"
      ],
      "metadata": {
        "id": "0SDcPBrgGE29"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 2: Accuracy Metrics"
      ],
      "metadata": {
        "id": "vtGbz-flGE8t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AccuracyMetrics:\n",
        "    def __init__(self, scaler=None):\n",
        "        self.scaler = scaler\n",
        "        self.metrics_history = {\n",
        "            'mae': [],\n",
        "            'rmse': [],\n",
        "            'mape': [],\n",
        "            'r2': []\n",
        "        }\n",
        "\n",
        "    def calculate_metrics(self, y_true: torch.Tensor, y_pred: torch.Tensor) -> Dict[str, float]:\n",
        "        \"\"\"\n",
        "        Calculate all accuracy metrics\n",
        "        \"\"\"\n",
        "        # Convert to numpy and rescale if scaler exists\n",
        "        if self.scaler:\n",
        "            y_true = self.scaler.inverse_transform(y_true.cpu().numpy())\n",
        "            y_pred = self.scaler.inverse_transform(y_pred.cpu().numpy())\n",
        "        else:\n",
        "            y_true = y_true.cpu().numpy()\n",
        "            y_pred = y_pred.cpu().numpy()\n",
        "\n",
        "        # Calculate metrics\n",
        "        mae = mean_absolute_error(y_true, y_pred)\n",
        "        rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "\n",
        "        # Calculate MAPE with handling for zeros\n",
        "        mask = y_true != 0\n",
        "        mape = np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100\n",
        "\n",
        "        # Calculate R2 score\n",
        "        r2 = r2_score(y_true, y_pred)\n",
        "\n",
        "        metrics = {\n",
        "            'mae': mae,\n",
        "            'rmse': rmse,\n",
        "            'mape': mape,\n",
        "            'r2': r2\n",
        "        }\n",
        "\n",
        "        # Update history\n",
        "        for metric, value in metrics.items():\n",
        "            self.metrics_history[metric].append(value)\n",
        "\n",
        "        return metrics\n",
        "\n",
        "    def plot_metrics_history(self):\n",
        "        \"\"\"\n",
        "        Plot metrics history\n",
        "        \"\"\"\n",
        "        fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "        fig.suptitle('Training Metrics History')\n",
        "\n",
        "        for ax, (metric, values) in zip(axes.flat, self.metrics_history.items()):\n",
        "            ax.plot(values)\n",
        "            ax.set_title(metric.upper())\n",
        "            ax.set_xlabel('Batch')\n",
        "            ax.grid(True)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(f'{EvaluationConfig().plot_dir}/metrics_history.png')\n",
        "        plt.close()"
      ],
      "metadata": {
        "id": "rNPXKtHFGFCA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 3: Communication Cost Analysis"
      ],
      "metadata": {
        "id": "VJmXNKWcGFF9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CommunicationAnalyzer:\n",
        "    def __init__(self):\n",
        "        self.comm_history = {\n",
        "            'bytes_sent': [],\n",
        "            'bytes_received': [],\n",
        "            'latency': [],\n",
        "            'bandwidth_usage': []\n",
        "        }\n",
        "        self.start_time = time.time()\n",
        "\n",
        "    def log_communication(self, message_size: int, direction: str, latency: float):\n",
        "        \"\"\"\n",
        "        Log communication metrics\n",
        "        \"\"\"\n",
        "        timestamp = time.time() - self.start_time\n",
        "\n",
        "        if direction == 'sent':\n",
        "            self.comm_history['bytes_sent'].append((timestamp, message_size))\n",
        "        else:\n",
        "            self.comm_history['bytes_received'].append((timestamp, message_size))\n",
        "\n",
        "        self.comm_history['latency'].append((timestamp, latency))\n",
        "\n",
        "        # Calculate bandwidth usage (bytes/second)\n",
        "        bandwidth = message_size / latency if latency > 0 else 0\n",
        "        self.comm_history['bandwidth_usage'].append((timestamp, bandwidth))\n",
        "\n",
        "    def analyze_communication_cost(self) -> Dict[str, float]:\n",
        "        \"\"\"\n",
        "        Analyze communication metrics\n",
        "        \"\"\"\n",
        "        total_sent = sum(size for _, size in self.comm_history['bytes_sent'])\n",
        "        total_received = sum(size for _, size in self.comm_history['bytes_received'])\n",
        "        avg_latency = np.mean([lat for _, lat in self.comm_history['latency']])\n",
        "        avg_bandwidth = np.mean([bw for _, bw in self.comm_history['bandwidth_usage']])\n",
        "\n",
        "        return {\n",
        "            'total_bytes_sent_mb': total_sent / (1024 * 1024),\n",
        "            'total_bytes_received_mb': total_received / (1024 * 1024),\n",
        "            'average_latency_ms': avg_latency * 1000,\n",
        "            'average_bandwidth_mbps': avg_bandwidth * 8 / (1024 * 1024)\n",
        "        }\n",
        "\n",
        "    def plot_communication_metrics(self):\n",
        "        \"\"\"\n",
        "        Plot communication metrics\n",
        "        \"\"\"\n",
        "        fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "        fig.suptitle('Communication Metrics')\n",
        "\n",
        "        # Plot bytes sent/received\n",
        "        ax = axes[0, 0]\n",
        "        sent_data = np.array(self.comm_history['bytes_sent'])\n",
        "        received_data = np.array(self.comm_history['bytes_received'])\n",
        "        ax.plot(sent_data[:, 0], sent_data[:, 1], label='Sent')\n",
        "        ax.plot(received_data[:, 0], received_data[:, 1], label='Received')\n",
        "        ax.set_title('Data Transfer')\n",
        "        ax.set_xlabel('Time (s)')\n",
        "        ax.set_ylabel('Bytes')\n",
        "        ax.legend()\n",
        "\n",
        "        # Plot latency\n",
        "        ax = axes[0, 1]\n",
        "        latency_data = np.array(self.comm_history['latency'])\n",
        "        ax.plot(latency_data[:, 0], latency_data[:, 1])\n",
        "        ax.set_title('Latency')\n",
        "        ax.set_xlabel('Time (s)')\n",
        "        ax.set_ylabel('Seconds')\n",
        "\n",
        "        # Plot bandwidth usage\n",
        "        ax = axes[1, 0]\n",
        "        bandwidth_data = np.array(self.comm_history['bandwidth_usage'])\n",
        "        ax.plot(bandwidth_data[:, 0], bandwidth_data[:, 1])\n",
        "        ax.set_title('Bandwidth Usage')\n",
        "        ax.set_xlabel('Time (s)')\n",
        "        ax.set_ylabel('Bytes/second')\n",
        "\n",
        "        # Plot cumulative data transfer\n",
        "        ax = axes[1, 1]\n",
        "        cumsum_sent = np.cumsum(sent_data[:, 1])\n",
        "        cumsum_received = np.cumsum(received_data[:, 1])\n",
        "        ax.plot(sent_data[:, 0], cumsum_sent, label='Sent')\n",
        "        ax.plot(received_data[:, 0], cumsum_received, label='Received')\n",
        "        ax.set_title('Cumulative Data Transfer')\n",
        "        ax.set_xlabel('Time (s)')\n",
        "        ax.set_ylabel('Total Bytes')\n",
        "        ax.legend()\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(f'{EvaluationConfig().plot_dir}/communication_metrics.png')\n",
        "        plt.close()"
      ],
      "metadata": {
        "id": "rGu5LphaGFLO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 4: Convergence Analysis"
      ],
      "metadata": {
        "id": "EoP6HYX8GFQY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvergenceAnalyzer:\n",
        "    def __init__(self):\n",
        "        self.loss_history = []\n",
        "        self.gradient_norms = []\n",
        "        self.parameter_changes = []\n",
        "        self.convergence_metrics = {}\n",
        "\n",
        "    def log_training_step(self, loss: float, model: torch.nn.Module,\n",
        "                         prev_params: Optional[Dict[str, torch.Tensor]] = None):\n",
        "        \"\"\"\n",
        "        Log training metrics for convergence analysis\n",
        "        \"\"\"\n",
        "        self.loss_history.append(loss)\n",
        "\n",
        "        # Calculate gradient norms\n",
        "        grad_norm = 0\n",
        "        for param in model.parameters():\n",
        "            if param.grad is not None:\n",
        "                grad_norm += param.grad.norm().item() ** 2\n",
        "        self.gradient_norms.append(np.sqrt(grad_norm))\n",
        "\n",
        "        # Calculate parameter changes if previous parameters available\n",
        "        if prev_params is not None:\n",
        "            param_change = 0\n",
        "            current_params = dict(model.named_parameters())\n",
        "            for name, prev_param in prev_params.items():\n",
        "                param_change += torch.norm(\n",
        "                    current_params[name] - prev_param\n",
        "                ).item() ** 2\n",
        "            self.parameter_changes.append(np.sqrt(param_change))\n",
        "\n",
        "    def analyze_convergence(self) -> Dict[str, float]:\n",
        "        \"\"\"\n",
        "        Analyze convergence metrics\n",
        "        \"\"\"\n",
        "        # Calculate convergence rate\n",
        "        if len(self.loss_history) > 1:\n",
        "            loss_diffs = np.diff(self.loss_history)\n",
        "            convergence_rate = np.mean(loss_diffs)\n",
        "        else:\n",
        "            convergence_rate = 0\n",
        "\n",
        "        # Check for oscillations\n",
        "        if len(self.loss_history) > 2:\n",
        "            oscillation_metric = np.std(loss_diffs)\n",
        "        else:\n",
        "            oscillation_metric = 0\n",
        "\n",
        "        # Calculate stability metrics\n",
        "        gradient_stability = np.std(self.gradient_norms)\n",
        "\n",
        "        self.convergence_metrics = {\n",
        "            'convergence_rate': convergence_rate,\n",
        "            'oscillation_metric': oscillation_metric,\n",
        "            'gradient_stability': gradient_stability,\n",
        "            'final_loss': self.loss_history[-1] if self.loss_history else None\n",
        "        }\n",
        "\n",
        "        return self.convergence_metrics\n",
        "\n",
        "    def plot_convergence_analysis(self):\n",
        "        \"\"\"\n",
        "        Plot convergence analysis\n",
        "        \"\"\"\n",
        "        fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "        fig.suptitle('Convergence Analysis')\n",
        "\n",
        "        # Plot loss history\n",
        "        ax = axes[0, 0]\n",
        "        ax.plot(self.loss_history)\n",
        "        ax.set_title('Loss History')\n",
        "        ax.set_xlabel('Step')\n",
        "        ax.set_ylabel('Loss')\n",
        "\n",
        "        # Plot gradient norms\n",
        "        ax = axes[0, 1]\n",
        "        ax.plot(self.gradient_norms)\n",
        "        ax.set_title('Gradient Norms')\n",
        "        ax.set_xlabel('Step')\n",
        "        ax.set_ylabel('L2 Norm')\n",
        "\n",
        "        # Plot parameter changes\n",
        "        ax = axes[1, 0]\n",
        "        if self.parameter_changes:\n",
        "            ax.plot(self.parameter_changes)\n",
        "            ax.set_title('Parameter Changes')\n",
        "            ax.set_xlabel('Step')\n",
        "            ax.set_ylabel('L2 Norm')\n",
        "\n",
        "        # Plot loss distribution\n",
        "        ax = axes[1, 1]\n",
        "        sns.histplot(self.loss_history, ax=ax)\n",
        "        ax.set_title('Loss Distribution')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(f'{EvaluationConfig().plot_dir}/convergence_analysis.png')\n",
        "        plt.close()"
      ],
      "metadata": {
        "id": "PERJ4ulJGFVo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 5: Evaluation Manager"
      ],
      "metadata": {
        "id": "0FbVZ3piGFaa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EvaluationManager:\n",
        "    def __init__(self, config: EvaluationConfig):\n",
        "        self.config = config\n",
        "        self.accuracy_metrics = AccuracyMetrics()\n",
        "        self.comm_analyzer = CommunicationAnalyzer()\n",
        "        self.convergence_analyzer = ConvergenceAnalyzer()\n",
        "\n",
        "    def log_batch(self, y_true: torch.Tensor, y_pred: torch.Tensor,\n",
        "                  loss: float, model: torch.nn.Module,\n",
        "                  message_size: int, latency: float,\n",
        "                  prev_params: Optional[Dict[str, torch.Tensor]] = None):\n",
        "        \"\"\"\n",
        "        Log metrics for a training batch\n",
        "        \"\"\"\n",
        "        # Log accuracy metrics\n",
        "        metrics = self.accuracy_metrics.calculate_metrics(y_true, y_pred)\n",
        "\n",
        "        # Log communication costs\n",
        "        self.comm_analyzer.log_communication(message_size, 'sent', latency)\n",
        "\n",
        "        # Log convergence metrics\n",
        "        self.convergence_analyzer.log_training_step(loss, model, prev_params)\n",
        "\n",
        "        return metrics\n",
        "\n",
        "    def generate_evaluation_report(self):\n",
        "        \"\"\"\n",
        "        Generate comprehensive evaluation report\n",
        "        \"\"\"\n",
        "        # Analyze all metrics\n",
        "        accuracy_results = dict(zip(\n",
        "            self.accuracy_metrics.metrics_history.keys(),\n",
        "            [np.mean(values) for values in self.accuracy_metrics.metrics_history.values()]\n",
        "        ))\n",
        "\n",
        "        comm_results = self.comm_analyzer.analyze_communication_cost()\n",
        "        convergence_results = self.convergence_analyzer.analyze_convergence()\n",
        "\n",
        "        # Create report\n",
        "        report = {\n",
        "            'timestamp': datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S'),\n",
        "            'accuracy_metrics': accuracy_results,\n",
        "            'communication_metrics': comm_results,\n",
        "            'convergence_metrics': convergence_results\n",
        "        }\n",
        "\n",
        "        # Save report\n",
        "        report_path = f'{self.config.save_dir}/evaluation_report.json'\n",
        "        with open(report_path, 'w') as f:\n",
        "            json.dump(report, f, indent=4)\n",
        "\n",
        "        # Generate plots\n",
        "        self.accuracy_metrics.plot_metrics_history()\n",
        "        self.comm_analyzer.plot_communication_metrics()\n",
        "        self.convergence_analyzer.plot_convergence_analysis()\n",
        "\n",
        "        logger.info(f\"Evaluation report saved to {report_path}\")\n",
        "        return report"
      ],
      "metadata": {
        "id": "fF5NgQVPGFfc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 6: Usage Example"
      ],
      "metadata": {
        "id": "NKNl8sDUGFjr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    # Initialize evaluation\n",
        "    config = EvaluationConfig()\n",
        "    evaluator = EvaluationManager(config)\n",
        "\n",
        "    # Simulate training loop\n",
        "    for batch_idx in range(100):\n",
        "        # Simulate batch training\n",
        "        y_true = torch.randn(32, 12, 207, 1)  # Example dimensions\n",
        "        y_pred = torch.randn(32, 12, 207, 1)\n",
        "        loss = torch.nn.functional.mse_loss(y_pred, y_true).item()\n",
        "\n",
        "        # Log metrics\n",
        "        metrics = evaluator.log_batch(\n",
        "            y_true=y_true,\n",
        "            y_pred=y_pred,\n",
        "            loss=loss,\n",
        "            model=model,  # Your AGCRN model\n",
        "            message_size=1000000,  # Example size\n",
        "            latency=0.1,  # Example latency\n",
        "            prev_params=prev_params  # Previous model parameters\n",
        "        )\n",
        "\n",
        "        if batch_idx % config.metrics_log_interval == 0:\n",
        "            logger.info(f\"Batch {batch_idx}: {metrics}\")\n",
        "\n",
        "    # Generate final report\n",
        "    report = evaluator.generate_evaluation_report()\n",
        "    logger.info(\"Evaluation completed\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "-UohNFdJGFok"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}